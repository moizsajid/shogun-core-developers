--- Log opened Fri May 25 00:00:41 2012
-!- puffin444 [62e3926e@gateway/web/freenode/ip.98.227.146.110] has joined #shogun
 shogun-buildbot	build #551 of java_modular is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/java_modular/builds/551  blamelist: sonne@debian.org
-!- puffin444 [62e3926e@gateway/web/freenode/ip.98.227.146.110] has quit [Quit: Page closed]
-!- shogun-buildbot [~shogun-bu@7nn.de] has quit [Ping timeout: 252 seconds]
-!- shogun-buildbot [~shogun-bu@7nn.de] has joined #shogun
 CIA-113	shogun: Sergey Lisitsyn master * rede11ce / src/shogun/classifier/svm/SVMOcas.cpp : Made SVMOcas support subsets - http://git.io/27jFxw
 CIA-113	shogun: Sergey Lisitsyn master * r37f1841 / (2 files in 2 dirs): Removed a few warnings - http://git.io/Q2r26g
-!- av3ngr [av3ngr@nat/redhat/x-zaxxfumfvxtiubyv] has joined #shogun
-!- blackburn [~blackburn@188.122.250.167] has quit [Quit: Leaving.]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
-!- Netsplit *.net <-> *.split quits: gsomix
-!- Netsplit *.net <-> *.split quits: @sonney2k, sonne|work, av3ngr
-!- Netsplit over, joins: gsomix
-!- av3ngr [av3ngr@nat/redhat/x-zaxxfumfvxtiubyv] has joined #shogun
-!- sonne|work [~sonnenbu@194.78.35.195] has joined #shogun
-!- sonney2k [~shogun@7nn.de] has joined #shogun
-!- ServerMode/#shogun [+o sonney2k] by pratchett.freenode.net
-!- Netsplit *.net <-> *.split quits: gsomix
-!- Netsplit over, joins: gsomix
-!- vikram360 [~vikram360@117.192.170.193] has joined #shogun
-!- vikram360 [~vikram360@117.192.170.193] has quit [Read error: Connection reset by peer]
-!- gsomix [~gsomix@83.234.54.21] has quit [Read error: Operation timed out]
-!- gsomix [~gsomix@83.234.54.21] has joined #shogun
-!- gsomix [~gsomix@83.234.54.21] has quit [Quit: Ex-Chat]
-!- pluskid [~pluskid@li400-235.members.linode.com] has joined #shogun
-!- mode/#shogun [-bb *!*46e7e626@*.70.231.230.38 sonney2k!~shogun@7nn.de] by sonney2k
-!- uricamic [~uricamic@2001:718:2:1634:5c56:9bc4:b0a1:c02b] has joined #shogun
-!- pluskid [~pluskid@li400-235.members.linode.com] has quit [Ping timeout: 244 seconds]
-!- av3ngr [av3ngr@nat/redhat/x-zaxxfumfvxtiubyv] has quit [Quit: That's all folks!]
-!- pluskid [~pluskid@111.120.53.76] has joined #shogun
-!- pluskid [~pluskid@111.120.53.76] has quit [Ping timeout: 252 seconds]
-!- pluskid [~pluskid@li164-218.members.linode.com] has joined #shogun
-!- pluskid [~pluskid@li164-218.members.linode.com] has quit [Ping timeout: 240 seconds]
-!- eric___ [2e1fd566@gateway/web/freenode/ip.46.31.213.102] has joined #shogun
 eric___	hi all
 eric___	sonne|work: is the new multiclasslabels interfaces working ?
 sonne|work	eric___: should be
 eric___	eric___: I will test it today, thx
 eric___	sonne|work: btw, I have mentioned few days ago, smthg strange with the multiclass Xvalid: for some kernel machine, the Xval mean is always equal to 0.1. When I split my data manually several times, I got mean > 0.7*
 sonne|work	eric___: can you give us some example to reproduce the problem?
-!- pluskid [~pluskid@111.120.53.76] has joined #shogun
 eric___	sure. how can I send you the features ?
 sonne|work	eric___: how big is this? can you reproduce this on some small example (the smaller the better, e.g. random/artificial data)
 eric___	sonne|work: okay, I will try to reproduce the problem. I am currently working with visual data so it's pretty big.
 sonne|work	eric___: thanks - that will make it much easier to fix the problem
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
 sonne|work	n4nd0, pluskid have you seen - we are drowning in warnings http://shogun-toolbox.org/buildbot/builders/java_modular/builds/553/steps/compile/logs/warnings%20%28213%29
 sonne|work	if you have time please fix the ones in your code
 pluskid	sure
 eric___	No more "get_label" method in CLabels ?
-!- alexlistens [6d2d0022@gateway/web/freenode/ip.109.45.0.34] has joined #shogun
 sonne|work	eric___: exactly
 sonne|work	eric___: each machine now returns a particular label object, like CMulticlassLabels (for multiclass machines)
 sonne|work	etc
 sonne|work	so you will need to do CMulticlassLabels* mc_labels=CMulticlassMachine::obtain_from_generic(labels);
 sonne|work	mc_labels.get_label()
-!- nicococo [~nico@lacedcoffee.ml.tu-berlin.de] has joined #shogun
 eric___	sonne|work: perfect
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- ckwidmer [~chris@HSI-KBW-046-005-237-106.hsi8.kabel-badenwuerttemberg.de] has joined #shogun
 n4nd0	nicococo: hey! I started yesterday to write some code to input the problem to mosek
-!- karlnapf [~heiko@host86-171-220-235.range86-171.btcentralplus.com] has joined #shogun
 karlnapf	sonney2k, in 20 mins it is 10 UTC not 11 UTC
 karlnapf	I thought we would meet at 11 UTC?
 karlnapf	sonne|work ^
-!- vojtech [9320543b@gateway/web/freenode/ip.147.32.84.59] has joined #shogun
 vojtech	sonne: hi Soeren, is the meeting at 10:00UTC or 11:00UTC ?
-!- blackburn [~blackburn@188.122.250.167] has joined #shogun
 eric___	sonne|work: I created CMulticlassLabels and trained mc_svm. But I cannot write CMulticlassLabels* training_output = mc_svm->apply(training_features); because "error: invalid conversion from 'shogun::CLabels*' to 'shogun::CMulticlassLabels*' [-fpermissive]" I have to write CLabels* training_output = mc_svm->apply(training_features); Is that what you wwant ?
 eric___	sonne|work: okay I find out .. Have to use "apply_multiclass" has we discuss last time
 sonne|work	11 UTC
 sonne|work	sry
 blackburn	eric___: you may use casting there
 eric___	blackburn: yes that's what I feared, casting casting .. :)
 eric___	gj btw
 sonne|work	eric___: or you use the helper directly CMulticlassLabels* mc_labels=CMulticlassMachine::obtain_from_generic(mc_svm->apply());
 blackburn	pluskid: I have crash here with ECOC encoding decoding
 blackburn	let me try to come up with reproducing example
 blackburn	pluskid: ok easy
 blackburn	just train and apply machine two times
 eric___	I have crashed LibSVM model->nr_class=9 while num_classes=10, never happened before with simple CLabels
 eric___	going for lunch, see you.
 sonne|work	eric___: assertion or what?
 sonne|work	I found many mistakes in examples simply because we didn't have checks :)
 pluskid	blackburn: with any ECOC strategy?
-!- karlnapf1 [~heiko@host86-185-113-34.range86-185.btcentralplus.com] has joined #shogun
-!- blackburn [~blackburn@188.122.250.167] has quit [Read error: Connection reset by peer]
-!- alexlistens [6d2d0022@gateway/web/freenode/ip.109.45.0.34] has quit [Ping timeout: 245 seconds]
-!- karlnapf [~heiko@host86-171-220-235.range86-171.btcentralplus.com] has quit [Ping timeout: 245 seconds]
-!- blackburn [~blackburn@31.28.59.65] has joined #shogun
 karlnapf1	tets
 sonne|work	karlnapf1: tuts
 karlnapf1	sonne|work :D
 karlnapf1	just checking my connection
 sonne|work	20% package loss
 karlnapf1	annoying
 karlnapf1	I think Ill go somewhere else next week during the day
 karlnapf1	all the workshops and coffee places here got better connections than mine at home
 sonne|work	lets hope my mobile phone will work :)
 karlnapf1	sonne|work are you IRCing via phone?
 karlnapf1	nice
 sonne|work	karlnapf1: notebook -> mobile phone
 karlnapf1	ah alright
 sonne|work	btw pluskid that is how I am only in trains
 sonne|work	now way that german trains have wlan :)
 pluskid	sonne|work: oh, I see! :D
 sonne|work	well some ICEs have but...
 karlnapf1	sonne|work the public transport in Berlin hasnt, its too poor ;)
 sonne|work	yeah
 sonne|work	I am already happy if trains go at all
 karlnapf1	London underground has neither, and there is also no mobile internet available there
 karlnapf1	hehe
 sonne|work	karlnapf1: I've just seen this nice graph http://www.ohloh.net/p/shogun
 sonne|work	with the mouse cursor hover over F
 karlnapf1	I keep adapting to the trains here: If you have to wait more than 5 mins you get angry
 karlnapf1	sonne|work yes, I already knew that one. its nice :)
 karlnapf1	.
 pluskid	sonne|work: git says I have changes to commit in the data directory
 pluskid	and git diff shows this: http://pastebin.com/BqfhYZRw
 pluskid	do you know what's this?
 sonne|work	pluskid: you have to do git submodule update
 sonne|work	pluskid: we have the data in a seperate repository
 sonne|work	separate
 pluskid	sonne|work: ah, works, thank you
 blackburn	pluskid: will you take a look?
 sonne|work	blackburn: you didn't really give more details...
 pluskid	blackburn: yeah, after I fix the doc warnings
 blackburn	just train multiclass machine two times
 blackburn	BOOM!
 blackburn	train and apply
 blackburn	for some reason submachine is null
 CIA-113	shogun: Chiyuan Zhang master * r93b9050 / (14 files in 4 dirs): Fix missing doc warnings and correct some label types in MC Strategies. - http://git.io/n1-yQw
 CIA-113	shogun: Soeren Sonnenburg master * r6c4cdd5 / (14 files in 4 dirs): Merge pull request #552 from pluskid/multiclass - http://git.io/cSPxHw
 blackburn	hahah
 blackburn	sonne|work: one more reason to use *STANDART* data structures
 pluskid	blackburn: you find the bug?
 blackburn	yes
 pluskid	what's it?
 blackburn	clear_array
 blackburn	instead of reset_array
 pluskid	hmm... where?
 blackburn	in train of multiclass machine
 pluskid	btw: you are super fast :D
 pluskid	I haven't finished re-compiling yet :D
 blackburn	ccache :D
 pluskid	already using ccache+clang
 blackburn	hmm
 pluskid	don't know whether using ccache-swig might helps further
 pluskid	already much faster than before
 blackburn	full recompile takes 3-4 mins here
 pluskid	with ccache?
 blackburn	yes
 pluskid	hmm, then I'm not too slower than yours :D
 blackburn	not slower at all I think
 blackburn	cause I am using gcc
 blackburn	afaik it is slower?
 pluskid	blackburn: btw, will you fix it?
 pluskid	gcc uses more memory
 CIA-113	shogun: Sergey Lisitsyn master * r19ddc93 / (2 files): Fixed wrong handling of submachines array in multiclass machine - http://git.io/a1TchQ
 blackburn	fixed what?:D
 pluskid	haha
 pluskid	super fast
-!- oliver [c07c1afb@gateway/web/freenode/ip.192.124.26.251] has joined #shogun
-!- karlnapf1 [~heiko@host86-185-113-34.range86-185.btcentralplus.com] has quit [Quit: Leaving.]
-!- heiko [~heiko@host86-185-113-34.range86-185.btcentralplus.com] has joined #shogun
@sonney2k	blackburn, the PolarBearAttack msg me with "learn not to ban hackers"
@sonney2k	cool or?
 blackburn	:D
 blackburn	are you trying to convince me it is a bot?
@sonney2k	that bot was even better than betty
 blackburn	I believe but you would have to agree it is a very cool and smart bot
 blackburn	:D
@sonney2k	yeah it is
@sonney2k	pluskid if you know of a way to split up a >10 MB .cpp file and to compile the splits separately but link them together in the end
@sonney2k	that would speed it up!
 blackburn	sonney2k: should ocas be faster than liblinear (binary)?
@sonney2k	depends on problem
@sonney2k	low dim problems - maybe
 pluskid	sonney2k: can't we compile different modules separately? (Evaluation, Classifier, etc.)
@sonney2k	but ask vojtech :D
 blackburn	oh meeting in a min
 blackburn	:D
@sonney2k	pluskid, yeah we had that - but this was causing lots of grief because modules needed to know types from other modules
 pluskid	hmm...
@sonney2k	pluskid, example is: you need Labels in evaluation
@sonney2k	kernels need features
@sonney2k	machines need features
@sonney2k	etc
@sonney2k	so now we only have shogun/modshogun left
-!- puffin444 [62e3926e@gateway/web/freenode/ip.98.227.146.110] has joined #shogun
 pluskid	I'm not sure, but as long as header files are included properly, they can be compiled separately, aren't they?
@sonney2k	pluskid, but a general tool must exist to split up .cpp files
 pluskid	each module into an .o file, and then link together
@sonney2k	I mean it is not that difficult
 pluskid	hmm...
@sonney2k	pluskid, it is not libshogun that is big
@sonney2k	libshogun compiles in a few sec
@sonney2k	it is the interfaces
@sonney2k	hmmhh so who is missing
-!- cheng [73406f11@gateway/web/freenode/ip.115.64.111.17] has joined #shogun
@sonney2k	cheng
@sonney2k	welcome
 pluskid	yeah, I see swig takes a long time
@sonney2k	(only swig)
@sonney2k	heiko - is arthur joining?
@sonney2k	does anyone know where wiking is / alex binder?
 cheng	Hi sorry to be a bit late
 heiko	sonney2k, I am not sure, I wrote him another email, but he is always very busy during the day
@sonney2k	nicococo, ?
 pluskid	will discuss about this compiling stuff later
@sonney2k	nips deadline yeah
 heiko	sonney2k, yes, I am involved this time aaaah :)
@sonney2k	very good
@sonney2k	cite shogun in you paper
@sonney2k	blackburn, you forgot that last time
 blackburn	sonney2k: what?
 blackburn	what did I forgot?
 pluskid	cite shogun
@sonney2k	so lets wait 1 more minute
@sonney2k	not good that wiking / alex are missing
@sonney2k	let me write them an email
-!- alexlistensagain [c25fae8d@gateway/web/freenode/ip.194.95.174.141] has joined #shogun
@sonney2k	alexlistensagain, ah hey
 alexlistensagain	the captchas in the webchat are very hard gfor me to identify ^^
@sonney2k	alexlistensagain, any idea where wiking is?
 n4nd0	:D damned captchas
 blackburn	sonney2k: I did not forget to cite shogun
@sonney2k	ok then
 alexlistensagain	I will ask viking via mail
@sonney2k	I already asked
 alexlistensagain	maybe he is eating now: 1 PM
@sonney2k	I know gsomix is not joining
@sonney2k	well date is known for 1 month...
@sonney2k	anyways
@sonney2k	lets start
@sonney2k	hello and welcome everyone to our second meeting.
@sonney2k	Before we continue - nico goernitz (nicococo) and alexander binder (alexlistensagain) are here today too. So please introduce yourself. Nico care to start?
@sonney2k	alexlistensagain, could you then? seems nico is asleep.
 alexlistensagain	I am Alex
 alexlistensagain	I am advising Viking (Viktor)
 alexlistensagain	on a project about latent structures SVM
 alexlistensagain	I am doing machine learning and computer vision at TU Berlin
 alexlistensagain	near the end of my PhD (some 120 oages written ;))
@sonney2k	congrats!
 alexlistensagain	if you want something from me pls kick me
@sonney2k	thank alexlistensagain
 alexlistensagain	best is a string of nagging mails
@sonney2k	nicococo, alive now?
 blackburn	alexlistensagain: are you familiar with HOG btw?
 alexlistensagain	yes
@sonney2k	if not then let me give you an update over what happened to shogun in the last 4 weeks
 blackburn	alexlistensagain: hmmm can I ask you some Qs after the meeting?
@sonney2k	With the help of pluskid, n4nd0, wiking, blackburn, heiko and gsomix we made automagic memory (de)-allocations in SGVector, Matrix etc possible.
 alexlistensagain	yes, you can do
@sonney2k	One can now just write x=SGVector<float64_t>(10) to get a vector of length 10 and does not have to take care of de-allocating memory.
@sonney2k	y=x and all that are zero-copy operations and ref-counting is being taken care of underneath.
@sonney2k	So thanks to all for the help in getting this pretty nice system done :-) We still have to convert SGString/List and SGSparseMatrix/Vector to this system but this will be much less intrusive.
@sonney2k	However...
@sonney2k	The probably most intrusive change is that we went from normal double* which machines returned as output to more complex Label objects
@sonney2k	BinaryLabels, MulticlassLabels, RegressionLabels, StructuredOutputLabels,...
@sonney2k	E.g binary labels are now just sign(f(x) aka +1/-1 and have f(x) stored as 'confidences')
@sonney2k	I also want to thank students for staying around in #shogun - only due to that we could quickly render decisions in joint discussions about how things should develop.
@sonney2k	some could be a bit more active / communicative though but hey
@sonney2k	so any questions to that?
@sonney2k	1
@sonney2k	2
@sonney2k	3
 cheng	like!
@sonney2k	4
@sonney2k	...1
@sonney2k	0
@sonney2k	ok
 blackburn	everybody is asleep
 alexlistensagain	I liked it as well
 n4nd0	awake here :P
@sonney2k	then lets continue
 alexlistensagain	we ould have needed labels w structrue anyway
@sonney2k	OK, so GSoC is now officially running since the beginning of this week and you know that you are on track if you (your student) has already committed the first patches related to his work. Recall mid-term evaluations are already due on July 13 - so by then the first part of the work should be done.
 vojtech	sonney2k: does it mean you defined types for output spaces?
@sonney2k	vojtech, better discuss that with nicococo and n4nd0
@sonney2k	afterwards
 vojtech	ok
@sonney2k	vojtech, but more or less ... coffin for SO
 vojtech	I see
@sonney2k	back to topic
 n4nd0	vojtech: that's the plan but it is not looking yet like that :S
@sonney2k	Please note that we don't want one big patch at the end of mid-term/GSoC but many small ones continuously floating in.
 n4nd0	vojtech: we can talk about it later if so
 blackburn	it looks like everybody is waiting for the afterparty
@sonney2k	So maybe each student/mentor combination can quickly state where they are
@sonney2k	what they have been doing and problems they see (of any nature).
@sonney2k	Again if someone is not happy with the work say so either here or to us in private and we see what we can do.
 alexlistensagain	viking started to code something
@sonney2k	alexlistensagain, something sounds like something :)
@sonney2k	I guess with wiking missing you should summarize later
 alexlistensagain	I did not scrutinize it but I have no complaints now
@sonney2k	since everyone has to write short 'I did that' summaries starting from monday to the mailinglist ... I hope we will find out more details
@sonney2k	vojtech, uricamic : want to continue?
 vojtech	well, our plane is to first finalize the plain BMRM using the SOL intefreace of shogun
 vojtech	I don't know if the interface is finsihed?
@sonney2k	vojtech, well it is merged but it will only be finished when your BMRM is merged in there
 vojtech	once we have the template for SOL optimizer we will implement our bundle method in C
 vojtech	currently we have Matlab version
@sonney2k	vojtech, uricamic: so I suggest to have some sub-meeting with n4nd0, nicococo after this session
@sonney2k	to get it done
 vojtech	is there any algorithm using the SOL interface ?
 vojtech	sonney2k: ok, we can discuss the SOL intefrace in a subgroup
@sonney2k	vojtech, n4nd0 wrote a summary here https://iglesiashogun.wordpress.com/
 n4nd0	vojtech, uricamic: I have started a basic algorithm for SO training, is not yet finished though
 vojtech	I read the pdf he sent
 vojtech	I have queastions but maybe it is better for the SOL people
 vojtech	only
 uricamic	n4nd0:  I have read the blog, nice work
@sonney2k	vojtech, n4nd0, uricamic, alexlistensagain I guess you all are affected and so should continue the discussion in a subgroup (after the meeting?)
 n4nd0	uricamic: thank you! let me know about your comments and thoughts
 blackburn	#shogun-sol
 blackburn	:D
@sonney2k	n4nd0, nicococo: so please give us an update :)
 n4nd0	and that ^ is to all in general, it may be better to introduce changes asap
 n4nd0	all right
 n4nd0	so we design the interface for SO learning in shogun
 alexlistensagain	I wanted to discusswith viking where we maybe would like changes in n4ndos framework
 alexlistensagain	will do that today or Tue
 n4nd0	in this post is more or less explained http://iglesiashogun.wordpress.com/2012/05/22/first-weekly-report-gsoc-2012/
 n4nd0	and I think this diagram summarizes it quickly http://iglesiashogun.files.wordpress.com/2012/05/test.pdf
@sonney2k	I guess that is sufficient
@sonney2k	for the general public
 alexlistensagain	thx! n4ndo
@sonney2k	more in the subgroup :)
@sonney2k	great work btw!
 n4nd0	and another thing I would like to say
 n4nd0	yesterday I started to interface mosek from shogun
@sonney2k	puffin444, oliver - would you please continue after n4nd0 is done?
 n4nd0	since we need to account for some constraints in the QP
@sonney2k	n4nd0, ok - thanks
 n4nd0	I am quite unexperienced with mosek, so if any of you have used it before - specially C interface
 n4nd0	it will be great to get some suggestions
@sonney2k	n4nd0, just ask later when you have questions, I did some stuff with cplex' C interface so it should be similar
@sonney2k	puffin444, please continue
@sonney2k	oliver, ...
@sonney2k	^]
 n4nd0	sonney2k: all right, thanks
 puffin444	I have the first weekly milestone tested and ready to be submitted as a patch
 puffin444	ProductKernel
 alexlistensagain	you use productor geometric average?
 ckwidmer	n4nd0, I guess they are using the python interface, but cvxopt has mosek bindings as far as I know, possibly there is something to learn there
@sonney2k	puffin444, ahh btw, please make use of CRegressionLabels in your GP code - we now have confidences in there too so please put them there too
 puffin444	will do
@sonney2k	puffin444, like a combined kernel but with products K(x,y)* K'(x,y) ?
 puffin444	Yes elementwise. It's based off of one in the GPML MATLAB toolbox
 alexlistensagain	well product or geometric average -> this is a question about kernel width treatment
@sonney2k	puffin444, ok
@sonney2k	puffin444, care to update us about your talk?
 puffin444	I will be using GPML to make sure my code is accurate
 puffin444	Yes. I took most of the day Wednesday to travel to Google's offices in Chicago
 puffin444	I was invited to do a lightning talk, lasting only 5 mins (4 slide limit)
@sonney2k	pluskid, cheng maybe you can prepare to be next  after puffin already now.
 puffin444	I was able to present the general idea of GP's and how cool shogun was to the audience :)
@sonney2k	heh
@sonney2k	oliver, do you have any additional comments?
@sonney2k	looks like not
@sonney2k	then thanks puffin444
 oliver	Great that the product kernel works....
 oliver	(rorry slow)
@sonney2k	oliver, anything else?
 oliver	I think it would be good to discuss the framework changes regarding parameter optimization at some point.
@sonney2k	heiko, that's with you I think
 oliver	That does a bit deeper into the shogun internals.
 heiko	ok
 heiko	I started on a framework for statistical tests
 oliver	Yes, would be great if Heiko has some time to sort this out. There were a couple of emails but it needs a real plan.
@sonney2k	oliver, pluskid, heiko maybe you schedule some subgroup meeeint
 heiko	ah sorry
@sonney2k	meeting
@sonney2k	like the SO guys
 heiko	yes
 nicococo	hi all, (back again ..)
@sonney2k	nicococo, we were only saying bad things about you
 oliver	that'd be great.
 nicococo	wonderful
@sonney2k	oliver, heiko, puffin444 maybe directly after the meeting?
 heiko	I am free afterwards but lets talk about this later
@sonney2k	I think we should continue now
 pluskid	ok
 puffin444	I think that's what we are doing
@sonney2k	pluskid, cheng yes
 pluskid	my turn?
@sonney2k	yes
 pluskid	I have typed a lot :D
 pluskid	I have almost finished the ecoclib porting: one encoder and several decoder left, but I don't plan to implement all of them currently because I think too much (similar) choices might confuse users. I'm currently doing a survey for other MC algorithms. I will post a preliminary draft at the weekly report.
 pluskid	for next, I might move on shareboost or one tree style algorithm from JL
 blackburn	one idea
 blackburn	may be some tree?
@sonney2k	excellent work...
 pluskid	I'll discuss with Cheng about that next week
 pluskid	I sent an email to the authors of ShareBoost to ask reference code
@sonney2k	cheng, shareboost was a nips paper last year by shai-shaleve schwhartz
 cheng	I must admit that the credit all goes only to pluskid. I'm sleeping.
 blackburn	TreeMulticlassMachine?
 pluskid	blackburn: Yeah, that's being planed
@sonney2k	I talked to him and they used it in some glasses for blind people to online do ocr
 pluskid	cheng: you suggested a lot of interesting reading for me
 pluskid	yeah, ShareBoost and many of JL's MC algorithms are aimed at large scale problems
 pluskid	with many many number of classes
@sonney2k	I think that is where we need to improve - so any algorithm for that would be great
@sonney2k	almost SO though
 cheng	There is a strange tradeoff, because then there are too few examples per class
@sonney2k	ok, any final comments
 cheng	With SO learning, the classes are somehow similar.
@sonney2k	cheng, pluskid?
 cheng	I'm done
 pluskid	cheng: yes, I saw in one of JL's paper that he is using 10^7 examples and 10^6 classes, then there will be only 10 examples in each class, it looks strange for me
 blackburn	while there are a few experts here
@sonney2k	pluskid, and thanks again for you help in the label / sgvector discussions/transistions. you spent quite some time helping
 blackburn	tell me - is it worth to use some custom distance delta(y_i,y_j) between classes in typical multiclass?
 pluskid	sonney2k: that's because you are soooooooo pushing :D haha
@sonney2k	hehe
 blackburn	cheng: ^ ?
 blackburn	sonney2k: ?
 alexlistensagain	I have seen some work  at ICCV2011 on imagent and large scale learning
 alexlistensagain	on imagenet data
 cheng	blackburn: I think generally it is believed that yes it should help to have custom delta
 pluskid	blackburn: don't know, since we have no structures in the Y space, don't have good knowledge to define a distance other than 0-1
@sonney2k	so next one then blackburn and ckwidmer !
 ckwidmer	well, blackburn has spent some time on fixing up shogun internals and is now working on finishing up Multiclass Domain Adaptation SVM, and will then move back towards merging/implementing stuff from the SLEP package. Also, we'll be merging in some MTL formulation developed with Marius Kloft and nicoco... co.
 cheng	But nobody has shown it to be helpful yet.
 cheng	ckwidmer has some neat paper where they learn similarity between multitask, almost multiclass
 ckwidmer	blackburn, feel free to give more background
 blackburn	hmm
 blackburn	ok
 alexlistensagain	we have also a paper where we learn similarities for multi-task
@sonney2k	blackburn, besides your usual vodka consumption please
 alexlistensagain	and we won a challenge with it :P
 blackburn	sonney2k: yes this week I spent almost all gsoc money for vodka
 blackburn	about SLEP - we were pretty confused with the way it organized
@sonney2k	molotov cocktails D:
 blackburn	but currently it is less or more clear
 vojtech	pluskid: imagine you want to classify people according to age categories, then there is clear structure in Y and 0/1 loss is not good
 ckwidmer	alexlistensagain, which paper is that?
 alexlistensagain	Samek et al CAIP2011 :)
 pluskid	vojtech: ok, that makes sense
 alexlistensagain	its uncionventional
 cheng	ckwidmer, blackburn, alexlistenagain: we've got an ICML 2011 paper where we learn the output kernel. Theoretically nice, practically so so
 blackburn	btw is there anybody interested in inverse covariance estimation?
 alexlistensagain	a general delta loss makes sense whenever one wants to penalize one loss over another
 blackburn	slep has some cool routine for that
@sonney2k	blackburn, ckwidmer I guess that's all from you right?
 ckwidmer	alexlistensagain, cool I'll check it out
 blackburn	yes crappy all
 blackburn	:D
@sonney2k	So then we should decide when we meet next
@sonney2k	how about 26.6. 11 UTC again?
 ckwidmer	cheng, the one with invexity, right?
 blackburn	I am ok with any date
 n4nd0	sonney2k: it is ok for me
 blackburn	except 20 and 14
 cheng	not ideal, but ok
 uricamic	sonney2k: ok for me
 cheng	ckwidmer: yes invexity
 nicococo	its ok
 pluskid	ok
 ckwidmer	fine for me
 heiko	ok
 alexlistensagain	ok by today
 vojtech	26.6. is ok
@sonney2k	OK 26th it is then
 puffin444	June 26th?
@sonney2k	pretty many ok's
@sonney2k	yes
 puffin444	Seems okay to me
 oliver	fine, yes.
@sonney2k	at that next meeting you should have 1st half of your work done
@sonney2k	it is ~1 month till then so plenty time if you work full time
@sonney2k	ahh and btw an update on gsomix's work
@sonney2k	he removed CArray* crap from shogun
@sonney2k	(that was only used in structure/)
@sonney2k	and replaced it with dynarray
@sonney2k	introduced CSet/CMap
@sonney2k	and did lots of cleanups
@sonney2k	and will now do something pretty cool if we get it to work:
@sonney2k	director classes
@sonney2k	i.e., one will be able to overload a shogun method from python
@sonney2k	with a python function
 heiko	that is awesome!
@sonney2k	so for prototyping that is crazily cool
@sonney2k	(think of trying out a new kernel...)
@sonney2k	anyway that's it form us
@sonney2k	from us
@sonney2k	blackburn, anything on your list?
 pluskid	haha, maybe some day shogun is compatible with scikit.learn
 blackburn	no I don't think I have anything
@sonney2k	or any general questions?
 pluskid	any guidelines/conventions for writing the weekly summary?
@sonney2k	pluskid, yeah we can use all scikits stuff too :)
@sonney2k	pluskid, no just *short*
@sonney2k	I prefer you all program on sth not writing reports
 pluskid	sonney2k: haha, then I'll write "see the IRC log"
 cheng	my 2 cents: weekly reports are more for those of us (like me) who don't hang out too much on IRC...
@sonney2k	pluskid, seems like I should push you into a different direction :)
 cheng	and still I think they should be short.
@sonney2k	which reminds me
@sonney2k	mentors, if possible just idle in #shogun too
@sonney2k	students rarely ask you directly
 pluskid	cheng: I see :)
@sonney2k	promised :)
 blackburn	'sorry I have played world of warcraft whole week'
@sonney2k	blackburn, 'world of battleship shogun labels'
 blackburn	that would be awesome weekly report
 alexlistensagain	@blackburn: you cannot, you spent all your money on vodka
 pluskid	blackburn: shouldn't be Diablo III?
 eric___	sonney2k: yes assertion : LibSVM model->nr_class=9 while num_classes=10
@sonney2k	alright then if there is nothing more
@sonney2k	case dismissed
@sonney2k	thank you all for attending
 ckwidmer	thanks, sonney2k
 n4nd0	sonney2k: thanks for organizing!
 eric___	sonney2k: shogun::ShogunException
 cheng	Night!
 alexlistensagain	thanks for organizing Soeren
 n4nd0	it's quite constructive to have these meetings
 blackburn	alexlistensagain: when can I ask you for some advice?
 blackburn	:)
 alexlistensagain	I hve to go in two hours
 alexlistensagain	otherwise I have time
 blackburn	hmm lets switch to /query then?
 oliver	puffin444, heiko: when shall we talk?
 puffin444	can we talk now?
 alexlistensagain	we have to see when the SO subgroup will talk
@sonney2k	eric___, well you call it wrong. but before things didn't get checked: please do obj->io->enable_file_and_line() run the script again
-!- heiko1 [~heiko@host86-180-47-5.range86-180.btcentralplus.com] has joined #shogun
@sonney2k	eric___, and you will see the line number
@sonney2k	heiko1, ^ puffin444, heiko: when shall we talk?
 oliver	Unfortunately I have a meeting now but can be back in ~1h.
 vojtech	alexlistensagain: yes, we should agree on time for So group
 heiko1	i could be there in 1h
 alexlistensagain	so blackburn, just ask me now
-!- heiko [~heiko@host86-185-113-34.range86-185.btcentralplus.com] has quit [Ping timeout: 245 seconds]
 alexlistensagain	if you like
@sonney2k	eric___, what are your labels 0...<nr_classes-1> I hope?
 heiko1	say at 2?
 n4nd0	vojtech: hey! so you asked before something about structure spaces types
 blackburn	alexlistensagain: hm ok I am working on http://benchmark.ini.rub.de/?section=gtsrb&subsection=news for my bachelor's thesis
 puffin444	So 1 UTC?
 eric___	sonney2k: yes, labels 0..9
 oliver	heiko, puffin444: ok - will be back in1h. I am flexible rest of the day...
 puffin444	13 UTC sry
 oliver	yes 1 UTC.
 oliver	great, cu then
 alexlistensagain	ahh, that broken challenge :)
 blackburn	alexlistensagain: why broken?
 vojtech	n4nd0: I need to ready the updated SO document first and then I'd like to ask questions
 alexlistensagain	because people can submit endlessly many results and can see their and others results immediately
 n4nd0	vojtech: ok
 alexlistensagain	then you do not need to do model selection
 blackburn	alexlistensagain: I stucked at 97.1% accuracy - need to improve features
 alexlistensagain	thats why I consider it broken
 vojtech	n4nd0: are you the person to ask ?
 alexlistensagain	ok
 n4nd0	vojtech: I am doing generic SO project so probably yes - I hope I'll be able to answer :)
 blackburn	alexlistensagain: what do you think is good normalization before computing HOGs?
 eric___	sonney2k: error from MulticlassLibSVM.cpp line 102
 n4nd0	uricamic: do you think the structure we have designed for SO fits well for the bundle algorithms you will implement?
 vojtech	n4nd0: 1st quick question: why do you need the generic constraints on w, like A'*w = b ?
 n4nd0	vojtech: ok, so it is nicococo who wrote that pdf
-!- heiko1 [~heiko@host86-180-47-5.range86-180.btcentralplus.com] has quit [Ping timeout: 245 seconds]
 vojtech	n4nd0: do you want to be as generic as possible or is it motivated by some practical SO tasks?
-!- puffin444 [62e3926e@gateway/web/freenode/ip.98.227.146.110] has quit [Quit: Page closed]
 n4nd0	vojtech: and yesterday he told me I should forget about all those constraints
 eric___	sonney2k: the call is from mc Xval function
 vojtech	n4nd0: :)
 nicococo	vojtech: we are actually using those constraints for gene finding application
 n4nd0	vojtech: and just consider Aw <= b and lb <= w <= ub
-!- heiko [~heiko@host86-176-176-185.range86-176.btcentralplus.com] has joined #shogun
 heiko	sorry, connection hazzle :(
 vojtech	nicococo: we also use Aw ,= b constraints
 vojtech	aw<= b
 uricamic	n4nd0: yep, I think it is ok, the only problem could be the regularization-matrix C, I have now the implementation just for a single regularizer
 vojtech	nicococo: but is it possible that some SO solvers will optimize a special instance of the generic SO problem you defined?
 nicococo	vojtech: i think it might not be necessary that every SO solver should be able to handle ALL constraints.. it is fine, if they have their restrictions
 vojtech	nicococo: yes, this is reasonable because exploiting a special (simpler) structure of the SO problem can significantly decree time
-!- cheng [73406f11@gateway/web/freenode/ip.115.64.111.17] has quit [Quit: Page closed]
 nicococo	vojtech: yepp, the solver could give a hint (msg) if it is not compatible with the problem defined.
 vojtech	nicococo: the PDF document also mentioned slack-rescaling loss approximation. is it still the plane? if yes I wonder for which SO tasks you can optimize it?
 nicococo	vojtech: we have a first sketch of slack rescaling for hm-svms, also there is an icml paper 2009
 nicococo	but i don't know if it boosts performance :(
 vojtech	nicococo: I experimented with the PosLearn loss function (ICML 2009) and it does not work for me at all ....
 nicococo	vojtech: i think the bound is really loose
 nicococo	..on page 3 Eqn. (2)
 vojtech	nicococo: I compared the PosLearn loss with margin-rescaling loss on synthetic data and margin-loss clearly wins
 nicococo	uhh..
 vojtech	nicococo: By PosLearn loss I mean the problem on page 4
 nicococo	vojtech: so all constraints get a slack, right?
 vojtech	nicococo: I didn't experiment with the variational approximation of slack-rescaling
 vojtech	yes
 nicococo	so its a bit like max-margin markov networks
 vojtech	I don't think, max-margin MN use standard margin-loss
 vojtech	if you mean papers by Taskar
 vojtech	they just replace the augmented max problem with LP relaxation
 vojtech	you mentioned that ye tried slcak-rescaling for HMMSVM, any results ?
 nicococo	vojtech: right :)
 nicococo	no so far we have no results :(  but at least we know there is a linear time viterbi-style approximation possible..
 eric___	sonney2k: is there a way to print subsets indices (in xval) without recompiling shogun ?
 sonne|work	eric___: heiko is the xval expert (he wrote the code)
 vojtech	nicococo: do you mean the variatinal approximation from the icml2009 paper or something new ?
 nicococo	vojtech: as soon as i have results i can tell you ...
 nicococo	no it is something different
 heiko	eric___ what do you want to do?
 heiko	there is no method for that, so recompiling would be necessary
 nicococo	vojtech: we are solving the argmax delta(1-dPsi) directly
 vojtech	nicococo: it is very interesting. I'll be happy to learn about it ...
 sonne|work	I eric___but I guess in this case you have fewer classes in this data split than in your labels
 heiko	I could add a debug message if you want, eric___
 sonne|work	so no example from class 8 or 9
 nicococo	vojtech: i will have results 1 or 2 weeks after nips deadline (for toy data at least, and compared against margin rescaling)
 eric___	heiko: yes it would be nice
 heiko	k
 heiko	what exctly do you want?
 eric___	heiko: I got some strange results using multiclass xvalid
 heiko	training/testing indices in x-val?
 eric___	heiko: yes
 heiko	ok
 heiko	will do, give me a few minutes
 vojtech	nicococo: thanks
 eric___	heiko: I got always "XVal: [0.100000,0.100000] with alpha=0.050000, mean=0.100000" in mc xval
 nicococo	vojtech: a pleasure :)
 heiko	that means all results were equal
 sonne|work	pluskid: actually weird how can eric___'s assert even be triggered
 nicococo	i have to go to lunch now.. i am starving.. bye
 sonne|work	pluskid: in bool CMulticlassLibSVM::train_machine(CFeatures* data)
 sonne|work	line 40
 n4nd0	nicococo: bye, enjoy your meal!
 sonne|work	you get the number of classes
 eric___	heiko: I cannot send you the features, too big, but when I split the data manually I got mean > 0.7
 sonne|work	which is 9
 sonne|work	and labels have 10 classes
 heiko	eric___, or than there is a problem
-!- nicococo [~nico@lacedcoffee.ml.tu-berlin.de] has left #shogun []
 heiko	might also be because of changes in Labels system
 pluskid	strange
 heiko	I had some problems with that a few days ago
 sonne|work	eric___: what are your labels?
 sonne|work	0...9 ?
 sonne|work	or something else in there?
 eric___	sonne|work: yes
 eric___	sonne|work: digits classes
 pluskid	sonney2k: "labels have 10 classes" <-- is this returned by labels->get_num_classes() ?
 pluskid	the number in the strategy is returned by such a call
 pluskid	in MulticlassMachine.cpp line 60
 sonne|work	pluskid: he has the error (01:50:27 PM) eric___: sonney2k: yes assertion : LibSVM model->nr_class=9 while num_classes=10
 sonne|work	pluskid: in multiclasslibsvm.cpp line 102
 pluskid	so where is model->nr_class calculated?
 eric___	sonne|work: pluskid: m LibSVM model->nr_class=9 while num_classes=10
 sonne|work	pluskid: I guess in libsvm...
 sonne|work	maybe one class is missing
 sonne|work	so he would have labels 0...8,9
 sonne|work	err 0...4,6,...9
 sonne|work	5 missing for example
 pluskid	why missing?
-!- vojtech [9320543b@gateway/web/freenode/ip.147.32.84.59] has quit [Quit: Page closed]
 sonne|work	pluskid: maybe 5 is not in the labels and libsvm checks the actual number of classes ocurring...
 eric___	pluskid: sonne|work: its happen when I call cross->evaluate(). In the same time I run manual split of the base train/test and I don't have any error. Mb it helps ?
 pluskid	sonne|work: but doesn't CLabels->get_num_class check that? it use CMath::unique IIRC
 pluskid	oops, something related to cross validation component?
 eric___	I checked my labels, I have  50 samples; 5 of each classes and my xval is launch with n_folds = 5
 heiko	sonne|work, is there any way to output a vector in only debug mode?
 heiko	because calling SG_DEBUG multiple times always has this ugly [DEBUG] before every element
 sonne|work	heiko: well you can call get_loglevel()
 heiko	perfect :)
 sonne|work	and then only output sth if io->get_loglevel() <= MSG_DEBUG
 sonne|work	pluskid: true then num_classes shouldn't be 10
 sonne|work	hmmhh
 CIA-113	shogun: Heiko Strathmann master * rf377998 / (2 files in 2 dirs): added debug messages for x-val - http://git.io/Yt7J5A
 CIA-113	shogun: Heiko Strathmann master * ra4fd65a / (2 files in 2 dirs): Merge pull request #553 from karlnapf/master - http://git.io/qEEoiw
 heiko	eric___ the indices are now printed
 heiko	I will grab some food now, be back at 2
 eric___	heiko: thx
 eric___	heiko: debug will be easier, I let you know
-!- pluskid [~pluskid@111.120.53.76] has quit [Ping timeout: 256 seconds]
-!- pluskid [~pluskid@li400-235.members.linode.com] has joined #shogun
-!- puffin444 [62e3926e@gateway/web/freenode/ip.98.227.146.110] has joined #shogun
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
 heiko	pluskid, are you there?
 puffin444	Hi Heiko. Is Oliver here yet?
 heiko	hi puffin444, not yet I think
 heiko	ehm, I get all these nicknames mixed up
 heiko	mixed you up with pluskid :)
 puffin444	I confused you with blackburn for  couple of days :)
 heiko	lol :)
 heiko	lets way a few minutes
 heiko	oliver, are you around?
 eric___	heiko: how do I print subsets indices ?
 heiko	eric___, sg_io->set_loglevel(MSG_DEBUG);
 heiko	after shogun init
 heiko	there will be some other stuff poping up too
 eric___	heiko: tx
 heiko	puffin444, what should be discuss?
 puffin444	Do you have a copy of the model selection diagrams I emailed some days ago?
 heiko	Wait I will get it
 heiko	k
 puffin444	so what I had in mind was abstracting away crossvalidation into a machineevaluation class that could do all kinds of different evaluations
 heiko	yes I lked that
 oliver	hi all
 oliver	back now
 oliver	sorry; took a bit longer.
 heiko	oliver, no worries, we just started
 puffin444	GradientOptimization inherits from machineevaluation adding an ability to obtain a gradient, as well as a differentiable function to be optimized
 puffin444	hi oliver
 puffin444	oliver, do you have a copy of the uml diagram I emailed some time back?
 pluskid	I made a list of nickname -> name -> project mapping, but lost that file when I re-install my system... too bad
 heiko	puffin444, why do you need this extra ability to obtain the gradient?
 heiko	this should already be doable via the "evaluate" method
 oliver	yes, have this here.
 heiko	which should be renamed
 puffin444	I thought that only specific forms of evaluation use a gradient, so I put it in a specialized class
 puffin444	Perhaps it makes more sense to put it in MachineEvaluation?
 heiko	what about a method
 sonne|work	pluskid: who's real name do you miss?
 heiko	mmh
-!- uricamic [~uricamic@2001:718:2:1634:5c56:9bc4:b0a1:c02b] has quit [Quit: Leaving.]
 puffin444	A method in MachineEvaluation that returns the gradient?
 heiko	I mean GradienResult already inherits from evaluation result
 heiko	so you could just return it like that
 pluskid	sonne|work: I'm not good at remember names, but I guess I can rebuild the list from the self-intro emails if necessary
 heiko	via the evaluation method
 heiko	and the GradientOptimisation class would then overload that method
 heiko	and return the gradient
 puffin444	Okay, so the gradient is stored in GradientResult
 puffin444	I see where you are coming from.
 heiko	I would like to generalise as much as possible
 puffin444	Does it make sense for GradientOptimization to have its own member called differentiablefunction
 heiko	This evaluation class just returns the quantity that is used for optimisation
 puffin444	okay
 heiko	yes, I think so
 oliver	I am missing a bit the function that is evaluated.
 oliver	Where does this come in?
 puffin444	That is the differentiable function class
 oliver	There is no need for GP methods to focus on marginal likelihood exclusively.
 puffin444	quantity is what is to be optimized, and gradient represents the gradient of the function that returns the quantity
 oliver	yes but why not have "objectiveFunction" which is either "Function" or "DifferentiableFunction"
 oliver	?
 oliver	THere is no need to optimize the marginal likelihood using gradients per se (there are some good reasons to use grids as well in some cases).
 puffin444	So a function that may or may not have gradients?
 oliver	It is merely an option as you can evaluate the gradient...
 oliver	yes]
 heiko	yes, but that is than not handled via the Gradient class
 heiko	but for example by gridsearch
 oliver	I think that is the standard interface an optimizer would use (perhaps worth looking at NLOPT for typical interfaces used in optimization).
 heiko	and for all function we would need a specialisation of MachineEvaluation
 oliver	I see two levels.
 oliver	a) the objective which can be marginal likelihood or classification performance or similar.
 heiko	eg. for the marginal likelihood we have another class that inherits from MachineEval
 heiko	and then this class returns the marginal likelihood via the evaluate method
 heiko	another example is x-val
 oliver	b) The optimization which can be grid based or by means of gradient optimization
 heiko	oliver yes
 heiko	split the objective (gradient, xval, objective) and its optimisation
 oliver	yes, agree
 heiko	Thats why I think all evaluations (whether they are gradients, objective values, or x-val estimates) should be accessible via the MachineEvaluation:evaluate method
 eric___	heiko: can I send your somewhere the debug mess of my xval, you may help me then find the problem ?
 puffin444	Okay, so theres XValidation, GradientOptimzaition, and ObjectiveOptimization that all inherit from MachineEvaluation?
 heiko	eric___, what about rather reproducing the problem in a minimal example? It takes ages for me to get into a large debug mess :)
 heiko	puffin444, yes
 heiko	but remove the optimisation
 heiko	that is happening in another class
 puffin444	Okay.
 heiko	currently only evaluating the criteria for optimisation
 heiko	I am also thinking of a more informative name than MachineEvaluation ... mmh?
 heiko	actually its fine :)
 oliver	yeah...
 oliver	one deatil: for LML it make sense to optimize ont he training set also.
 oliver	I.e. you want a cross validation class that con just carry out a grid search on the training set.
 puffin444	Another question. How will Gradient/Objective get access to the function to be optmized?
 oliver	It's then barely anything else a grid based global optimizer but would be good to have this functinality as gradinet-based stuff runs into
 oliver	local optima quite often.
 oliver	Alternatively one could stick in a global optimizer.
 heiko	oliver, yes, I think there should be a flag in the GridSearchModelSelection class
 oliver	puffin444: What optimizer are you planing to use?
 eric___	heiko: in the same xval run, printed training set indices and testing set indices are the same
 puffin444	Say I want to optimze the likihood using gradient search.
 heiko	eric___, mmmh thats probably multiclass related stuff then, or labels. Could you isolate that in a small program? Then I can check
 puffin444	Should the function be directly set independently of the machine (which seems weird), or should it somehow extract it from the Machine?
 puffin444	*the optimizer
 heiko	puffin444 what do you mean?
 heiko	the differentiable function?
 puffin444	Yest
 puffin444	Yes
 heiko	good question :)
 puffin444	Should the machine have some getter/setter, or should the differential function just be set independently of the machine?
 heiko	It clearly depends on the machine's parameters right?
 heiko	what happens if you would add a get_lh_gradient to the GP base class?
 puffin444	I think so. Theoretically if the differentiable function is independently set, it may not have any relation whatsoever to the machine
 puffin444	which seems silly
 heiko	indeed
 heiko	but this happens when we generalise in these two layers
 heiko	what about obtaining the function from the machine then?
 heiko	mmmh, but thats difficult with types
 oliver	hm... I am confused still.
 heiko	No I think one will have to do it by hand
 puffin444	Okay.
 heiko	but if you got a better solution? you are right its weird that one can set completely different functions
 oliver	Sorry, I missed this earlier. Wat exactly is the purpose of machine evaluation?
 oliver	seems like cross validation and gradientOptimization are fully capable of doing the job on their own.
 heiko	to return the value that you are optimising
 heiko	oliver, MachineEvaluation is the generalisation of x-val
 heiko	which does only evaluate the machine
 heiko	or the gradient on its objective
 oliver	But then MachineEvalaution *is* the function to be optimized.
 eric___	heiko: in the libshogun mcxval example, printed indices for train set 0 and test set 0 are the same.
 heiko	eric___ ok I will have a look little later
 heiko	yes
 oliver	To put the question the other way round: where would the "Gaussian process class" be in this setting?
 heiko	it would be in the machine variable of MachineEvaluation
 heiko	and then either
 eric___	heiko: ok thx
 heiko	a) x-val class is asked for estimate by grid-search
 heiko	b) gradient evaluation class is asked for gradient by GradientModelSelection
 oliver	ok - sorry; I think I got it now ;)
 heiko	both x-val class and gradient eval class are subclasses of machine evaluation class
 oliver	There is a fundamental difference between a/b, right.
 heiko	oliver, yes :)
 oliver	I actually mean: the marginal likelihood can be directly calculated from the GP class, no "evaluation" needed.
 oliver	Any test set error requires the "Machine Evaluation" to wrap around.
 heiko	For that we could add another subclass of MachineEvaluation that returns an objective function
 oliver	yes
 heiko	for the cases where that can be computed instantly
 heiko	and that may then e.g. be called from grid-search opti
 heiko	thats why I think the name evaluation may be misleading
 oliver	true
 heiko	its more a class to generalise different numerical estimates that have to be max/minimised/0ed
 oliver	How about: MachineEvaluation provides the interfaces for either grid-based or graident based optimization (in principle).
 oliver	The different types of evaluations could then just be sub classes.
 oliver	MachienEvaluationMSE
 oliver	MachineEvaluationLML (log marginal likelihood), etc.
 heiko	We have the model selection class
 heiko	which currently has the x-val for evaluation
 heiko	this could be replaced by the MachineEval class
 heiko	and then subclasses of model selection could call the evaluate method of MachineEval
 heiko	then it would be split a bit more
 heiko	and new methods for model selection would only require adding a new subclass of model selection
 oliver	yes, that sounds nice
 oliver	Perhaps useful to think about the workflow of the user.
 heiko	currently, te grid-search works on x-val. With that system it would work with any subclass of MachineEval
 heiko	same for gradient stuff (not implemented yet)
 heiko	would work on gradient of ML as well as on gradient of some SVM-C gradient
 heiko	and this hybrid case grid/gradient would be another instance of ModelSelection that uses both of the other classes
 heiko	yes, it would be nice to have some eas< methods for everything
 heiko	that do all the technical pluggin classes into each other
 heiko	if you look at the current model selection examples, these are pretty complicated
 oliver	Agree, but it is complicated to be general.
 oliver	Nevertheless we need to start somewhere.
 heiko	I think a good starting point is to do this MachineEvaluation class
 oliver	puffin444: perhaps most useful if you start with the general interface to evaluation marginal likelihoods and gradients, but encapsulating them into a general framework of differentiable functions etc.
 oliver	Those would then be "naively" optimizable by calling a gradient optimizer and can in due course be integrated
 oliver	with the heavy machinery...
 heiko	thats a nice idea
 oliver	I think it's good to keep things simple until the gradients are all working / matching and you get results that are compataible with existing libraries.
 puffin444	okay. specific to general
 oliver	FOr debuging the full framework seems a pain....
 oliver	Exactly. Let's make it work first. Simple and pragmatic, but of course having the final solution in mind.
 heiko	oliver, yes thats your part - I currently care about the framework :)
 oliver	sure thing - and that's very much needed!
 oliver	I just know the pain of debugging gradients and figuring out why they don't much what we expect.
 oliver	I think it's key that the basic GP parameter optimization works somehow first.
 heiko	hehe, yes
 heiko	puffin444, you should write a lot of tests for the isolated gradient methods
 heiko	with defined inputs/outputs
 puffin444	By the way, oliver, do you have any concerns about the diagrams about GPs I made some time bach?
 puffin444	keiko: will do
 heiko	shogun lacks that, and its so hard to find errors without it
 puffin444	*back
 blackburn	keiko matsui :D
 puffin444	:) lol
 oliver	puffin444: I think it looks verygood and matches the previous discussions. Definitely a very good start.
 oliver	Not sure down the line whether the GetAlpha stuff for the inference method is general enough.
 puffin444	According to the project plan I will be implementing those in the next few weeks first before modelselection
 heiko	blackburn, everybody asks me if my name is Japanese here in London :) but ITS NOT ITS GERMAN
 oliver	From my experience I think it's best if you get something to work first and then you'll see that several plans need to be adapted here andt here.
 blackburn	well they just pronounce it in a wrong way I guess
 oliver	The same will happen to the framework integration of the optimization.
 heiko	oliver, puffin444, yes the modsel stuff is not really important now
 oliver	but still good to have discussed this.
 heiko	needs to be changed all over a few times anyway (my last years experience :)
 puffin444	I already have for this week the productkernel written and tested.
 puffin444	I just want to make sure there are no memory leaks before I submit it as a patch
 oliver	Nice!
 oliver	But feel free to submit it early. I have time tomorrow to look at things (weekend is generally good).
 puffin444	Well it's on the project plan for this week.
 puffin444	I don't want to get behind! :)
 heiko	oliver, puffin444, thanks for the discussion, I gotta go now (studygroup for exam)
 puffin444	Thanks for your time, heiko.
 oliver	great, thanks for inputs.
 oliver	and talk soon.
 heiko	take care everybody!
 heiko	bye
 puffin444	oliver, if you don't mind, I would like to go back to bed.
 puffin444	bye
 oliver	ok, sure - bye!
 puffin444	thanks for taking time for this meeting, oliver.
 oliver	Perhaps let's try to talk sometime soon again.
 puffin444	Absolutely. What time would be good for you?
 oliver	I am around over the weekend...
 oliver	tomorrow is perfect; next week I am travelling quite a bit but certainly can come online here and there.
 puffin444	What time tomorrow would be good?
 oliver	UTC 8 am-UTC4 pm
 oliver	Just write me an email
 puffin444	I will.
 puffin444	See you all later
 oliver	cu
-!- oliver [c07c1afb@gateway/web/freenode/ip.192.124.26.251] has quit [Quit: Page closed]
-!- puffin444 [62e3926e@gateway/web/freenode/ip.98.227.146.110] has quit [Quit: Page closed]
-!- alexlistensagain [c25fae8d@gateway/web/freenode/ip.194.95.174.141] has quit [Quit: Page closed]
 CIA-113	shogun: Heiko Strathmann master * r07554b5 / src/shogun/evaluation/CrossValidation.cpp : corrected debug message - http://git.io/PHWNRA
 CIA-113	shogun: Heiko Strathmann master * r43b5b5e / src/shogun/evaluation/CrossValidation.cpp : Merge pull request #554 from karlnapf/master - http://git.io/u6eoPw
-!- heiko [~heiko@host86-176-176-185.range86-176.btcentralplus.com] has left #shogun []
 eric___	sonne|work:  is it possible to enable [DEBUG] messages without [INFO] ones
 CIA-113	shogun: Soeren Sonnenburg master * r1de9b14 / (32 files): fix java modular examples - http://git.io/8T7fkQ
 blackburn	sonney2k: alex helped me to overwhelm 97.00% curse! :D
-!- eric___ [2e1fd566@gateway/web/freenode/ip.46.31.213.102] has quit [Quit: Page closed]
-!- pluskid [~pluskid@li400-235.members.linode.com] has quit [Quit: Leaving]
-!- cwidmer [~chris@HSI-KBW-046-005-237-106.hsi8.kabel-badenwuerttemberg.de] has joined #shogun
-!- ckwidmer [~chris@HSI-KBW-046-005-237-106.hsi8.kabel-badenwuerttemberg.de] has quit [Ping timeout: 246 seconds]
-!- gsomix [~gsomix@178.45.68.181] has joined #shogun
 gsomix	hi all
 gsomix	home, sweet home
 gsomix	"@SpaceX #Dragon capsule securely bolted to the Harmony module of the #ISS at 12:02pmET!"
 gsomix	ok, time to work
-!- cwidmer [~chris@HSI-KBW-046-005-237-106.hsi8.kabel-badenwuerttemberg.de] has quit [Read error: Operation timed out]
-!- ckwidmer [~chris@HSI-KBW-046-005-237-106.hsi8.kabel-badenwuerttemberg.de] has joined #shogun
@sonney2k	blackburn, to get what?
 blackburn	sonney2k: to get what?
 blackburn	:)
 blackburn	I do not understand
@sonney2k	97.00001%
@sonney2k	?
 blackburn	hah no
 blackburn	97.58
@sonney2k	heh
 blackburn	sonney2k: btw I have interesting problem here
 blackburn	we lost information about outputs in multiclass machine
 blackburn	so we can't plot OvR ROC currentyl
@sonney2k	blackburn, ehh? we never had outputs in multiclassmachine
@sonney2k	just 0,1,...
 blackburn	sonney2k: yes but need to have
-!- gsomix_ [~gsomix@109.169.139.36] has joined #shogun
-!- gsomix [~gsomix@178.45.68.181] has quit [Read error: Connection reset by peer]
@sonney2k	blackburn, with new labels you can store confidences
@sonney2k	so feel free to add the max f(x) ..
 blackburn	yes but one vector = # class confidences
 blackburn	it won't help to plot ROC
 CIA-113	shogun: Soeren Sonnenburg master * rf96fdfa / (24 files in 2 dirs): fix c# and ruby example to work with new SGVector - http://git.io/u50cgw
@sonney2k	blackburn, you can always overload the confidence system for multiclass...
 blackburn	he
@sonney2k	it can be huge though
@sonney2k	blackburn, while I am away - we need more coverage of our examples in languages other than python
 blackburn	while you are away?
@sonney2k	well beginning of june
 blackburn	ah
@sonney2k	it would make a lot of sense to get all the octave_modular etc examples updtaed with what we have in python
 blackburn	should be easy but takes time
@sonney2k	no difficult task and I think one can do 1-2 langueages per day
@sonney2k	and I think it is actually partially interesting
@sonney2k	I mean learnign the basics of 5 $LANG :)
@sonney2k	man the buildbot is overloaded
 blackburn	97.67!
 blackburn	:D
@sonney2k	blackburn, what is the secret ingredient?
 blackburn	C :D
@sonney2k	you didn't do model selection?!?
@sonney2k	c'mon!?
 blackburn	sonney2k: I do not have to do model selection - I know correct results
@sonney2k	???
 blackburn	I just fit C for best accuracy :D
@sonney2k	that is what one calls modelselection
@sonney2k	gridsearch in shogun :)
 blackburn	no I have test/train features and labels
@sonney2k	exactly
 blackburn	okay actually I am changing features
-!- gsomix_ is now known as gsomix
@sonney2k	??
@sonney2k	C is not the C of the SVM?
 blackburn	??! :D
 blackburn	yes I vary over C
 blackburn	but actually I changed features
 blackburn	oook I need 98%!
 blackburn	:D
 CIA-113	shogun: Sergey Lisitsyn master * reac2e3c / (5 files in 2 dirs): Added rejection strategy handling to multiclass machine - http://git.io/EKOONQ
-!- gsomix [~gsomix@109.169.139.36] has quit [Quit: Ex-Chat]
 CIA-113	shogun: Sergey Lisitsyn master * ra077bd5 / src/shogun/multiclass/RejectionStrategy.h : Fixes for Qtest rejection strategy - http://git.io/yrKL2g
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- ckwidmer [~chris@HSI-KBW-046-005-237-106.hsi8.kabel-badenwuerttemberg.de] has quit [Remote host closed the connection]
@sonney2k	blackburn, yet another toolbox https://github.com/davidpicard/jkernelmachines/wiki
@sonney2k	we should probably make sure we have all the kernels they have :)
 blackburn	WTF is adaptative
 blackburn	:D
 blackburn	sonney2k: looks like useless crap at the very first sight
@sonney2k	yeah indeed
 blackburn	sonney2k: my Q-test idea failed it seems
 blackburn	:D
@sonney2k	hmmh the buildbot has no chance to catch up it seems...
@sonney2k	Q-test?
 blackburn	yes I tried to determine rejects according to Q-test for outlier detection
 blackburn	i.e. if score can be considered as outlier
 blackburn	it should not be rejected
 blackburn	else reject
 blackburn	like [3.0,0.1,0.2] - not reject and [0.3,0.1,0.2] - reject
@sonney2k	ok
@sonney2k	makes sense
@sonney2k	anyway
@sonney2k	tme to slep
@sonney2k	:D
@sonney2k	oh swig 2.0.6  release
@sonney2k	d
 blackburn	sonney2k: slep?
 blackburn	yes right
 blackburn	time to SLEP
 blackburn	:D
 shogun-buildbot	build #560 of java_modular is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/java_modular/builds/560
--- Log closed Sat May 26 00:00:41 2012
