--- Log opened Mon Apr 09 00:00:19 2012
 PhilTillet	blackburn, I rebased all my commit cause I thought one would be clearer, was it a mistake? (it seems to me that the big commit made things more unclear than anything else :p)
 blackburn	yeah probably no need to do that
 blackburn	however not so bad
 PhilTillet	blackburn, this year, the ViennaCL GSoC Idea is on solving the Eigenvalue Problem on GPU :p So in september it should be possible to integrate Hardware Accelerated dimension reduction into Shogun.
 blackburn	hmm nice
 blackburn	PhilTillet: are you applying for viennacl as well?
 PhilTillet	blackburn, no, I applied this year but to be honest was rejected (3 slots for 70 applications :D)
 PhilTillet	but I ended up working directly with Technical University of Vienna
 PhilTillet	to another "Summer of Code", but organized directly by their university
 blackburn	ah I see
 blackburn	you mean you applied last year?
 PhilTillet	(this is how I was able to write a paper etc..)
 blackburn	why didn't you applied this year then?
 PhilTillet	Cause I wanted to do machine learning
 PhilTillet	:p
 blackburn	I see
 PhilTillet	there was not a lot of C++/Machine Learning projects :p
 blackburn	one I guess
 PhilTillet	yes, did not find any other organization
 PhilTillet	well to a smaller extent there was also OpenCV, but their main focus is not Machine Learning
 PhilTillet	blackburn, yes, I mean I applied last year earlier (didn't notice the typo :p)
 PhilTillet	only applying for Shogun this year..
 PhilTillet	I think I'm gonna listen to some Azis and then go to bed YaY
 blackburn	lol
 PhilTillet	last year this was the Rebecca Black period
 PhilTillet	http://www.youtube.com/watch?v=kfVsfOSbJY0
 blackburn	oh that is too gay
 PhilTillet	she said in an interview that she was crazy about Justin Bieber :D
 blackburn	oh that is awful song
 blackburn	:D
 PhilTillet	The best is the lyrics :D
 blackburn	her voice is $#$#@
 PhilTillet	"Yesterday was thursday, today is Friday, tomorrow is Saturday, and Sunday, comes afterwards"
 blackburn	we gonna have a ball today
 blackburn	wtf
 blackburn	are they talking about balls?
 blackburn	:D
 PhilTillet	I don't  know :D I have to admit that it sounds like
 PhilTillet	Indeed the official lyrics are "we gonna have a ball today".
 blackburn	I am not any adult but this is way too 'teenagy' :D
 PhilTillet	:D
-!- harshit_ [~harshit@182.68.113.64] has joined #shogun
 harshit_	blackburn: Hi !
 blackburn	hi
 harshit_	hey, I havn't done any thing in last 2 days, as in related to shogun
 harshit_	coz not able to fully understand what needs to be done in LBP features
 blackburn	may be I can suggest anything else?
 harshit_	blackburn: Could you suggest me somewhat easier task to do in mean while
 blackburn	aham
 harshit_	Do you want to see s3vm in shogun ?
 harshit_	or co-clustering
 harshit_	or any other semi-supervised learning algo
 blackburn	why not if it is easier :)
 harshit_	So first step would be to find a functional library..
 harshit_	Also I think I have a small experience with Classifiers so that would be easy ..
 harshit_	blackburn: I'll mail you some of the implementations of S3VM tomorrow, plz have alook and tell me whether it would worth for me to spend time on it !
 harshit_	For now,Bye
 blackburn	ok sure
 blackburn	bye
-!- harshit_ [~harshit@182.68.113.64] has quit [Quit: Leaving]
 PhilTillet	blackburn,  where are you from by the way?
 blackburn	blackburn: samara just like genix
 PhilTillet	oooh you are neighbours :p
 PhilTillet	and what time is it there??
 blackburn	yes
 blackburn	03-18
 blackburn	I shall go to bed probably :D
 PhilTillet	:D
 PhilTillet	I think people are always more productive during night
 blackburn	yeah probably
 blackburn	however I still need to wake up in 6 hrs
 blackburn	and will be non-productive next morning :)
 PhilTillet	that's a point :D
 blackburn	okay see you
 PhilTillet	see you
 blackburn	it is night in france as well so good night :)
-!- blackburn [~qdrgsm@83.234.54.186] has quit [Quit: Leaving.]
-!- PhilTillet [~Philippe@vir78-1-82-232-38-145.fbx.proxad.net] has quit [Quit: Leaving]
-!- wiking [~wiking@huwico/staff/wiking] has quit [Quit: wiking]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has joined #shogun
-!- V[i]ctor [~victor@host-176-100-246-254.masterbit.su] has joined #shogun
 n4nd0	blackburn: let's see if I succeed with the cover tree mission :P
 blackburn	n4nd0: oh that's painful
 blackburn	damn ich moechte shlafen
 n4nd0	blackburn: are you tired?
 blackburn	yeah want to sleeep
 n4nd0	blackburn: first I am going to test if JL's implementation is actually faster using their tests and comparing to our unbeatable quick sort :)
 blackburn	you should note that as I said before qsort is slower in the lle
 n4nd0	yes
 blackburn	that is something impossible actually - it seems that in your test
 n4nd0	yeah ... I don't understand why it turns out to be faster in LLE
 blackburn	qsort had something like O(Nlog N)
 n4nd0	there is something fishy
 blackburn	it is true but there are N vectors or so
 blackburn	so it should be O(N^2 log N)
 n4nd0	cover tree?
 n4nd0	what do you mean it should be O(N? log(N))?
 blackburn	in the LLE at least
 blackburn	I mean if there are N vectors
 blackburn	and we need a neighbor for each of them
 blackburn	it would be N*O(N log N)
 blackburn	with qsort
 blackburn	and should be N*O(log N) with covertree
 n4nd0	yes
 n4nd0	but I guess that the implementation of our tree is not that efficient
 n4nd0	or?
 blackburn	yes but O should stay the same
 blackburn	if it is not log N - wtf it is not a covertree then :D
 blackburn	however it can be that
 n4nd0	that's why I want to make this test using JL's impl. first
 n4nd0	if quick sort is still slower, we better ignore  it
 blackburn	makes sensse
 blackburn	hmm I'm curious whether they will wake me up if I fall asleep lool
 n4nd0	haha
 n4nd0	are you in the job?
 blackburn	yeah
 blackburn	I'm going to leave it actually
 blackburn	in june
 n4nd0	you focus on GSoC then
 blackburn	right
 n4nd0	have to go now
 n4nd0	bye
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Remote host closed the connection]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- PSmitAalto [82e9b263@gateway/web/freenode/ip.130.233.178.99] has joined #shogun
 blackburn	wiking: have you seen lecun's paper on EBM?
 blackburn	energy based models
 wiking	i've seen one energy based model
 wiking	but i'm not sure if it's the same
 wiking	do u have full title or link?
 blackburn	yeah
 blackburn	http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf
 blackburn	it looks like kind of generalization for all the latent and SO stuff
 wiking	i have this among my papers on my comp: Efficient Learning of Sparse Representations with an Energy-Based Model
 blackburn	https://groups.google.com/forum/?fromgroups#!forum/google-summer-of-code-discuss
 blackburn	whoa how stupid it is
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has quit [Ping timeout: 245 seconds]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has joined #shogun
 wiking	sonney2k: here?
-!- wiking_ [~wiking@78-23-191-201.access.telenet.be] has joined #shogun
-!- wiking_ [~wiking@78-23-191-201.access.telenet.be] has quit [Changing host]
-!- wiking_ [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking_ [~wiking@huwico/staff/wiking] has quit [Remote host closed the connection]
-!- wiking_ [~wiking@vpnb172.ugent.be] has joined #shogun
-!- wiking_ [~wiking@vpnb172.ugent.be] has quit [Changing host]
-!- wiking_ [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Ping timeout: 245 seconds]
-!- wiking_ is now known as wiking
-!- PhilTillet [~Philippe@vir78-1-82-232-38-145.fbx.proxad.net] has joined #shogun
 PSmitAalto	Hey All
 n4nd0	PSmitAalto: hey!
 PSmitAalto	I am trying to get a MKLMultiClass to work, but for now I'm getting quite bad results
 PSmitAalto	What is a good strategy for setting the right epsilon, mkl_epsilon and mkl_norm
 n4nd0	PSmitAalto: ok, I have not used myself so probably I am not the best to give suggestions but
 n4nd0	have you tried using model selection for that?
 blackburn	PSmitAalto: in which means it is bad?
 PSmitAalto	No I haven't tried to use model selection.
 PSmitAalto	The results are worse than training an svm on a single feature
 blackburn	I see. however I am not a mkl expert as well
 blackburn	my suggestion is to ask about that using mailing list
 blackburn	IIRC alex binder reads it and could answer
 PSmitAalto	Ok, I'll do that
 PSmitAalto	Thanks anyway!
 blackburn	you may also glance over mkl paper
 blackburn	http://jmlr.csail.mit.edu/papers/volume12/kloft11a/kloft11a.pdf
 PSmitAalto	That is even better! I'll go through that one first
 PhilTillet	hello everybody
 blackburn	hey
 wiking	:>
 wiking	let's see if i'm gonna have the same troubles with mkl
 blackburn	yeah. @PSmitAalto wiking is on the same way as you trying some mkl stuff
 wiking	PSmitAalto: i'll be having results within 20 mins
 blackburn	genix: here?
 PSmitAalto	Ok, nice
 genix	blackburn, yep
 genix	hi all
 blackburn	genix: small task
 blackburn	genix: do you know how does sg_progress stuff work?
-!- genix [~gsomix@188.168.13.216] has quit [Ping timeout: 260 seconds]
 blackburn	oh he is afraid of sg_progress probably *lol*
 n4nd0	:D
-!- genix [~gsomix@85.26.165.173] has joined #shogun
 blackburn	n4nd0: once you are finished with covertree I can suggest you some framework stuff as well (some simple memory measurement system)
 blackburn	memory usage*
 genix	blackburn, what up?
 genix	*s
-!- genix is now known as gsomix
 blackburn	gsomix: I was asking you if you are acknowledged how SG_PROGRESS works
 blackburn	are you?
 gsomix	blackburn, no, I am not
 blackburn	https://github.com/shogun-toolbox/shogun/blob/master/src/shogun/classifier/ConjugateIndex.cpp
 blackburn	line 134
 blackburn	it is used to indicate the reached progress
 blackburn	to start with you could add similar stuff there:
 blackburn	https://github.com/shogun-toolbox/shogun/blob/master/src/shogun/classifier/GaussianNaiveBayes.cpp
 gsomix	blackburn, hm, ok.
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Ping timeout: 276 seconds]
 gsomix	blackburn, how can I check the current progress?
 gsomix	ah, stop
 gsomix	I figured out
 blackburn	gsomix: http://pastebin.com/ifFsCG5c
 blackburn	use something like that
 gsomix	ok
 blackburn	however that would be too fast
 blackburn	increase N and number of classes
 blackburn	currently it would be 50% and 100% only
 blackburn	gsomix: a little more ambiguous is to progress some svm solvers
-!- genix [~gsomix@188.168.14.52] has joined #shogun
-!- gsomix [~gsomix@85.26.165.173] has quit [Ping timeout: 246 seconds]
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
 n4nd0	blackburn: hey! what is that framework for memory measurement you were talking about?
-!- pluskid [~chatzilla@111.120.9.128] has joined #shogun
 blackburn	n4nd0: I think that would be nice to have some system that measures memory usage
 blackburn	i.e. you could get how much time classifier ate while training
 blackburn	or applying
 blackburn	err no time
 blackburn	memory
 blackburn	pluskid: want simple task?
 n4nd0	blackburn: haha you are with ideas today :)
 blackburn	yes
 blackburn	*nothing to do at job*
 n4nd0	blackburn: :D do you have something particular in mind / somewhere you have seen something similar before?
 blackburn	not really
 blackburn	ok the idea is rather simple
 blackburn	but could be extended seriously
 blackburn	n4nd0: simplest way is to add SG_MALLOC_N or so
 blackburn	it could store name of block
 blackburn	however I don't really like it
 blackburn	better would be to add new class
 blackburn	and each malloc should add memory usage info to it
 blackburn	once you have some get_memory_stats method in SGObject you can check all you need
 n4nd0	blackburn: I think I understand the idea
 pluskid	blackburn: what's that?
 blackburn	n4nd0: however better try to finish covertree - would be useful
 blackburn	pluskid: https://github.com/shogun-toolbox/shogun/blob/master/src/shogun/classifier/GaussianNaiveBayes.cpp currently it uses whole training matrix to train
 blackburn	shouldn't be so
 pluskid	what's the difference between a Gaussian NB and an ordinary NB?
 pluskid	OK
 pluskid	I find the doc
 pluskid	I'll look at it
 n4nd0	blackburn: yes, I am going to devote some work to cover tree
 n4nd0	blackburn: but I think it will take me some effort
 blackburn	pluskid: it assumes that features are continuous and gaussian distributed
 n4nd0	the code is a total mess to be honest
 blackburn	pluskid: no way to use NB with continuous variables you know
 blackburn	(if you don't know distribution)
 pluskid	yeah
 blackburn	n4nd0: yeah but it is the reality - svm solvers are not much better I think
 n4nd0	blackburn: it is good to get training in this aspect too :)
 n4nd0	and even if I complain, this must be better than starting from scratch
 blackburn	hah sure
 blackburn	writing covertree from scratch would be a headache
 pluskid	blackburn: you mean should not get the whole matrix in a whole, but use get_computed_dot_feature_vector one by one?
 blackburn	pluskid: exactly
 pluskid	ok
 n4nd0	blackburn: don't you think that these cases of computing the whole matrix or re-computing features
 n4nd0	blackburn: something similar to SPE with the distance matrix
 n4nd0	blackburn: should be done in both ways?
 blackburn	n4nd0: yes and again my code
 blackburn	ah
 blackburn	there - not really
 n4nd0	blackburn: why?
 blackburn	it is not really faster to compute whole matrix
 n4nd0	blackburn: do you think so?
 blackburn	yes - that should be the same
 n4nd0	mmm I thought it should be faster
 blackburn	in case of simple features and available feature matrix
 blackburn	no difference to get feature vector or to get feature matrix
 blackburn	just pointer right?
 blackburn	n4nd0: btw that gnb is really fast
 blackburn	you could try on that data I gave to you
 n4nd0	blackburn: Gaussian Naive Bayes?
 blackburn	n4nd0: yes
 blackburn	that thing was written by me when I was young^W applying for gsoc 2011 btw
 n4nd0	blackburn: my point with the feature / distance matrices is that if we don't pre-compute them, some things may be computed several times
 n4nd0	blackburn: haha are you old already :P
 blackburn	n4nd0: well yes but it is cost of doing some large-scale applicable stuff
-!- genix is now known as gsomix
 n4nd0	blackburn: yes, but that is why I think that it could be better to offer both possibilities
 n4nd0	in some application it can be interesting to compute the whole matrix, in some others not
 blackburn	n4nd0: anyway in the stuff you did it is ok to use callback
 blackburn	because callback can access precomputed stuff as well
 n4nd0	e.g. for using the cover tree, pluskid measured that there where lot of acceses to distances
 blackburn	err not callback - virtual function
 blackburn	code would be messy if you would support matrices as well
 n4nd0	we can make in transparent using a class and overloading '()'
 n4nd0	don't you think so?
 n4nd0	I think that override may be a better word here
 blackburn	why don't you like ->distance(i,j)?
 n4nd0	I like it
 n4nd0	that's why I mean the code would not turn to be a mess
 n4nd0	the difference would be that actually
 blackburn	I mean it already supports precomputing
 n4nd0	distance(i,j) would do inside
 n4nd0	distance_mat[i + N*j] if the matrix is precomputed
 n4nd0	or compute the distance between features i and j otherwise
 blackburn	n4nd0: yes so what you want to change?
 n4nd0	blackburn: add and option as a class member that allows to do this selection
 n4nd0	blackburn: what do you think?
 blackburn	n4nd0: it is manageable already with customdistance/kernel
 blackburn	look
 blackburn	https://github.com/lisitsyn/shogun/blob/libedrt/src/shogun/converter/LocallyLinearEmbedding.cpp
 blackburn	line 176
 blackburn	here I added that stuff with no option but it is rather easy to change
 n4nd0	ok
 blackburn	option should be there but it should not be handled with anything but Custom*
 blackburn	n4nd0: so no need to modify distance stuff
 n4nd0	by CustomKernel?
 blackburn	kernel or distance
 blackburn	however there should be some caching I think
 blackburn	i.e. it would be nice to have function that caches distances to neighbors
 blackburn	I will add one later I think
-!- pluskid [~chatzilla@111.120.9.128] has quit [Quit: ChatZilla 0.9.88.2 [Firefox 11.0/20120314124128]]
-!- pluskid [~chatzilla@173.254.214.60] has joined #shogun
-!- PSmitAalto [82e9b263@gateway/web/freenode/ip.130.233.178.99] has quit [Quit: Page closed]
 n4nd0	blackburn: did you try JL covertree?
 blackburn	n4nd0: no I thought you will :D
 n4nd0	blackburn: haha yes, I am doing it
 pluskid	here comes the pull request
 n4nd0	blackburn: it was to compare opinions
 n4nd0	blackburn: I am surprised about the time it takes to construct it
 n4nd0	blackburn: here it seems that it is constructed in 0.178523 seconds using 37749 vectors
 blackburn	pluskid: I will be able to merge it within 1-2hrs
 blackburn	n4nd0: wow nice
 n4nd0	blackburn: that is quite different from the time of the other day with the other tree
 blackburn	not 423432423 seconds dncrane's did
 pluskid	blackburn: ok, I'll back to LARS then
 pluskid	tell me if there's any problems
 blackburn	sure
 blackburn	pluskid: thanks!
 pluskid	u r wel
 blackburn	I think I need to update news today
 pluskid	so?
 blackburn	to include all your (gsocers) contributions
 pluskid	on the homepage?
 blackburn	no, in repo
 pluskid	didn't see it
 pluskid	is there a NEWS file in the repo?
 blackburn	https://github.com/shogun-toolbox/shogun/blob/master/src/NEWS
 pluskid	oh, got it!
-!- PhilTillet [~Philippe@vir78-1-82-232-38-145.fbx.proxad.net] has quit [Remote host closed the connection]
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has quit [Quit: Page closed]
-!- shogun-buildbot [~shogun-bu@7nn.de] has quit [Ping timeout: 245 seconds]
-!- shogun-buildbot [~shogun-bu@7nn.de] has joined #shogun
 n4nd0	shogun-buildbot: did you get tired of IRC?
-!- shogun-buildbot [~shogun-bu@7nn.de] has quit [Ping timeout: 245 seconds]
-!- shogun-buildbot [~shogun-bu@7nn.de] has joined #shogun
-!- PhilTillet [~android@92.90.16.70] has joined #shogun
-!- PhilTillet [~android@92.90.16.70] has quit [Ping timeout: 260 seconds]
@sonney2k	n4nd0, hmmhh we have memory tracing already...
@sonney2k	can be enabled with --enable-trace-mallocs IIRC
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Read error: Operation timed out]
@sonney2k	wiking, whats up?
 wiking	sonney2k: i wanted to ask some stuff about mkl
@sonney2k	ask
@sonney2k	(I hate mkl btw)
 wiking	ahahhaha cool
@sonney2k	close to useless crap :D
 wiking	your name is on the paper :)))
 wiking	since now i have like really different kind of features that's why i thought that it'd be great to use it
 wiking	you reckon it's really wouldn't make a much of a difference?
@sonney2k	wiking, well you can even use different features without mkl
@sonney2k	just use several kernels
 wiking	well yeah i've tried that
@sonney2k	with shogun
@sonney2k	(CombinedKernel)
 wiking	mmm
 wiking	but can i just chuck in a combined kernel
 wiking	to any solver?
 wiking	since now i'm just trying to follow the example from the tutorials
 wiking	i've following: ../examples/documented/python_modular/mkl_multiclass_modular.py
 gsomix	sonney2k, moin. how are you?
@sonney2k	wiking, any kernel machine yes
@sonney2k	wiking, the mkl stuff is only to learn the weights in front of the linear combination
 wiking	mmm but i guess the only difference then is that it doesn't compute the weighting i guess...
@sonney2k	yes
@sonney2k	and actually the weighting can make things worse - or better - depending on your problem :D
@sonney2k	gsomix, tired - watched demos too long tonight
 wiking	oh great
 wiking	then first i just check out a simple combined kernel stuff
@sonney2k	my experience is that mkl_norm=2 can help
@sonney2k	(a tiny bit)
 wiking	ehehhe ok will give it a go as well
 wiking	it's just that i think a combined kernel must give me a better result
@sonney2k	it usually is better to work on actual features, do fine grained model selection etc
@sonney2k	wiking, usually yes
 wiking	than concatenating each feature and using one type of kernel on it
@sonney2k	but you have to normalize data / kernels
 wiking	since the features are really different in nature...
@sonney2k	and that itself can be tricky :D
@sonney2k	and mkl won't help you with this either...
 wiking	hehehehe
 wiking	ok let's see how it works out
 wiking	i'm just still having fun with loading the features into shogun in a good way
 wiking	since they are in various formats :)
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Ping timeout: 276 seconds]
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
-!- V[i]ctor [~victor@host-176-100-246-254.masterbit.su] has quit [Quit: Leaving.]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- PhilTillet [~Philippe@157.159.42.154] has joined #shogun
 PhilTillet	Hi hi
 n4nd0	sonney2k: hey! how is it going?
 n4nd0	sonney2k: so we have already memory management implemented in shogun?
-!- nickon [~noneedtok@dD5774105.access.telenet.be] has joined #shogun
-!- V[i]ctor [~victor@host-176-100-246-254.masterbit.su] has joined #shogun
 wiking	doh i'm doing something wrong
 wiking	[ERROR] Index out of Range: idx_a=0/0 idx_b=0/0
 wiking	oh i know what :>
 wiking	sonney2k: still around? i just wonder for example in the case of ../examples/documented/python_modular/kernel_combined_custom_poly_modular.py
 wiking	why do you create twice the CombinedKernel....
 wiking	wouldn't it be enough to create it once...? and then just use different kernel.init calls?
-!- pluskid [~chatzilla@173.254.214.60] has quit [Quit: ChatZilla 0.9.88.2 [Firefox 11.0/20120314124128]]
-!- PhilTillet [~Philippe@157.159.42.154] has quit [Remote host closed the connection]
 wiking	is there a function for merging/concatenating simple features?
-!- PhilTillet [~Philippe@157.159.42.154] has joined #shogun
@sonney2k	n4nd0, well one can list blocks of memory that are allocated
@sonney2k	n4nd0, so everything that SG_MALLOC etc allocates can be traced when ./configure --enable-trace-mallocs is on
@sonney2k	wiking, use CCombinedDotFeatures
@sonney2k	then you can mix dense, sparse, xxx features
@sonney2k	and use any e.g. linear classifier with it
@sonney2k	or if you want to mix any kind of feature types, CCombinedFeatures
@sonney2k	wiking, yes one kernel is sufficient
 PhilTillet	sonney2k, I have a question :D Why isn't the Gaussian Kernel implemented as a CDistanceKernel?
 wiking	sonney2k: heheh yeah i've tried with one kernel and worked... i'm trying now combined kernel but i want some of my features to be handled by one type of kernel, that's why i want to concatenate some features
 wiking	ah i see append_feature_obj should work for CCombinedDotFeatures
-!- harshit_ [~harshit@182.64.221.94] has joined #shogun
 wiking	mmm i've found NormOne preprocessor but is there NormTwo, or NormN for that matter ? as i cannot find it :(
 harshit_	n4nd0: hola ! , wassup .!
 gsomix	http://piccy.info/view3/2869209/689d46487f8b6162bd1c6c1534b630f9/ Samara city... =___=
 n4nd0	harshit_: hey! how is it going?
 wiking	n4nd0: yo
 V[i]ctor	hi!
@sonney2k	wiking, no
 wiking	sonney2k: mmm i guess then it's time to have one :)
@sonney2k	heh
 wiking	can it go as preprocessor ? just like in case of NormOne ?
@sonney2k	wiking, look at what normone does
 wiking	yep i've checked
@sonney2k	not sure what you want to do...
 wiking	well what if i want norm-2
 n4nd0	wiking: hey
 wiking	so the euclidean norm
 wiking	or any p-norm for that matter... where p>=1
 wiking	that's why i thought having a NormP preprocessor would be good... which by defaults calculates the 2-normalized vectors of a feature matrix...
 harshit_	n4nd0: good here :)
 harshit_	n4nd0: Do you have any experience with semi supervised algos ?
 n4nd0	harshit_: I have studied some EM stuff but I think that fits better in unsupervised
 n4nd0	harshit_: at least that's the way I remember I studied it
 harshit_	yeah EM is mostly unsupervised, have a look at the mail I sent
 harshit_	If you have any idea about those implementations, do tell me
 CIA-64	shogun: pluskid master * r1179258 / (3 files in 2 dirs): GNB: replace SGVector with SGMatrix to make the code easier to read. - http://git.io/hoqSCA
 CIA-64	shogun: pluskid master * rf87cd67 / src/shogun/classifier/GaussianNaiveBayes.cpp : Fetch one feature vector at a time instead of the whole feature matrix for potential large-scale training. - http://git.io/RZ68Fw
 CIA-64	shogun: pluskid master * rcaba5ca / examples/undocumented/python_modular/classifier_gaussiannaivebayes_modular.py : Remove debug code. - http://git.io/DxYHBg
-!- blackburn [~qdrgsm@83.234.54.186] has joined #shogun
 blackburn	mighty blackburn here lol
 PhilTillet	hi :)
 blackburn	hi
 PhilTillet	did you sleep well?
 blackburn	oh not really
 blackburn	:D
 PhilTillet	=D
-!- harshit_ [~harshit@182.64.221.94] has quit [Quit: Leaving]
 gsomix	blackburn, yo.
 blackburn	hi-hi
 blackburn	two days left for announcement of slots probably
 PhilTillet	yes..
@sonney2k	wiking, NormOne ensures actually ||x||_2 = 1
 blackburn	SumOne is for L1
 wiking	sonney2k: yeah i've realized, and i wondered why is it called NormOne when it's norm-2 :P
 blackburn	however yes I agree it should be generalized
 wiking	ok i'll make a fast one now
 wiking	as i need it anyways
@sonney2k	well the norm of each vector is one :)
 blackburn	wiking: kind of norm->one
@sonney2k	after processing .
 blackburn	wiking: could you please also specialize that for p=2 with cblas_dnrm2?
 wiking	?
 wiking	explain more :)
@sonney2k	speedup the code!
 blackburn	I know it is more stable in means of underflow and overflow
 wiking	ahhahahaha
 blackburn	than dot of two vectors
 blackburn	wiking: yeah seriously
 wiking	doin' it
 blackburn	dnrm2 is better than ddot
 wiking	just a sec
 blackburn	[1] http://fseoane.net/blog/2011/computing-the-vector-norm/
 blackburn	:D
-!- nickon [~noneedtok@dD5774105.access.telenet.be] has quit [Quit: ( www.nnscript.com :: NoNameScript 4.22 :: www.esnation.com )]
@sonney2k	blackburn, I think we should then update CMath::twonorm too :)
 blackburn	sonney2k: we have CMath::twonorm?
 blackburn	lol
@sonney2k	hehe
 wiking	ok
 wiking	ready
 wiking	oups almost... 1.0 norm is missing... :)
 n4nd0	blackburn: hey! so it looks that sonney2k pointed out a solution that already exists for the memory allocation framework you suggested
 n4nd0	blackburn: do you think there is anything else that you were thinking of but not covered there?
 blackburn	n4nd0: yes only small patch should be there probably
@sonney2k	blackburn, what is missing?
 blackburn	yes, we can also store relation to object
 blackburn	I mean now we can't check how memory libsvm ate
@sonney2k	only in total yes / no annotations or so
@sonney2k	blackburn, http://sonnenburgs.de/soeren/media/images/gsoc2012-proposals-stats.png
 wiking	sonney2k blackburn here's the implementation of p-norm: https://github.com/vigsterkr/shogun/commit/01c13468de45eec7616ecbbdb7ad1823fd029646
 blackburn	oh how many links ;)
 wiking	if you have any comments let me know otherwise i do the things for modular interface and i'll submit a pull request
 blackburn	sonney2k: whoa a few just before deadline
 blackburn	wiking: please use_that_naming
 wiking	ah shit ok forgot :))
 n4nd0	sonney2k: nice graph :)
 wiking	blackburn: ok pushed...
 blackburn	okay I have to go for a while
 blackburn	wiking: Soeren will merge I think ;)
 wiking	blackburn: is the lapack handling ok?
 wiking	i suppose so just want to double check
 blackburn	yes
 wiking	ok
 wiking	then i'll do the modular thingy and then i'll do a commit + pull request
 wiking	and then it's up to you guys if you want to get rid of NormOne and SumOne :P
 wiking	pull request sent...
 shogun-buildbot	build #462 of python_modular is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/python_modular/builds/462  blamelist: pluskid@gmail.com
@sonney2k	OK I blogged about this stats: http://sonnenburgs.de/soeren/category/blog/#shogun-student-applications-statistics-google-summ
@sonney2k	wiking, we cannot get rid of these things completely (for compatibility)
 wiking	okey no worries
 wiking	well what can be done is that simply do an inheritance from this class to NormOne and SumOne
 gsomix	good night, guys
 PhilTillet	good night gsomix
 wiking	mmmm mkl is quite slow :(
@sonney2k	wiking, as I said don't do it :)
@sonney2k	wiking, what are you doing btw?
@sonney2k	gsomix, have a good sleep
 wiking	sonney2k: well doing a combined kernel learning
 wiking	mmm ok i'll do the changes soon
@sonney2k	wiking, with mkl or just with svm?
 wiking	well both
 wiking	i'm trying with gnmpsvm
@sonney2k	?
@sonney2k	so just svm
 wiking	it works nice
 wiking	but i thought i give it a go with mkl
@sonney2k	how big is the kernel cache?
@sonney2k	how big is the data
 wiking	default
 shogun-buildbot	build #456 of ruby_modular is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ruby_modular/builds/456  blamelist: pluskid@gmail.com
@sonney2k	which kernels?
 wiking	JensenShannon + LINEAR
@sonney2k	wiking, did you use normone preproc ?
 wiking	the data... mmm it's about 1500 features
@sonney2k	err kernel normalizer
 wiking	sonney2k: haven't tried kernel normalizer
@sonney2k	wiking, it is sth you need ... I guess sqrtdiagkernelnormalizer is what you want :)
@sonney2k	wiking, 1500 examples or dims?
 wiking	dims
 wiking	ok so what kernel normalizer should i use
@sonney2k	and #examples?
@sonney2k	sqrtdiagkernelnormalizer
 wiking	and only on the the combinedkernel?
 wiking	or on each subkernels?
@sonney2k	wiking, no for each submkernel
 wiking	ok
 wiking	let's see how that helps
 wiking	why exactly sqrtdiagkernelnormalizer ?
@sonney2k	trace(K)=1
 wiking	ok adding them :)))
 wiking	trace(K) ?
 wiking	number of examples are 1k
 blackburn	??
 blackburn	re
 blackburn	:D
 wiking	yo
@sonney2k	wiking, but then it is fast right? I mean worst case precompute the matrix and done
 wiking	dooooh
 wiking	mkl finished.... worst results than with a simple svm
 wiking	significantly :(
 blackburn	I think it is totally wrong idea :D
 wiking	ahhahahahaha
 blackburn	I mean mkl (though I am not an expert right)
 wiking	ok i'm trying now the normalization of the sub kernels :)
@sonney2k	wiking, ahh and don't forget to adjust C
@sonney2k	anyways sleep time for me
@sonney2k	cu
 wiking	sonney2k: where in mkl or svm? or both? :)
@sonney2k	mkl C use 0 always
@sonney2k	only svm
 wiking	ah ok maybe that was the problem :)))
 wiking	i've used 1.0
 wiking	sonney2k gnite and thnx for the tips
 PhilTillet	gnight sonney2k
 n4nd0	sonney2k: good night
 blackburn	oh I have to say this
 blackburn	sonney2k: good night!!
 PhilTillet	:p
 PhilTillet	blackburn, do I still have some fixes to do in my nearest centroid pull request? :s
 blackburn	ah
 PhilTillet	maybe adding shrinking?
 blackburn	what kind of shrinking? :)
 PhilTillet	I have seen on google that there was a variant called nearest shrunk centroids
 PhilTillet	it shrinks centroids towards zero
 PhilTillet	shrunken* :p
 blackburn	oh I don't know
 blackburn	just fix things I noted
 PhilTillet	well I did it
 PhilTillet	didn't you see the new commit? :p
 blackburn	https://github.com/shogun-toolbox/shogun/pull/433
 blackburn	can you?
 PhilTillet	oh, seems like i made a mistake in my commit name
 PhilTillet	i can see 69cca92
 PhilTillet	* Fixed the example include and comments
 PhilTillet	but there are other stars in that commit with other things i fixed
 PhilTillet	:p
 blackburn	hmm right strange
 blackburn	why comments are after that
 PhilTillet	I don't know :o
 blackburn	okay more commits then
 PhilTillet	yes, actually i had many different commits, but rebased them into one
 PhilTillet	probably bad idea
 PhilTillet	that's probably why it appears before too
 PhilTillet	won't do that again :D
 blackburn	PhilTillet: okay commented some stuff
 PhilTillet	saw that, I don't understand the free thing, target is just a pointer, not allocated
 blackburn	actually you should rather use DotFeatures here I think
 PhilTillet	ah, you are talking about float64_t* current ?
 blackburn	no
 blackburn	okay actually it is ok for simple features
 blackburn	however there is a do_free stuff you know
 blackburn	it is supposed for such things
 blackburn	workflow is to get and call free with do_free
 blackburn	it sets do_free automagically and frees according to its value
 PhilTillet	okay got it
 PhilTillet	and concerning the other comment, 1.0/(float64_t)num_per_class[i], if I got it right I should replace with 1.0/((float64_t)num_per_class[i]-1) right?
 blackburn	yeah
 blackburn	but consider case with N=1
 PhilTillet	yes
 PhilTillet	that's what i was going to point out
 PhilTillet	:D
 PhilTillet	understood
 PhilTillet	I just check it still executes fine and I push
 blackburn	ok
-!- harshit_ [~harshit@182.64.221.94] has joined #shogun
 shogun-buildbot	build #463 of python_modular is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/python_modular/builds/463
 harshit_	blackburn: hi,Got your mail.! what do you mean by " What you would need is to make use of its semi-supervised capabilities there."
 harshit_	does that mean that I need to create an example of it ?
 blackburn	harshit_: I mean we currently do not provide abilities to train semi-supervised there
 harshit_	ohk
 blackburn	so you would need to create some class for that
 harshit_	I need to go through SVMlin implementation in shogun, Before saying anything else !
 harshit_	blackburn: A wrapper kind of class ?
 blackburn	yes
 harshit_	got it
 harshit_	thanks,..
-!- genix [~gsomix@188.168.4.3] has joined #shogun
 blackburn	n4nd0: ah btw! are you here?
 n4nd0	blackburn: yeah, tell me
-!- gsomix [~gsomix@188.168.14.52] has quit [Ping timeout: 260 seconds]
 blackburn	n4nd0: heiko added subset of subset of subset of subset support
 n4nd0	haha
 blackburn	so kernel multiclass stuff should work now
 n4nd0	cool
 n4nd0	I should try it
 shogun-buildbot	build #457 of ruby_modular is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ruby_modular/builds/457
 n4nd0	blackburn: what are you working on lately?
 blackburn	I'd say nothing :D
 blackburn	university kills my time this week
 PhilTillet	blackburn, I updated my pull request :)
 n4nd0	university stuff then
 blackburn	n4nd0: sad true
 blackburn	truth I mean lol
 CIA-64	shogun: Sergey Lisitsyn master * r7b3b7bc / src/NEWS : Updated NEWS - http://git.io/nGKAMQ
 n4nd0	blackburn: got you :D
 blackburn	n4nd0: damn heiko did not add add_subset thing to labels
 n4nd0	blackburn: :O
 blackburn	only to features
 blackburn	not damn heiko :D
 blackburn	damn. heiko
 n4nd0	lol
 blackburn	ah I'll finish that later
 n4nd0	ok
 blackburn	damn it is getting warm here
 blackburn	was -5 week before and +15
 blackburn	already
 PhilTillet	hehe
 PhilTillet	Russia is not the warmest country ever :p
 n4nd0	oh +15
 n4nd0	we don't have that temperature here yet
 PhilTillet	Spain is very warm on summer though :p
 PhilTillet	I used to go near Barcelona
 blackburn	almost no snow there left
 blackburn	PhilTillet: I guess he is in Sweden ;)
 PhilTillet	ooooh
 blackburn	okay see you tomorrow guys
 PhilTillet	see you tomorrow :)
-!- blackburn [~qdrgsm@83.234.54.186] has quit [Ping timeout: 248 seconds]
 n4nd0	good night
-!- PhilTillet [~Philippe@157.159.42.154] has quit [Quit: Leaving]
--- Log closed Tue Apr 10 00:00:19 2012
