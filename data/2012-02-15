--- Log opened Wed Feb 15 00:00:19 2012
 n4nd0	blackburn: hi!
 blackburn	n4nd0: hi
 n4nd0	blackburn: how is it going?
 n4nd0	blackburn: I tested the classifier splitting the data in train and test and I am quite surprised with the results
 blackburn	fine, but get no sleep today preparing to some talk at student's conference :)
 blackburn	tell me
 n4nd0	blackburn: they were much better than I expected
 blackburn	with which classifier?
 n4nd0	blackburn: SVMLib
 blackburn	libsvm I guess
 blackburn	I see
 n4nd0	blackburn: yeah, libsvm sorry
 n4nd0	blackburn: so the accuracy is 0.993338360985
 n4nd0	blackburn: what is much better than what I expected using just an svm and the image pixels as features
 blackburn	looks pretty unreal for faces hmm
 n4nd0	blackburn: exactly
 blackburn	what are the features?
 n4nd0	blackburn: pixel values
 blackburn	is it CBCL face database?
 n4nd0	blackburn: black and white images, normalized to mean 0 and std 1, but pixel values indeed
 n4nd0	blackburn: is the database I used for a course at the university, let me check if it was taken from a known database
 blackburn	I recalled it has 19x19 images too
 n4nd0	blackburn: yes
 blackburn	then why did you do splitting?
 blackburn	I mean there is test set
 n4nd0	so I don't use all the data for training but I have part of it to test as well
 n4nd0	I don't know if I got what you meant
 blackburn	i mean if we are talking about the same dataset
 blackburn	http://cbcl.mit.edu/projects/cbcl/software-datasets/FaceData1Readme.html
 blackburn	there is a train and test sets
 blackburn	so you don't have to split I guess
 n4nd0	aha, I see
 n4nd0	I will try with that database to see what I get
 blackburn	btw it is important to use whole training set
 n4nd0	ok
 blackburn	or even with virtual images
 blackburn	it is a common practice
 n4nd0	virtual images?
 n4nd0	artificially generated you mean?
 blackburn	i.e. shifted faces or noised
 blackburn	yeah
 n4nd0	ok
 blackburn	there is a citation here, they used some crazy method for features
 n4nd0	I remember that was pretty useful to train the cascade with boosting
 blackburn	yeah boosting works well in practice afaik
 blackburn	I am not a big fan of it though ;)
 n4nd0	I believe it is called bootstraping
 n4nd0	bootstrapping*
 blackburn	or more generally ensembles
 blackburn	:)
 n4nd0	:)
 n4nd0	anyway
 n4nd0	I guess that trained classifiers can be stored and retrieved from a program later right?
 blackburn	hmm yes, using serialization techniques
 n4nd0	like save them into a file and later load them into memory
 n4nd0	does that work between interfaces?
 n4nd0	e.g., I store sth trained with python and load it from octave
 blackburn	should work
 blackburn	if you did not use pickle or so
 n4nd0	don't really know what is pickle
 blackburn	pickle is a serialization package for python
 blackburn	that enables to save/load objects
 n4nd0	ah ok
 blackburn	I am not sure there
 n4nd0	so then there is not something in shogun that enables the serialization
 blackburn	you could try
 blackburn	hmm that's pretty complex thing
 blackburn	let me try to describe
 blackburn	while we have swig interfaces
 blackburn	we have some internal serialization part
 blackburn	based on C==
 blackburn	++
 blackburn	and 'external' related to concrete interface like python or ruby
 blackburn	so when pickle in python tries to save or load shogun object it uses that C++ serialization code
 n4nd0	ok
 n4nd0	then it might be possible, just wondering anyway :)
 blackburn	http://www.youtube.com/watch?feature=player_detailpage&v=EokaVrvZWBs
 n4nd0	blackburn: about gsoc, I want to start taking a closer look to possible projects I could apply for
 n4nd0	haha good summary of a day
 blackburn	my current life remind me that video: http://www.youtube.com/watch?feature=player_detailpage&v=kfchvCyHmsc
 n4nd0	blackburn: I think it is good if I start some coding related to it
 blackburn	hmm
 blackburn	okay there would be definitely be structured output learning
 blackburn	and gaussian processes
 blackburn	then one idea would be possibly related to ECOC and some label tree learning
 n4nd0	are you planning to apply for one of those this year or will you continue with dimensionality reduction?
 blackburn	ah yes I am going to apply to multitask learning
 n4nd0	I read today a bit about gaussian procceses and structured output learning, both look really interesting
 blackburn	yeah promising edges
 n4nd0	blackburn: so what do you think is a suitable approximation to get into one of those?
 blackburn	I am not sure what you mean
 blackburn	:)
 n4nd0	blackburn: study a current implementation of it, like this one for GPs and later try to port it?
 n4nd0	http://mloss.org/software/view/118/
 blackburn	hmm I would suggest you to take a look on scikits GPs
 blackburn	I believe it would be more readable
 n4nd0	all right, thanks :)
 n4nd0	blackburn: so I meant for example, I start a documentation phase and once the coding can be started I have to tell around here that I am working on that and that's all?
 blackburn	not really
 blackburn	are you about gsoc applying part?
 n4nd0	right know I was about collaboration before gsoc
 blackburn	well it is not necessary to start right now
 n4nd0	I guess that if I start with this during the next days I will be able to start working on it before gsoc has started
 blackburn	you don't have to hurry
 n4nd0	aha ok
 blackburn	if you finish things in may what would you do during summer? :)
 n4nd0	haha I see
 n4nd0	I assumed that could give better chances for the application to succeed
 blackburn	sure but you may do some other things for now ;)
 blackburn	for example you'd be very welcome to integrate your face recognition things
 blackburn	we lack good -real- examples
 n4nd0	ok :)
 n4nd0	that's good then, I will continue with that and try to make a nice example :)
 n4nd0	some doc about GPs
 blackburn	I find pretty useful to implement things by myself in some scripting lang
 blackburn	and then port to C++
 blackburn	so if you are hungry to GPs it would be useful to implement it in octave/matlab/python/etc
 blackburn	I believe it would take less than week to port things then
 blackburn	:)
 n4nd0	good
 n4nd0	I have to get some sleep now
 blackburn	and staying in touch increases your chances significantly :)
 n4nd0	blackburn: :)
 blackburn	there are some guys promising some things to implement
 blackburn	they appear and disappear for weeks
 n4nd0	aham
 blackburn	not really good practice for me :)
 n4nd0	well, thank you for the suggestions
 blackburn	you should talk to Soeren as well
 blackburn	to get him to know you
 blackburn	I am not the boss :)
 blackburn	okay sleep well then :)
 n4nd0	haha ok
 n4nd0	good night
 blackburn	good night
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
-!- naywhayare [~ryan@spoon.lugatgt.org] has joined #shogun
-!- blackburn [~qdrgsm@188.168.4.152] has left #shogun []
-!- dfrx [~f-x@inet-hqmc01-o.oracle.com] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Quit: wiking]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Quit: wiking]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Ping timeout: 240 seconds]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Quit: wiking]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- dfrx [~f-x@inet-hqmc01-o.oracle.com] has quit [Quit: Leaving.]
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has joined #shogun
 blackburn	wiking: JS was a little better than HIK ;)
 wiking	hehehe
 wiking	cool
 wiking	it took this long?
 blackburn	wiking: not really, just recalled
 blackburn	but anyway long, yes
 blackburn	30K seconds for 2000 vectors
 blackburn	libsvm OvO
 blackburn	not a real-time system lol
 wiking	:>>
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
 blackburn	sonne|work: ???-??-??-???!
 blackburn	unbelievable %$%$
 wiking	:>
 sonne|work	blackburn: ?
 blackburn	sonne|work: you don't answer mails and it is impossible to catch you!
 blackburn	looks like I ve been pinging you for last month :D
 blackburn	wiking: are you willing to integrate this homogay kernel map from vlfeat?
 wiking	blackburn: yep
 blackburn	so I shouldn't, right?
 blackburn	just checking
 wiking	blackburn: i'm just finishing up some other code, but if u guys say that you are willing to do the pull then i'll do it this week
 wiking	i guess it should go within the preprocessing
 blackburn	I'm not really in hurry with it
 wiking	i mean preprocessor
 blackburn	hmm
 blackburn	yes, looks like
 wiking	ok great
 blackburn	could be converter as well..
 blackburn	but i guess preprocessor fits better
 wiking	ok
 blackburn	btw we already have similar thing here
 blackburn	random gaussian fourier blabla
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Ping timeout: 260 seconds]
 CIA-18	shogun: Soeren Sonnenburg master * r0338587 / examples/undocumented/python_modular/regression_linear_ridge_modular.py : remove unused gaussian kernel from example - http://git.io/Sf2o5w
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has quit [Quit: Page closed]
-!- wiking [~wiking@huwico/staff/wiking] has quit [Ping timeout: 245 seconds]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Remote host closed the connection]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- n4nd0 [~n4nd0@s83-179-44-135.cust.tele2.se] has joined #shogun
--- Log closed Thu Feb 16 00:00:19 2012
