--- Log opened Fri Apr 20 00:00:19 2012
-!- emrecelikten [~emre@176.40.238.20] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Ping timeout: 248 seconds]
-!- emrecelikten [~emre@176.40.238.20] has quit [Quit: Leaving.]
-!- emrecelikten [~emre@176.40.238.20] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Quit: wiking]
-!- av3ngr [av3ngr@nat/redhat/x-svsxtaryupzxrgvv] has joined #shogun
-!- PhilTillet [~Philippe@157.159.42.154] has quit [Quit: Leaving]
-!- emrecelikten [~emre@176.40.238.20] has quit [Quit: Leaving.]
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Ping timeout: 244 seconds]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
 CIA-64	shogun: Evgeniy Andreev master * rb919bef / examples/undocumented/python_modular/regression_gaussian_process_modular.py : fixed regression gaussian process example for python3 support - http://git.io/f08Skg
 CIA-64	shogun: Soeren Sonnenburg master * rd466587 / examples/undocumented/python_modular/regression_gaussian_process_modular.py :
 CIA-64	shogun: Merge pull request #473 from gsomix/python3_interface
 CIA-64	shogun: Fixed regression gaussian process example for python3 support - http://git.io/Vr85dg
 CIA-64	shogun: Soeren Sonnenburg master * r8b0a9d7 / (74 files in 11 dirs):
 CIA-64	shogun: Merge pull request #472 from gsomix/big_deal_with_sgvector
 CIA-64	shogun: Start with SGVector -> SGVector& migration (+12 more commits...) - http://git.io/aGuOHQ
 CIA-64	shogun: Soeren Sonnenburg master * r39c82e6 / (src/shogun/regression/LARS.cpp src/shogun/regression/LARS.h): fix compile error: make LARS unavailable w/o lapack - http://git.io/9e1viA
-!- wiking [~wiking@78-23-189-112.access.telenet.be] has joined #shogun
-!- wiking [~wiking@78-23-189-112.access.telenet.be] has quit [Changing host]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Quit: wiking]
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
-!- uricamic [9320543b@gateway/web/freenode/ip.147.32.84.59] has joined #shogun
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Client Quit]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
-!- Jiuding [d2198538@gateway/web/freenode/ip.210.25.133.56] has joined #shogun
-!- Jiuding [d2198538@gateway/web/freenode/ip.210.25.133.56] has quit [Client Quit]
 xiangwang	hi wiking, pull request made succesfully. Thanks:)
-!- harshit_ [~harshit@182.68.43.52] has joined #shogun
 wiking	xiangwang: no worries
 wiking	gsomix: yeeeey cool patches!
 wiking	gsomix: around
 wiking	?
-!- harshit_ [~harshit@182.68.43.52] has quit [Ping timeout: 260 seconds]
 xiangwang	ok, just keep on working++
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has joined #shogun
 blackburn	ok I am finally finished with that shit
 blackburn	who is around? wiking? gsomix? sonne|work?
 wiking	here
 wiking	finished with what shit?
 blackburn	wiking: passed optics ungraded exam
 wiking	hahahah congrats
 blackburn	that was the most awful exam ever
 blackburn	I guess
 wiking	btw: don't we want to expose the primal objective value in svm?
 wiking	i would need it...
 blackburn	comatic aberrations, chromatic aberrations
 blackburn	hrhrrh
 wiking	hahahaha
 blackburn	seidel aberrations
 blackburn	holography
 blackburn	denisyuk holography
 n4nd0	blackburn: I am here around too, I am glad you finish you exam ;)
 n4nd0	finished*
 blackburn	n4nd0: uh sorry I missed your nickname in the list
 blackburn	thanks
 blackburn	wiking: I thought it is available
 blackburn	wiking: do you mean multiclass?
 wiking	blackburn: noun... i'm talking about svmocas
 blackburn	wiking: binary?
 wiking	yeps
 blackburn	svm base class has primal objective method IIRC
 blackburn	so it doesn't depend on implementation
 wiking	mmm where? :)
 wiking	man i was looking cmachine and clinearmachine api
 wiking	haven't seen one...
-!- av3ngr [av3ngr@nat/redhat/x-svsxtaryupzxrgvv] has quit [Quit: That's all folks!]
 blackburn	wiking: SVM
 wiking	checking now CSVM
 blackburn	how can that be linearmachine? ;)
 blackburn	what is the objective
 wiking	get_objective?
 blackburn	float64_t compute_svm_dual_objective();
 blackburn	this one
 wiking	mmm
 blackburn	or primal it is up to you
 blackburn	;)
 wiking	ok then there's only one thing i think
 wiking	class CSVMOcas : public CLinearMachine
 wiking	shogun/classifier/svm/SVMOcas.h
 wiking	this needs to be fixed afaik
 wiking	and this is why i was checking linear machine ;P
 wiking	since i'd like to use ocas for latent
 blackburn	ohohoho
 blackburn	I see
 wiking	so i guess before anything
 wiking	i should do the porting of svmocas to csvm
 blackburn	no way!
 wiking	or use libocas straight away
 blackburn	wiking: it shouldn't be csvm
 blackburn	csvm is a kernel machine
 wiking	ah so there's no linear svm api
 blackburn	yes exactly
 wiking	ok i see now
 blackburn	I am afraid we would need that
 wiking	yep
 wiking	so we would need CSVM and CKERNELSVM
 wiking	or seomthing like this
 wiking	or CSVM and from that have a CKERNELSVM inherited
 blackburn	just insert CLinearSVM between CLinearMachine and CSVMOcas
 blackburn	no I don't think we need to rename basic svm
 wiking	ok
 wiking	anyways we need a standard api for linear svm
 wiking	where one can get access to the primal/dual objective value
 blackburn	things getting tougher w/o multiple inheritance
 blackburn	wiking: actually even computing routines are different
 blackburn	computing primal of linear svm costs nothing
 blackburn	would be really fast I mean
 wiking	yeah it's only that currently you do not have access to those values ;P
 blackburn	wiking: just add it is easy ;)
 wiking	i mean i could have just hacked now CSVMOcas and expose the values in it
 wiking	but i thought it's better to do something more general
 wiking	and since now i've realized that we don't have a standard api for linear svm
 blackburn	yes CLinearSVM sounds legal for me
 wiking	ok i'll make one
 blackburn	sonne|work: CLinearSVM
 wiking	heheh again a branch switch
 wiking	i looooove git stash :D
 blackburn	#optimization, #shogun, #svms
 blackburn	that should take his attention
 wiking	hahahaha
 wiking	blackburn: we've agreed yesterday
 wiking	to have a shogun/optimizer folder
 wiking	with all the qp solvers being there
 blackburn	yay
 blackburn	I shall read the logs
 wiking	only thing that sonne|work isn't sure yet what should we do about tron and pr_loqo
 n4nd0	wiking: what is tron exactly? I have not found that much doc within the code
 n4nd0	and google search gets other hits by tron as you can imagine :)
 wiking	:D
 blackburn	n4nd0: some optimizer
 wiking	blackburn: ah yeah forgot to mention. would u mind if i change the doxygen config that the inherited methods are as well present in the documentation of a class?
 blackburn	I don't but no idea what sonne|work would say
 wiking	ok well u guys will decide about the pull request :P
 blackburn	I am actually thinking
 blackburn	we should spend some week in may
 blackburn	on doc
 blackburn	kind of doc sprint heh
 wiking	yeyey
-!- Marty28 [~marty@74-21.vpn.rz.uni-potsdam.de] has joined #shogun
 blackburn	n4nd0: do you like it?
 blackburn	wiking: and you?
 n4nd0	doc improvement?
 n4nd0	I might be kind of boring but it is probably necessary... so yes I like it
 blackburn	no we can make it fun
 n4nd0	how?
 blackburn	http://priceofoil.org/wp-content/uploads/2009/10/barack-obama-yes-we-can.jpg
 blackburn	n4nd0: barack obama says we can
 n4nd0	haha all right
 n4nd0	but not how, looks fishy
 blackburn	n4nd0: be a mathematician
 blackburn	existence is everything
 wiking	blackburn: most definitely would be up for it
-!- Marty28 [~marty@74-21.vpn.rz.uni-potsdam.de] has quit [Quit: Colloquy for iPad - http://colloquy.mobi]
 blackburn	what about middle of may?
 n4nd0	after the 7th it is good for me
 wiking	mm i'm away between 13-20 and 24->31
 wiking	otherwise it's good
-!- gsomix [~gsomix@188.168.13.79] has quit [Read error: Operation timed out]
 blackburn	wiking: is it serious you will be in iceland or so?
 wiking	blackburn: in july yes
 wiking	blackburn: but there i'll be 24/7 available
 wiking	in may i have conferences at those dates... that's why i cannot really work
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Ping timeout: 265 seconds]
 blackburn	I see
 shogun-buildbot	build #500 of ruby_modular is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ruby_modular/builds/500  blamelist: sonne@debian.org
-!- gsomix [~gsomix@188.168.13.79] has joined #shogun
 sonne|work	wiking, blackburn please no CLinearSVM
 blackburn	sonne|work: why?
 wiking	sonne|work: ok what then?
 sonne|work	nothing
 blackburn	sonne|work: where to place helpers like objective stuff?
 sonne|work	blackburn: in LinearMachine directly
 blackburn	sonne|work: any motivation why we should avoid CLinearSVM?
 wiking	sonne|work: so i should then reimplement ocas optimizer if i want to get access to objective value?
 sonne|work	blackburn: what would you derive liblinear from?
 blackburn	sonne|work: ehm CLinearSVM?
 sonne|work	haha
 sonne|work	it is logistic regression, linear programming machine, support vector regression *and* linear svm
 sonne|work	all in one thing
 wiking	yep true that
 blackburn	ah you're right
 blackburn	sonne|work: do you like doc sprint idea?
 sonne|work	I am certainly happy if you all write doc :D
 wiking	ehehhe so ok
 wiking	should we then just add a new function to linear machine
 blackburn	sonne|work: it would need your help too ;)
 wiking	that is 'optional'?
 blackburn	especially for legacy stuff
 sonne|work	wiking: yes - even implement it directly in there
 sonne|work	blackburn: why that?
 sonne|work	then it is not good :P
 blackburn	sonne|work: I am not able to doc some POIMs (wtf it is actually?), alignment kernels blabla
* sonne|work hates writing docs - and yes lots if not most of the doc was written by me
 wiking	sonne|work: directly there? i mean it depends on the solver whether i have access to it at all...
 sonne|work	wiking: I thought you wanted to compute objective?
 sonne|work	svm objective is pretty clear if you have training data, w and b
 sonne|work	and C
 wiking	yes but only svm has it
 blackburn	wiking: hm but why not to compute dual objective of LDA's w?
 blackburn	would be interesting haha
 sonne|work	ok then - float64_t compute_primal_objective() { SG_NOTIMPLEMENTED; }
 wiking	sonne|work: yep that's what i thought
 wiking	that have an pure virtual function
 wiking	in linear machine
 wiking	and if we can have such
 wiking	we supply one
 wiking	if not then it's notimplemented
 sonne|work	not pure virtual but virtual yes
 wiking	hehe ok
 blackburn	okay lets schedule some doc madness in the second half of may
 wiking	ok can i ask a naive question
 wiking	like in the case of CSVMOcas
 wiking	why the svmocas related variables are protected?
 wiking	are we planning ahead that maybe one day somebody will do an inheritance of it where he/she wants access to those variables
 wiking	but i mean this is true for a lot of machines..
 blackburn	wiking: but they are protected so what is the problem?
 wiking	ok other way to formulate my question: why aren't they private
 blackburn	sorry I misread your question as statement :)
 blackburn	yes it makes sense to provide such extensibility I think
-!- PhilTillet [~Philippe@npasserelle10.minet.net] has joined #shogun
 PhilTillet	Hello everybody
 PhilTillet	:)
 blackburn	hi
 PhilTillet	I'm finally in spring break for 1 week yeee
 wiking	PhilTillet: good on you
 wiking	enjoy it ;)
 PhilTillet	haha
 PhilTillet	I won't get bored :p a lot of work
 PhilTillet	i'm kind of disappointed by what I do at school so I end up having to do a lot of work on my own :p
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Ping timeout: 276 seconds]
 shogun-buildbot	build #520 of csharp_modular is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/csharp_modular/builds/520  blamelist: sonne@debian.org, gsomix@gmail.com
 blackburn	nice patch
 shogun-buildbot	build #533 of octave_modular is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/octave_modular/builds/533  blamelist: sonne@debian.org, gsomix@gmail.com
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
-!- PhilTillet [~Philippe@npasserelle10.minet.net] has quit [Ping timeout: 248 seconds]
 shogun-buildbot	build #509 of lua_modular is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/lua_modular/builds/509  blamelist: sonne@debian.org, gsomix@gmail.com
 shogun-buildbot	build #510 of java_modular is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/java_modular/builds/510  blamelist: sonne@debian.org, gsomix@gmail.com
-!- PhilTillet [~Philippe@157.159.42.154] has joined #shogun
 shogun-buildbot	build #506 of python_modular is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/python_modular/builds/506  blamelist: sonne@debian.org, gsomix@gmail.com
 sonne|work	gsomix: you need to adjust all typemaps to work with SGVector& too
 gsomix	sonne|work, ok. I need a little time. I have just returned.
 sonne|work	gsomix: and of course changing typemaps when there are still some SGVector's without & around will still cause breakage - so maybe better just copy typemaps for now to have a SGVector& and SGVector variant and then slowly proceed migrating them
 gsomix	sonne|work, got it.
 sonne|work	gsomix: all the other things I have in mind are piece of cake compared to this transition
 sonne|work	most intrusive so should be done first and will trigger lots of bugs
-!- sonne|work [~sonnenbu@194.78.35.195] has left #shogun []
-!- xiangwang_ [~chatzilla@210.73.4.120] has joined #shogun
-!- xiangwang_ [~chatzilla@210.73.4.120] has quit [Quit: ChatZilla 0.9.88.2 [Firefox 9.0.1/20111220165912]]
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Ping timeout: 272 seconds]
-!- sonne|work [~sonnenbu@194.78.35.195] has joined #shogun
 blackburn	*pleeease turn on conditioners*
 PhilTillet	haha
 PhilTillet	blackburn, what about turning on the preconditioners?
 PhilTillet	:D
 blackburn	PhilTillet: I don't mind if any preconditioner is able to cool the room heh
 PhilTillet	well
 PhilTillet	preconditioners are cool
 PhilTillet	:D
 PhilTillet	or maybe you can put a preconditioner on your conditioner
 PhilTillet	so that the temperature converges faster
 PhilTillet	o_o
 blackburn	I hope it would converge to some minus this time
 PhilTillet	haha
 PhilTillet	Better if the problem is convex too
 PhilTillet	XD
 n4nd0	:O
 blackburn	I'll become convex if temperature in this room stays the same or it becomes hotter
 PhilTillet	lol
 PhilTillet	n4nd0,  yes we're a bit crazy
 n4nd0	what the hell man, today it shows in Sweden and you in Russia are warm
 n4nd0	no way
 n4nd0	snows
 n4nd0	not shows
 n4nd0	haha
 blackburn	snows?
 n4nd0	yeah
 blackburn	I'm dying because of the hell here
 n4nd0	it has snowed today here
 blackburn	it should be +30
 PhilTillet	weird
 PhilTillet	is sweden that far from Russia?
 blackburn	russia is far from russia
 PhilTillet	lol
 blackburn	hmm +24
 n4nd0	haha
 blackburn	but feels like hell
 blackburn	they broke conditioners in the office
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
 n4nd0	see you later guys
 gsomix	sonney2k, sonne|work around?
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Ping timeout: 248 seconds]
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Ping timeout: 245 seconds]
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Ping timeout: 260 seconds]
-!- n4nd0 [~nando@n129-p107.kthopen.kth.se] has joined #shogun
 gsomix	blackburn, wut? today is cold, desu
 blackburn	gsomix: cold? you should visit netcracker office with turned off conditioners
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
 blackburn	however it is way too warm outside as well
 gsomix	blackburn, hmm. I'm in my room and I'm cold, hehe
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Ping timeout: 245 seconds]
 blackburn	are you cold?
 PhilTillet	blackburn, I'm kind of cold too
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
 blackburn	as for me I want to sleeeep :)
 PhilTillet	haha
 PhilTillet	me too, but i'm reading some svm stuffs :p
 PhilTillet	does Shogun use SMO for training SVMs?
 blackburn	PhilTillet: at some point
 blackburn	libsvm is some kind of
 PhilTillet	yes I read it was based on that
 PhilTillet	but not exactly the same
 blackburn	in the shogun we just incorporate different solver
 blackburn	with some improvement along the way to merge
 PhilTillet	okay
 PhilTillet	cause i've read several papers on parallelizing svm, and most of the time they just use SMO for learning
-!- pluskid [~pluskid@173.254.214.60] has joined #shogun
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Ping timeout: 265 seconds]
-!- n4nd0 [~nando@n129-p107.kthopen.kth.se] has quit [Quit: leaving]
-!- harshit_ [~harshit@182.68.43.52] has joined #shogun
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has quit [Quit: Page closed]
 gsomix	time to compile
* gsomix afk
-!- Marina_ [55b38cc8@gateway/web/freenode/ip.85.179.140.200] has joined #shogun
-!- xiangwang [~chatzilla@159.226.60.224] has joined #shogun
 Marina_	@sonney2k: if i try to train a svm on the real spice data, I get the error:  km = kernel.get_kernel_matrix(); SystemError: Out of memory error, tried to allocate 20000000000000000 bytes using malloc.
 Marina_	isn't it possible to train with so many datas?
 PhilTillet	Marina_, isn't that 2 e16 bytes? :p
-!- harshit_ [~harshit@182.68.43.52] has quit [Remote host closed the connection]
 Marina_	the dna_train.dat is 9.814.454 KB
-!- xiangwang [~chatzilla@159.226.60.224] has quit [Ping timeout: 260 seconds]
 Marina_	or what do you mean?
 sonne|work	Marina_: use a small subset of the data
 Marina_	@sonney2k how many data should I use for the subset? and should I load them first all into the programm or is it possible to load only a subset from the file?
 sonne|work	Marina_: start with very few (say 1000) and then gradually take more
 sonne|work	100k is probably enough to show anything of interest
 Marina_	@sonne2k so i load them all with lm.load_dna('real_data/dna_train.dat') and then take the first 1000
 Marina_	right?
 sonne|work	no
 sonne|work	load just a few
 Marina_	but how do I do so?
 sonne|work	x=file('my_file.dna').readlines()[:100] ?
 sonne|work	do it in whatever language you progam in
-!- harshit_ [~harshit@182.68.43.52] has joined #shogun
 harshit_	hello everyone :)
 harshit_	sonney2k, here ?
-!- n4nd0 [~nando@n129-p107.kthopen.kth.se] has joined #shogun
 n4nd0	sonne|work: hey! I got some time to be in shogun mode :)
 n4nd0	sonne|work: do you want me to try first if MulticlassKernel is ok now after Heiko's work?
 n4nd0	sonne|work: or should I continue with cover tree??
 sonne|work	n4nd0: I am most interested in the timing experiment
 sonne|work	harshit_: yes
 harshit_	sonne|work, got to know form logs that svr is released ..! Are you working on it ?
 harshit_	I am asking coz I want to do that
 gsomix	sonne|work, ok, it compiled. python_modular, ruby_modular, octave_modular are fine now.
 n4nd0	sonne|work: using CBlas function then right? I don't have that clear if we concluded whether CBlas or the decomposition (x-y)^2 = x^2 + y^2 -2?x?y is preferable
 gsomix	sonne|work, i need to go. cu little later
 sonne|work	n4nd0: cblas has no norm(x,y) function
 sonne|work	n4nd0:  so try the decomposition using blas
 n4nd0	sonne|work: let me look in the logs, I remember blackburn suggested to use a cblas function
 sonne|work	n4nd0: dnrm2
 n4nd0	sonne|work: yeah exactly
 sonne|work	n4nd0: that doesn't help, will only do ||x||
 sonne|work	not ||x-y||
 sonne|work	harshit_: I started already - but what you are trying to do (SVMLin) is also nice!
 n4nd0	sonne|work: I could comptue the difference vector first
 sonne|work	which is already slower than doing x^T y in the decomposition :)
 sonne|work	and blas
 PhilTillet	Ha, now I understand why GaussianKernel is a DotKernel and not a distance kernel :p
 sonne|work	PhilTillet: yeah nice trick eh?
 PhilTillet	yes :D
 PhilTillet	on GPU, norm2(x-y) is faster :p this was why I was facing a little design issue for my patch
 sonne|work	PhilTillet: why that?
 sonne|work	I mean if you already hav ||x||^2 and ||y||^2 precomputed
 sonne|work	x^T y cannot possible slower or?
 PhilTillet	yes, if you have these two precomputed
 PhilTillet	indeed we have
 PhilTillet	:p
 sonne|work	yeah of course you need to precompute these
 sonne|work	otherwise -> slow
 PhilTillet	the point is that i was still with these matrix stuff, I did some benchmark replacing dot product with dot on GPU
 PhilTillet	but well, it is pointless I think
 PhilTillet	gpu starts to benefit for blas1,2 for vector size > 100 000
 PhilTillet	and I guess we rarely have features of dimension more than 100 000 :p
 PhilTillet	well, and I was thinking, maybe the cleanest thing is to make some GPUKernels, like GPUDotKernels, etc...
 sonne|work	PhilTillet: maybe it is really only possible if this is done for a specific kernel, specific features + kernel machine
 sonne|work	so GaussianKernelMachine
 sonne|work	working only on 'simple' features
 PhilTillet	Hmmm
 PhilTillet	Could be possible with sparse features too
 PhilTillet	but I agree that for online learning, it's probably not efficient
 PhilTillet	:p
 sonne|work	how could that work with sparse features?
 sonne|work	isn't that random memory access then again?
 PhilTillet	Hmm, it's possible to do sparse linear algebra on GPU :p
 PhilTillet	I guess what's important is to have all the features at the beginning so you can cache them efficiently
 PhilTillet	I've seen a paper with SMO on GPU where they use chunking because the kernel matrix is too large to fit in memory
 PhilTillet	they had 50x speedup on learning compared to libsvm ><
-!- harshit_ [~harshit@182.68.43.52] has quit [Ping timeout: 276 seconds]
-!- uricamic [9320543b@gateway/web/freenode/ip.147.32.84.59] has quit [Quit: Page closed]
 sonne|work	PhilTillet: yeah sure that makes sense
 sonne|work	PhilTillet: actually chunking methods like svmlight precompute a part of the kernel matrix in each iteration (about 40 kernel rows)
 PhilTillet	hmm, interesting
-!- Marina_ [55b38cc8@gateway/web/freenode/ip.85.179.140.200] has quit [Ping timeout: 245 seconds]
-!- blackburn [5bde8018@gateway/web/freenode/ip.91.222.128.24] has joined #shogun
-!- blackburn [5bde8018@gateway/web/freenode/ip.91.222.128.24] has quit [Quit: Page closed]
 gsomix	sonney2k, sonne|work java_modular is ok now.
-!- harshit_ [~harshit@182.68.43.52] has joined #shogun
-!- PhilTillet [~Philippe@157.159.42.154] has left #shogun ["Leaving"]
-!- pluskid [~pluskid@173.254.214.60] has quit [Quit: Leaving]
-!- harshit_ [~harshit@182.68.43.52] has quit [Remote host closed the connection]
-!- xiangwang [~xiangwang@210.73.4.120] has joined #shogun
 n4nd0	sonne|work: there is no huge speedup using the decomposition :(
 n4nd0	this is the way I am computing it, just in case I got the idea wrong
 n4nd0	http://snipt.org/uhigh2#expand
-!- emrecelikten [~emre@176.40.238.20] has joined #shogun
-!- xiangwang [~xiangwang@210.73.4.120] has quit [Remote host closed the connection]
@sonney2k	gsomix, ok then I better merge things :)
@sonney2k	n4nd0, no wonder
@sonney2k	n4nd0, you should precompute x^T x
@sonney2k	and store these constants
 CIA-64	shogun: Soeren Sonnenburg master * r48b3ffd / (42 files in 7 dirs):
 CIA-64	shogun: Merge pull request #458 from pluskid/multiclass-refactor2
 CIA-64	shogun: Refactoring of multiclass (+11 more commits...) - http://git.io/Zjyx0Q
 CIA-64	shogun: Soeren Sonnenburg master * rd6cc3eb / (7 files in 7 dirs):
 CIA-64	shogun: Merge pull request #474 from gsomix/big_deal_with_sgvector
 CIA-64	shogun: add SGVector& typemaps for 'smooth' transition (+7 more commits...) - http://git.io/dbyMcQ
 n4nd0	sonney2k: to compute x^T x the one I am doing it right now with cblas_ddot(xlen, x, 1, x, 1) is fine or not?
@sonney2k	n4nd0, just use CMath::dot() (which effectively does this)
 n4nd0	the way instead of the one ^
 n4nd0	all right
 n4nd0	do you expect a major improvement storing it?
@sonney2k	n4nd0, of course
@sonney2k	factor 3 faster then
 n4nd0	wait a moment
@sonney2k	n4nd0, btw I think you should compare this to JL's covertree distance
 shogun-buildbot	build #754 of libshogun is complete: Failure [failed compile]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/libshogun/builds/754  blamelist: pluskid@gmail.com
@sonney2k	ours should be faster then
 n4nd0	with precomputing x^T x
@sonney2k	yes
 n4nd0	this is for the whole training data right?
@sonney2k	yes, going once over all data
 n4nd0	I mean for each training vector x store x^T x
@sonney2k	yes
@sonney2k	have a look at CGaussianKernel
@sonney2k	it does the same
 n4nd0	ok, I will check it
@sonney2k	I guess you can even just copy the code
 n4nd0	but I thought in any case that in shogun we normally assume that these type of matrices do not fit into memory
@sonney2k	dammed buildbot :D
@sonney2k	n4nd0, most algorithms assume that data fits in memory
@sonney2k	but storing a scalar per vector is not really a lot even if not
 n4nd0	in the same way it is done for the training data
@sonney2k	yes
 n4nd0	it is good to do it for the query points
@sonney2k	you have to do it for lhs and rhs
 n4nd0	got it
 n4nd0	thank you for the pointer to CGaussianKernel :)
 CIA-64	shogun: Soeren Sonnenburg master * r732f288 / src/shogun/classifier/svm/SVM.h : add missing friend 'class' Foo to fix compile error - http://git.io/rs1rSg
@sonney2k	n4nd0, let me know whether JLs distance is faster or ours now - and if ours is faster our KNN+covertree should be too
@sonney2k	:P
@sonney2k	shogun-buildbot, be happy!
 shogun-buildbot	What you say!
 emrecelikten	someone set up us the bomb
@sonney2k	shogun-buildbot, you are the bomb!
 shogun-buildbot	build #756 of libshogun is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/libshogun/builds/756
 shogun-buildbot	What you say!
@sonney2k	yay!
 gsomix	sonney2k, ok. I'm waiting for shogun-buildbot judgement.
 shogun-buildbot	build #686 of r_static is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/r_static/builds/686  blamelist: sonne@debian.org
 CIA-64	shogun: Soeren Sonnenburg master * ra6d10e0 / src/shogun/machine/MulticlassMachine.cpp : fix compile warnings - http://git.io/cdw-Rg
 shogun-buildbot	build #708 of cmdline_static is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/cmdline_static/builds/708  blamelist: sonne@debian.org
 CIA-64	shogun: Soeren Sonnenburg master * r36b4b6e / examples/undocumented/libshogun/classifier_mklmulticlass.cpp : fix include MultiClass -> Multiclass - http://git.io/E7bhbA
@sonney2k	gsomix, it will take some time - have to cleanup pluskids bugs :)
@sonney2k	gsomix, I really hope we can make some fast progress on this sgvector business
@sonney2k	this and some reshuffling into lib/external / multitask / multiclass are the big changes
@sonney2k	all the rest are just incremental feature updates
@sonney2k	not so likely to break the whole build
 CIA-64	shogun: Soeren Sonnenburg master * r53cc701 / examples/undocumented/libshogun/classifier_libsvmmulticlass.cpp : another MultiClass -> Multiclass include fix - http://git.io/4HG5DA
 shogun-buildbot	build #687 of octave_static is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/octave_static/builds/687  blamelist: sonne@debian.org
 gsomix	sonney2k, I also hope so.
@sonney2k	shogun-buildbot, stinky-finger!
 shogun-buildbot	What you say!
 gsomix	sonney2k, I have some misunderstanding with reference counting. can we discuss these issues a little later?
@sonney2k	sure but first the SGVector& business
 shogun-buildbot	build #674 of python_static is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/python_static/builds/674  blamelist: sonne@debian.org
 gsomix	sonney2k, ok. I need to go now. cu, later for discuss future plan.
@sonney2k	gsomix, cu
* sonney2k waits for the buildbot to send out love and happiness again
 shogun-buildbot	build #215 of nightly_none is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/nightly_none/builds/215
-!- genix [~gsomix@83.234.54.246] has joined #shogun
-!- gsomix [~gsomix@188.168.13.79] has quit [Ping timeout: 276 seconds]
-!- genix is now known as gsomix
 gsomix	haha
 gsomix	>:]
 gsomix	wiking, around
 wiking	ye
 gsomix	wiking, did you wanted to tell me smth? I'm slowpoke - missed your message.
 wiking	ah yeah
 wiking	i think maybe blackburn already told you about a little change we'll need to do in Features.h
 wiking	and in all the inherited classes
 gsomix	wiking, const methods?
 wiking	yes
 gsomix	aha
 wiking	ok cool so you know about it \o/
-!- n4nd0 [~nando@n129-p107.kthopen.kth.se] has quit [Quit: leaving]
 gsomix	:3
* gsomix afk
 wiking	thnx in advance for the changes!
 wiking	now it's time for the night session developing...
 gsomix	it's time to homework for me.
@sonney2k	alright the deduplication meeting is over and everyone of you who was in before is still in :D
 wiking	hahahaha
 wiking	now the only question is
 wiking	who's in
 wiking	but i guess we'll only know this next week
 CIA-64	shogun: Soeren Sonnenburg master * rac7a60e / (2 files): fix examples MultiClass -> Multiclass - http://git.io/eoanrA
 wiking	nyiha
 wiking	the we'll only know it next monday between 21:00 and 22:00 CEST
 CIA-64	shogun: Soeren Sonnenburg master * rfa27ebf / (16 files in 9 dirs): MultiClass -> Multiclass replacement in all remaining examples - http://git.io/Bzc30Q
 wiking	sonney2k: so there's gonna be a structural-svm gsoc project?
@sonney2k	yeah
 wiking	ok cool
@sonney2k	hmmhh pluskid really did lots of changes causing all MC examples to fail
 wiking	:(
@sonney2k	simple changes are missing but I guess I never said that one has to compile for all interfaces and run make check-examples
@sonney2k	anyway it will be over soon
@sonney2k	wiking, anyway 8 students is a lot and I hope you will all have fun :)
 wiking	hahaha so should i understand the implied meaning here ? ;)
@sonney2k	I am not implying anything
 wiking	ah ok
 wiking	:D
 emrecelikten	I sadly could not find time for doing the patch requirement for this project
 emrecelikten	Maybe I will work on something on my own if none of my proposals get accepted in general
 emrecelikten	I still have that HMM project in my mind :D
@sonney2k	emrecelikten, you mean continous output hmms?
 emrecelikten	Yep, Gaussian mixtures
 emrecelikten	I am a text-to-speech guy
 emrecelikten	It's used a lot
@sonney2k	yeah
@sonney2k	would be a very welcome contribution... maybe you even find C/C++ code for that already
@sonney2k	huh? someone has withdrawn his proposal?!
 emrecelikten	I think there are various tools, but performance is quite important I think
 emrecelikten	Baum-Welch takes a lot of time
@sonney2k	got to leave train
@sonney2k	cu
 emrecelikten	Bye!
 wiking	sonney2k: mmm wasn't it 9 slots?
 emrecelikten	What are the projects of you guys?
 emrecelikten	I know that Fernando applied to structured SVM outputs
 gsomix	emrecelikten, "Many changes, improvements, bugs, lolz and vodka for Good!"
 wiking	gsomix: the best project \o/
 wiking	emrecelikten: i've applied for latent svm
 emrecelikten	Vodking all the time then huh?
 emrecelikten	Too bad that I'm a straight edge :P
 emrecelikten	wiking: Nice. I applied for structured SVM output and C5.0
 wiking	yeah structured svm would be cool to have
 emrecelikten	But since I haven't sent a patch, I don't think I have a chance
 wiking	well i've send a lot of patches
 wiking	but not much related to latent svm yet :(
 wiking	that is still under progress
 emrecelikten	I think it's fine, you're supposed to work on it later
 wiking	i might have something tonight
 emrecelikten	If you could do something serious by now, there wouldn't be a need for GSoC, would there?
 emrecelikten	:D
 wiking	just cooked myself a turkish coffee so i should have the power ;)
 wiking	but yeah the latent svm would be in big need for having structural svm
 emrecelikten	Should I send you some? :P
 wiking	emrecelikten: i have some here with me ;P
 wiking	not the structural svm
 wiking	but the turkish coffee ;)
 emrecelikten	Haha
 wiking	anyhow
 wiking	i want to finish this
 wiking	i'm aaalmost there
 wiking	the minimization is done
 wiking	now i just have to figure out the handle the latent variable handling in a nice way
 wiking	and then i might already be able to run the first dummy test
 wiking	and actually it'd be great if it really works out
 wiking	since it's gonna use libocas
 emrecelikten	Best of luck to you then :)
 wiking	which suppose to be very efficient
 wiking	and latent svm will need that
 wiking	since each iteration is basically consist of a cutting plane finding....
 wiking	*search
 wiking	but i even have to now construct a dummy test for the whole thing
 wiking	so that i can see that actually it works :)
 wiking	not just calculating infinity
 wiking	and till now i haven't managed to find a simple train/test set .... so it seem i'll have to construct it myself
 emrecelikten	You shouldn't worry about being accepted though, regarding the conversation at top
 emrecelikten	8 slots is a lot
 emrecelikten	Unless someone is ninjaing your project, you should be fine I guess
 emrecelikten	My "primary" project had 2 slots last year
 emrecelikten	It's Spartan-like competition to get accepted there
 emrecelikten	Not saying that it's easy here or something, but there wasn't any "friendly competition", that's what I meant :D
@sonney2k	emrecelikten, wiking - the funny thing is that last year no one applied for the structured output task and the latent svm!
 wiking	:(
 wiking	too bad
 emrecelikten	sonney2k: I sort of feel bad about not applying to Shogun last year
 emrecelikten	I discovered it too late
@sonney2k	emrecelikten, well it was much tougher to get in last year
@sonney2k	5 slots for 73 proposals
 emrecelikten	It's like 8 slots for 50 proposals now?
@sonney2k	yeah
 wiking	mmm i think i have a problem with git svn rebase ;)
@sonney2k	but decision is easier this year too - what counts is # and quality of patches
 emrecelikten	Zero of which are mine :P
 wiking	oh i was meaning to ask
 wiking	don't we want to do the documentation in http://docutils.sourceforge.net/rst.html ?
 wiking	easy to use and nice html can be generated as well
@sonney2k	emrecelikten, yeah well ... contributing not just directly before gsoc is also an option... even for next year (if we apply  & get in...)
@sonney2k	wiking, but it won't work with doxygen
@sonney2k	or are you thinking of writing a new separate doc?
 wiking	well
 wiking	maybe a bit more of documentation would be good
 wiking	aaah btw maybe u haven't seen it
 wiking	about doxygen
 wiking	could we turn on the flag that it actually adds the inherited functions as well to a class interface?
 wiking	or u have strong objections about that
 emrecelikten	sonney2k: I know, I know :)
 wiking	INLINE_INHERITED_MEMB  = YES
 wiking	i think this is the doxygen option
@sonney2k	too bad that pluskid is not here :(
@sonney2k	wiking, I know that flag - do you really think that helps?
 wiking	now that i'm doing latent machine
 wiking	it's a direct inherited from linear machine
 wiking	t
 wiking	h
 wiking	which is a machine
 wiking	so i was like ok let's see what are the funcitons
 wiking	so i was checking two headers
 wiking	looking for what are the pure virtual functions etc
@sonney2k	they apply method of multiclass svm is gone?!?
@sonney2k	cannot find it in multiclasskernelmachine either
 wiking	so it'd be great if for example i could see from the class that i'm inheriting from that ok these are the function i'll need to implement and actually i have by default
@sonney2k	wiking, I mean we can try it
 wiking	so in my case it's helpful
 wiking	of course now that clang has this amazing error and warning messages
 wiking	it's actually making a lot easier to see where did i do something wrong with the inheritance and missing some pure virtual function implementation
 wiking	:P
@sonney2k	wiking, send a pull request :)
 wiking	heheh ok
 wiking	interfaces/modular/modshogun.doxy is the config file right?
 wiking	oh no
 wiking	there's Doxyfile ;)
--- Log closed Sat Apr 21 00:00:15 2012
