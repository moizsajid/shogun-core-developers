--- Log opened Thu Mar 22 00:00:19 2012
-!- romi_ [~mizobe@187.57.1.50] has quit [Ping timeout: 246 seconds]
-!- romi_ [~mizobe@187.57.1.50] has joined #shogun
-!- romi_ [~mizobe@187.57.1.50] has quit [Ping timeout: 246 seconds]
 n4nd0	sonney2k: I just sent a pull request for QDA but appears to me like none has been assigned to it, can you tell me if you have been notified?
-!- vikram360 [~vikram360@117.192.164.158] has joined #shogun
-!- PhilTillet [~Philippe@tillet-p42154.maisel.int-evry.fr] has quit [Remote host closed the connection]
-!- mayanks43 [~Marcus@115.248.130.148] has joined #shogun
-!- l0nr4n [~l0nr4n@unaffiliated/l0nr4n] has quit [Quit: This computer (or maybe me) has gone to sleep]
-!- canonind [d2198538@gateway/web/freenode/ip.210.25.133.56] has joined #shogun
-!- canonind [d2198538@gateway/web/freenode/ip.210.25.133.56] has quit [Quit: Page closed]
-!- canonind [d2198538@gateway/web/freenode/ip.210.25.133.56] has joined #shogun
-!- canonind [d2198538@gateway/web/freenode/ip.210.25.133.56] has quit [Client Quit]
-!- Canonind [d2198538@gateway/web/freenode/ip.210.25.133.56] has joined #shogun
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
-!- vikram360 [~vikram360@117.192.164.158] has quit [Ping timeout: 252 seconds]
-!- vikram360 [~vikram360@117.192.164.158] has joined #shogun
-!- vikram360 [~vikram360@117.192.164.158] has quit [Ping timeout: 252 seconds]
-!- yash [46ab0416@gateway/web/freenode/ip.70.171.4.22] has joined #shogun
-!- romi_ [~mizobe@187.57.1.50] has joined #shogun
-!- yash [46ab0416@gateway/web/freenode/ip.70.171.4.22] has quit [Quit: Page closed]
-!- Miggy [~piggy@14.139.82.6] has quit [Ping timeout: 260 seconds]
-!- mayanks43 [~Marcus@115.248.130.148] has left #shogun []
-!- harshit_ [~harshit@182.68.142.173] has joined #shogun
-!- in3xes [~in3xes@180.149.49.227] has joined #shogun
-!- in3xes [~in3xes@180.149.49.227] has quit [Ping timeout: 244 seconds]
-!- in3xes [~in3xes@210.212.58.111] has joined #shogun
-!- harshit_ [~harshit@182.68.142.173] has quit [Ping timeout: 252 seconds]
-!- gsomix [~gsomix@85.26.232.68] has joined #shogun
 gsomix	hi
-!- harshit_ [~harshit@182.68.142.173] has joined #shogun
-!- in3xes_ [~in3xes@59.163.196.121] has joined #shogun
-!- in3xes_ [~in3xes@59.163.196.121] has quit [Client Quit]
-!- in3xes_ [~in3xes@59.163.196.121] has joined #shogun
-!- in3xes__ [~in3xes@59.163.196.121] has joined #shogun
-!- in3xes__ [~in3xes@59.163.196.121] has quit [Remote host closed the connection]
-!- in3xes [~in3xes@210.212.58.111] has quit [Ping timeout: 276 seconds]
-!- in3xes_ [~in3xes@59.163.196.121] has quit [Ping timeout: 265 seconds]
-!- gsomix [~gsomix@85.26.232.68] has quit [Ping timeout: 246 seconds]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
 harshit_	hey @n4nd0
 n4nd0	harshit_: hi there!
 n4nd0	harshit_: how is your stuff going?
 harshit_	one more problem now
 harshit_	my ./configure dont recognize lapack library
 harshit_	i have installed it and also its c interface
 n4nd0	ok
 n4nd0	so how have you installed it?
 harshit_	by making some changes in make.inc file
 harshit_	and then installing fortran library
 harshit_	and then installed the lapacke
 n4nd0	mmm
 n4nd0	what OS are you with?
 harshit_	ubuntu 11.10
 n4nd0	apt-get install liblapack-dev?
 n4nd0	I normally install everything with apt-get
 n4nd0	I think I did this also this way
 harshit_	okay wait i am doing that
 harshit_	Is lapack example in shogun's examples, Running on your machine
 harshit_	?
 n4nd0	which example in particular?
 harshit_	mathematics_lapack.cpp
 n4nd0	compiling ...
 harshit_	hey thanks ./configure now recognized the lapack
 n4nd0	yes, it looks like it runs without problems
 harshit_	thanks apt-get is great
 n4nd0	yes
 n4nd0	if you are fond of more graphical stuff I recommend you synaptic
 n4nd0	apt-get is good enough though
 harshit_	also one more thing if say suppose i didht have any library installed at time i installed shogun
 n4nd0	the only problem is that you need to know the name of the package to install / have intuition for the naming conventation
 n4nd0	conventions*
 harshit_	and then later i install that library
 harshit_	then do i need to recompile whole shogun ?
 n4nd0	yes, probably
 n4nd0	I think there's no general answer for that (there may be some exceptions) but in general yes
 n4nd0	to build shogun faster I recommend you to do
 n4nd0	./configure --disable-optimization [the other options you want to use]
 n4nd0	and later run make for several threads
 n4nd0	make -j2 or make -j4
 harshit_	that would be useful sometimes
 n4nd0	yes
-!- Canonind [d2198538@gateway/web/freenode/ip.210.25.133.56] has left #shogun []
 harshit_	hey, my shogun compiled and is installed successfully but still when i run mathematics_lapack.cpp it doesn't show anything
-!- Jiuding [d2198538@gateway/web/freenode/ip.210.25.133.56] has joined #shogun
 Jiuding	hi feeling great to join you
 n4nd0	harshit_: well, have you checked the code?
 harshit_	yes .. in my case HAVE_LAPACK is not defined
 harshit_	so ifdef evaluates to be false
 harshit_	and doesnt show anything
 harshit_	and HAVE_LAPACK is supposed to be defined in config.h
 n4nd0	I think that there's no nothing to show in that example apart from error messages
-!- gsomix [~gsomix@85.26.232.68] has joined #shogun
 n4nd0	there's nothing* ... fuck, my fingers are clumsy in the morning
 harshit_	but still i dont knw why my machine is doing that
 harshit_	i think i should redo the entire procedure
 n4nd0	how do you know that HAVE_LAPACK is evaluated to false?
 n4nd0	have you tried it writing some printfs inside?
 harshit_	becoz if i printf inside it doesnt print
 harshit_	yes
 n4nd0	ok
 n4nd0	have you built shogun after installing lapack?
 harshit_	yes
 n4nd0	you should run configure, check that lapack is detected
 n4nd0	run make, and finally make install
 n4nd0	have you done all the steps?
 harshit_	yes after you told me to install via apt-get
 harshit_	it was detected by configure
 n4nd0	so if you did later make and make install I guess it should work
 n4nd0	however, it might be that there are other dependencies in order for lapack to work, I don't come up with other explanation
 harshit_	yes i did
 harshit_	i think only way out is to reinstall
 harshit_	no ?
 harshit_	reinstall everything
 harshit_	also do you knw how to uninstall any library
 n4nd0	mmm
 n4nd0	I don't know if I recommend you to do that, one should be careful
 n4nd0	yes, you can uninstall libraries with apt-get remove
 n4nd0	easier with synaptic
 n4nd0	I'd recommend you to take a look here first http://www.shogun-toolbox.org/doc/en/current/installation.html
 n4nd0	in the requirements, it might be that you're still missing sth
 harshit_	what is sth ?
 n4nd0	it looks like that atlas library could be necessary
 n4nd0	ups sorry, sth = something
 n4nd0	:)
 harshit_	i thought sth is some program
 harshit_	also i tried to apt-get it :)
 n4nd0	haha sorry
 harshit_	okay thanks n4nd0 ,g2g will do it and
 harshit_	will ask you some more questions .lol
 n4nd0	apt-cache show is useful to read package descriptions before installation
 n4nd0	try if you want for example
 n4nd0	apt-cache show liblapack-dev
 n4nd0	you'll see the description of the package you just installed
 harshit_	yes it works. nice
 harshit_	and also when we download documentation through synaptic, how can we access that
-!- gsomix [~gsomix@85.26.232.68] has quit [Ping timeout: 246 seconds]
 n4nd0	afaik the package documentation is usually man pages
 n4nd0	e.g. now you should be able to do man lapack
 n4nd0	if you want to know more info about a topic apropos
 harshit_	but when i do man lapack it says :
 harshit_	No manual entry for lapack
 harshit_	same for every other documentation i download
 n4nd0	probably you need the package liblapack-doc
 harshit_	yeah get it..
 harshit_	thanks
 harshit_	bye
-!- harshit_ [~harshit@182.68.142.173] has quit [Quit: Leaving]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has joined #shogun
 blackburn	n4nd0: yes we were notified
 n4nd0	blackburn: cool :)
 blackburn	sonne|work: ping
 blackburn	This program is SG_FREE software
 blackburn	oh lol auto replace
 n4nd0	haha
 blackburn	n4nd0: so did you fix this mess in your repo?
 n4nd0	blackburn: yeah, it is looking way better now :)
 n4nd0	blackburn: I have to ask you one thing about one vs. one training, not repo related
 blackburn	n4nd0: just create new branches for each new pull
 blackburn	and use rebase not merge
 blackburn	n4nd0: ask
 n4nd0	blackburn: I didn't manage to get to work the trick using the same vector all the time, I don't know if you remember
 n4nd0	blackburn: the thing was to allocate an array big enough and pass to CSubset on each iteration the adequate lenght of this array
 n4nd0	blackburn: probably not the complete one
 n4nd0	blackburn: the thing is that later, when one does remove subset both in feature and labels, the vector is also de-allocated so in the next second iteration it explodes
 n4nd0	blackburn: let me show you in code
 n4nd0	https://github.com/iglesias/shogun/blob/multiclass_1vs1/src/shogun/machine/MulticlassMachine.cpp
 n4nd0	the nice idea would be to have lines 147 and 148 out of the for loop
 blackburn	n4nd0: let it stay for now
 blackburn	not really high demanding thing
 n4nd0	blackburn: ok :)
 n4nd0	blackburn: about the repo, I read about rebase yesterday and I think I got the difference wrt merge
 n4nd0	blackburn: but why do you think it is better to do it that way?
 blackburn	n4nd0: yeah you just put your commits on top of it
 blackburn	no 'merged blabla from blabla' commits
 n4nd0	ok
 n4nd0	but in any case I should not worry about merging my branches into master when doing a pull request
 blackburn	n4nd0: the approach is to keep master updated and rebase your branches on top of it
 blackburn	in this way everything looks clearer
 blackburn	http://book.git-scm.com/assets/images/figure/rebase5.png
 blackburn	http://book.git-scm.com/assets/images/figure/rebase5.png
 blackburn	ehm
 blackburn	one picture heh
 blackburn	n4nd0: commit graph would not look like some social graph :D
 n4nd0	hehe ok :)
 blackburn	n4nd0: train 1-v-1 looks ready
 blackburn	what u'd need now is insert classify 1-v-1 from multiclasssvm
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Ping timeout: 276 seconds]
 n4nd0	blackburn: yes
 n4nd0	blackburn: the simple example I created with LibLinear was working at least
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
 blackburn	n4nd0: you mean it trained successfully?
 n4nd0	blackburn: yes
 blackburn	nicer
 blackburn	nice*
 n4nd0	blackburn: https://github.com/iglesias/shogun/commit/61c4eeb055ac17bbbb3c4bed6f41e863064d94e1
 n4nd0	blackburn: that program breks because apply is not implemented yet, what is a good signal this far :)
 n4nd0	brb
 blackburn	ok
 blackburn	n4nd0: I'd suggest you to add method add_subset to kernel
 blackburn	n4nd0: for custom kernel it just delegates to set_row and set_col subsets
 blackburn	for others just checks lhs==rhs and sets subsets for lhs and rhs
 n4nd0	do you mean add_subset in KernelMachine or just in Kernel?
 blackburn	in kernel would be enough I think
 blackburn	thisway you may simply delegate it in add_machine_subset and remove_machine_subset
 n4nd0	aha I see what you mean
 n4nd0	and the method in kernel should be virtual so it can be specialized in CustomKernel
 blackburn	yeah
 blackburn	LUNCH TIME
 blackburn	:D
 n4nd0	enjoy your meal
-!- wiking [~wiking@huwico/staff/wiking] has quit [Quit: wiking]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Ping timeout: 264 seconds]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
 blackburn	re
-!- Jiuding [d2198538@gateway/web/freenode/ip.210.25.133.56] has quit [Ping timeout: 245 seconds]
-!- blackburn_ [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has joined #shogun
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has quit [Ping timeout: 245 seconds]
-!- l0nr4n [~l0nr4n@hugogascon.ml.tu-berlin.de] has joined #shogun
-!- l0nr4n [~l0nr4n@hugogascon.ml.tu-berlin.de] has quit [Changing host]
-!- l0nr4n [~l0nr4n@unaffiliated/l0nr4n] has joined #shogun
-!- vikram360 [~vikram360@117.192.163.50] has joined #shogun
-!- harshit_ [~harshit@182.68.142.173] has joined #shogun
-!- vikram360 [~vikram360@117.192.163.50] has quit [Ping timeout: 246 seconds]
-!- vikram360 [~vikram360@117.192.164.215] has joined #shogun
-!- harshit_ [~harshit@182.68.142.173] has quit [Ping timeout: 252 seconds]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: Lost terminal]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- gsomix [~gsomix@85.26.165.233] has joined #shogun
 gsomix	hi
 gsomix	philosophy is too deep for me :)
-!- gsomix [~gsomix@85.26.165.233] has quit [Client Quit]
-!- gsomix [~gsomix@85.26.165.233] has joined #shogun
-!- harshit_ [~harshit@182.68.142.173] has joined #shogun
 n4nd0	blackburn_: how important is to do the m_parameters->add(...) for each of the members of the class in the constructor?
 n4nd0	blackburn_: does it give problems sometimes?
 blackburn_	n4nd0: it is required for proper serialization
 n4nd0	wihout clear reason it has started to fail for a boolean member
 blackburn_	n4nd0: fail to compile?
 blackburn_	what is the error/member?
 n4nd0	seg fault
 n4nd0	is a float sorry not a boolean
 n4nd0	float64_t
 blackburn_	wait, segfault related to float64_t??
 n4nd0	yes
 blackburn_	show me the code
 blackburn_	i.e. it fails with m_parameters->add and float64_t??
 blackburn_	that shouldn't be possible
 n4nd0	http://snipt.org/ugDh0
 n4nd0	the line between the rpints and seg faults
 n4nd0	info from gdb
 n4nd0	Program received signal SIGSEGV, Segmentation fault.
 n4nd0	0xb4dd2170 in shogun::Parameter::add_type (this=0x917ec10, type=0xbfffecec, param=0x917d50c, name=0xb4e732bf "m_tolerance", description=0xb4e732ad "Tolerance member.") at base/Parameter.cpp:2369
 n4nd0	2369if (strcmp(m_params.get_element(i)->m_name, name) == 0)
 blackburn_	whoaa
 n4nd0	??
 blackburn_	no idea how can it be possible
 n4nd0	but it started to happen when I added this m_slog member
 n4nd0	a SGVector< int32_t >
 n4nd0	before that it was working good
 n4nd0	I cannot see any connection though
 blackburn_	try to comment it out then
 n4nd0	shit, now it seg faults in the next m_parameters->add
 n4nd0	something must have got messed while adding a new member
 n4nd0	I don't see why though
 sonne|work	n4nd0: stack overflow?
 blackburn_	sonne|work: how can it cause it
 n4nd0	sonne|work: do you mean because there may be too many attributes?
 sonne|work	maybe too much allocated on stack...
 sonne|work	what does valgrind say?
 n4nd0	in the moment that method is executed almost nothing has been allocated
 blackburn_	sonne|work: how can I reach you to get answer? :D
 sonne|work	I am just reading your email
 blackburn_	I asked you in mail yesterday
 sonne|work	I think what you want to do is a lot of work
 blackburn_	in irc
 blackburn_	and in mail again!
 blackburn_	no, I already did a half of it
 sonne|work	and I don't think that one should do this
-!- menonnik [~chatzilla@59.178.164.96] has joined #shogun
 sonne|work	just for the purpose of getting it published
 blackburn_	I like this idea pretty much
 blackburn_	no,  I like idea itself
 sonne|work	cheng seemed fine without this so there is no need
 blackburn_	sonne|work: it would be better in this way
 sonne|work	well of course you can do whatever you want but you need e.g. kernels/distances some interface to some other language or cmdline interface, some minimal build system
 blackburn_	no!
 sonne|work	that is >1 week of work
 menonnik	sir, i wanted some clarifications regarding implementation if C5.0. Are we training the data to form a tree or a rule set?
 blackburn_	sonne|work: it can even improve further development
 n4nd0	sonne|work: it executed with valrgind without seg fault
 blackburn_	I liked callbacks of OCAS
 sonne|work	but ocas has all this extra - extra matlab interface, extra implementation of dot features for sparse & dense, extra parallelizaed code, extra implementation for double and float...
 blackburn_	sonne|work: I don't want to create my own lib!
 blackburn_	I just want to extract code to some lib everyone can borrow as easy as libsvm
 blackburn_	or liblinear
 blackburn_	my point is just extract deep internals to libedrt.cpp
 blackburn_	with callback interface
 blackburn_	everything else should stay
 sonne|work	liblinear also has a cmdline interface & file format reader/writer
 blackburn_	well if they won't like it again I'll create some simple interface
 blackburn_	but this time I just want to extract its guts to make it borrowable
 blackburn_	I hope 3rd submission is possible?
 sonne|work	blackburn_: to publish you need to be able to show that your system works somehow - so you need to provide some example code - some interface
 sonne|work	they will need an interface
 blackburn_	it works with shogun..
 blackburn_	you suggest the same
 sonne|work	you should aim at getting it in this time for sure
 blackburn_	I do not understand your point :(
 sonne|work	and I don't see how a separation helps here
 blackburn_	because it would be hard to re-use that code anywhere
 sonne|work	what I mean is reviewers were rather positive. this and an improved selling of EDRT alone should suffice to get it accepted
 blackburn_	but with libedrt.cpp and callback it would be reusable
 blackburn_	all the converter stuff will just delegate its apply to libedrt
 blackburn_	sonne|work: so do you prefer to let code stay as it is?
 sonne|work	you didn't describe exactly what you want to do. to me it seems one can just use libshogun and do all the re-use one wants
 sonne|work	blackburn_: well yes but maybe you need to specify what you want to do before I can give a definitive answer
 blackburn_	sonne|work: I suggest to extract LLE/LTSA/all other stuff internals
 blackburn_	with callback distances/feature vector access/kernels
 n4nd0	sonne|work, blackburn_ : how can it be that it executes with valgrind but not alone?
 blackburn_	n4nd0: valgrind does some sandboxing..
 sonne|work	blackburn_: print functions, exceptions too - right?
 blackburn_	sonne|work: in that case one could borrow libedrt code and provide custom distances
 blackburn_	with no need to extend shogun somehow
 blackburn_	it is more custom than shogun
 blackburn_	sonne|work: why would I need any exceptions?
 blackburn_	but probably yes
 blackburn_	I don't think there should be any printing though
 sonne|work	error  messages / progress
 blackburn_	yeah, you are right, it would be needed
 blackburn_	sonne|work: so shogun's LLE would stay but it would delegate m_distance->distance(i,j) as callback
 sonne|work	and then you need implementations for every callback
 sonne|work	as illustration at least
 blackburn_	I need only distances, feature vector access and kernels
 blackburn_	nothing more
 sonne|work	(which is a lot already)
 blackburn_	&m_distance->distance
 sonne|work	so say gaussian kernel, euclidian dist, and dense realvalued features
 blackburn_	&m_kernel->kernel
 blackburn_	sonne|work: why should I write this?
 sonne|work	to publish a separate libedrt - you would need to show that it is sth useful so you need the functionality + some illustration how it can be used in the most simple case
 blackburn_	got it
 blackburn_	well not that much work
 blackburn_	sonne|work: again, would I need to do separate libedrt??
-!- gsomix [~gsomix@85.26.165.233] has quit [Quit: ????? ? ?? ??? (xchat 2.4.5 ??? ??????)]
 blackburn_	I see no difference between not 'touching it at all' and 'extract some code'
 blackburn_	in both ways it is dependent on shogun
 blackburn_	my intention is not about getting published
 blackburn_	but about getting it more useful
 sonne|work	blackburn_: in which way is it more useful? what can you do what you couldn't?
 blackburn_	sonne|work: one can borrow the code and use it w/o much changing it
 blackburn_	w/o changing at alll
 blackburn_	as for shogun - it makes me able to provide pretty nice custom options
 blackburn_	like computing full distance matrix or not
 blackburn_	same for kernels
 sonne|work	what do you mean by borrow the code?
 blackburn_	sonne|work: e.g. waffles can integrate this code in a day
 blackburn_	it is really easy to provide euclidean distance and feature vector access
 blackburn_	nothing more is required
 blackburn_	sonne|work: i.e. just like ocas but developed inside shogun
 sonne|work	so what you mean is: one only needs to integrate libedrt not whole libshogun?
 blackburn_	yeah
 blackburn_	libedrt is shogun independent in that means
 blackburn_	sonne|work: looks like you don't much like it?
-!- harshit_ [~harshit@182.68.142.173] has quit [Ping timeout: 260 seconds]
 blackburn_	sonne|work: point is while libedrt provides such custom interfaces
 blackburn_	i.e. distance/kernel callbacks
 sonne|work	not so much no... to use libedrt in shogun one then needs to create (like for libocas) all kinds of wrapping functions
 blackburn_	but in shogun it is possible to use it everywhere
 blackburn_	and use file features/etc
 blackburn_	sonne|work: all wrapping functions are already done in features, distances and kernels
 sonne|work	no not all - you need one more layer of wrapping functions, like compute_output in CSVMOcas
 blackburn_	sonne|work: ??
 sonne|work	that calls dense_dot_range
 sonne|work	so you would have e.g. KernelPCA and need a mean to get k(i,j)
 blackburn_	no, I'm not going to extract kernel pca
 sonne|work	so you need some kernel_function()
 blackburn_	it is a different kind of preprocessor
 blackburn_	only converters
 sonne|work	which underneath is calling kernel->kernel(i,j)
 blackburn_	sonne|work: yes, my interface prototype requires
 blackburn_	double (*kernel)(int, int)
 blackburn_	&m_kernel->kernel
 blackburn_	that's all
 blackburn_	same with distance
 blackburn_	and double* (*feature_vector)(int)
 sonne|work	no that won't work
 blackburn_	why?
 sonne|work	because kernel is not a static method
 sonne|work	so you need a wrapper function ' kernel_function(i,j)' within your class that knows about a kernel object
 blackburn_	ah I see
 blackburn_	it is not a problem at all
 sonne|work	within that you can then do kernel->kernel(i,j)
 blackburn_	I can just provide pointer there
 blackburn_	it is not a problem still
 blackburn_	sonne|work: I have to go now, thank you
 blackburn_	I hope you got my idea
 sonne|work	yeah I got your idea but I still don't like it :)
 blackburn_	sonne|work: damn
 blackburn_	sonne|work: I'll show code next week and then we decide
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: Lost terminal]
 blackburn_	I still think it would be useful even inside shogun (I can change things easier)
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
 blackburn_	see you
-!- blackburn_ [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has quit [Quit: Page closed]
-!- menonnik [~chatzilla@59.178.164.96] has quit [Read error: Connection timed out]
-!- menonnik [~chatzilla@59.178.164.96] has joined #shogun
-!- harshit_ [~harshit@182.68.142.173] has joined #shogun
 n4nd0	sonne|work: so it seems that getting rid of a couple of class members in QDA that were not used any more solved the problem
 n4nd0	sonne|work: but I still don't understand why it did happen
 sonne|work	n4nd0: did you by chance allocate some variables on stack?
 sonne|work	i mean like
 sonne|work	double bla[10000]
 sonne|work	?
 sonne|work	that would explain it
 sonne|work	(stack overflow)
 n4nd0	no
 sonne|work	SGVector<float64_t> x(1000) doesn't create on stack btw
 sonne|work	I mean the object yes but not the vector
 n4nd0	there was an SGVector, a float64_t, a boolean and some pointers
 sonne|work	hmmhh
 n4nd0	one of the members was SGVector
 n4nd0	maybe I should have used SGVector* even if I jus wanted one vector?
 n4nd0	just*
 sonne|work	no SGVector is merely a pointer and a boolean underneath
 n4nd0	then I don't understand why
 sonne|work	yeah me neither
-!- menonnik [~chatzilla@59.178.164.96] has quit [Quit: ChatZilla 0.9.88 [Firefox 10.0.2/20120215223356]]
 n4nd0	sonne|work: about valgrind, I get a huge quantity of errors when I run my python examples
 n4nd0	I am using a suprresions file, but still
 n4nd0	I have read sth about compiling python, do you know if it improves the results doing it that way?
 sonne|work	n4nd0: yeah one needs more suppressions for python...
 n4nd0	sonne|work: I will check how to do that then ...
 sonne|work	recompiling with certain settings would help - but these errors are there on purpose (faster ...)
 n4nd0	the problem is that I find it quite difficult to understand whether the code is buggy or not with all those messages
 sonne|work	what you can do is debug either just libshogun based c++ example or from octave modular or grep for shogun::
 sonne|work	it is tough for me too btw...
 n4nd0	libshogun based c++ example looks like the best option from my point of view
 n4nd0	it also increases the development time though
 sonne|work	n4nd0: well octave modular is also a good option
 sonne|work	(octave doesn't have valgrind errors)
 n4nd0	I will take a look with octave
 n4nd0	valgrind + octave right?
 sonne|work	yes
 sonne|work	just valgrind octave :)
 n4nd0	thank you
-!- harshit_ [~harshit@182.68.142.173] has quit [Ping timeout: 244 seconds]
 n4nd0	sonne|work: do you happen to know why some methods seem to be not accesible from octave?
 n4nd0	for example apply is not found from the example classifier_lda_modular.m
 n4nd0	for the class LDA
 n4nd0	does this have sth to do with swig?
-!- pythonroar [d2198538@gateway/web/freenode/ip.210.25.133.56] has joined #shogun
 pythonroar	how to hand up my student application?
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Quit: Leaving]
 n4nd0	pythonroar: the period is still not open, wait for next week
 n4nd0	pythonroar: check more info at http://news.gmane.org/gmane.comp.ai.machine-learning.shogun
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
-!- pythonroar [d2198538@gateway/web/freenode/ip.210.25.133.56] has quit [Quit: Page closed]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
-!- vikram360 [~vikram360@117.192.164.215] has quit [Ping timeout: 246 seconds]
-!- vikram360 [~vikram360@117.192.188.225] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Read error: No route to host]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Ping timeout: 276 seconds]
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Remote host closed the connection]
-!- PhilTillet [~Philippe@npasserelle10.minet.net] has joined #shogun
 PhilTillet	hey hey hey!
 PhilTillet	Hello -ChanServ-
@sonney2k	PhilTillet, hi
 PhilTillet	sonney2k, hi !
@sonney2k	PhilTillet, did you find some time to continue the benchmarking?
 PhilTillet	there's some progress :) I also have a conference to prepare :p I have done the gaussian kernel for what we talked about yesterday
 PhilTillet	based on the code of a matrix-matrix product
@sonney2k	well you cannot really assume that the whole matrix is in memory but yeah sometimes it is
 PhilTillet	i thought it worked to split the training set ?
@sonney2k	ahh you mean the set of x_i ?
@sonney2k	yes that one is in there
@sonney2k	but not the set of x (might be computed on demand)
 PhilTillet	but didn't you link a paper from ntu where it was explained?
 PhilTillet	how to train when data cannot fit in memory
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
@sonney2k	PhilTillet, wait this is a totally different problem
@sonney2k	one thing is to apply a trained classifier (this is what you are parallelizing) the other is about training
 PhilTillet	I see
 PhilTillet	So what do you do anyway on a CPU when training data cannot fit memory?
@sonney2k	stream the data from file and use anonline algorithm or sub-sample or ...
@sonney2k	(have to leave train)
@sonney2k	cu
-!- blackburn [~qdrgsm@83.234.54.68] has joined #shogun
-!- gsomix [~gsomix@188.168.2.59] has joined #shogun
-!- harshit_ [~harshit@182.68.142.173] has joined #shogun
-!- blackburn [~qdrgsm@83.234.54.68] has quit [Ping timeout: 265 seconds]
-!- blackburn [5bde8018@gateway/web/freenode/ip.91.222.128.24] has joined #shogun
-!- PhilTillet [~Philippe@npasserelle10.minet.net] has quit [Ping timeout: 252 seconds]
-!- l0nr4n [~l0nr4n@unaffiliated/l0nr4n] has quit [Quit: This computer (or maybe me) has gone to sleep]
 harshit_	hello
-!- blackburn_ [5bde8018@gateway/web/freenode/ip.91.222.128.24] has joined #shogun
-!- blackburn [5bde8018@gateway/web/freenode/ip.91.222.128.24] has quit [Ping timeout: 245 seconds]
 gsomix	harshit_, hi :)
 harshit_	Hey gsomix, hav a few questions, do you hav time ?
 gsomix	harshit_, unfortunately I do not have time. before I had prepared for laboratory work in physics and is now going to bed.
 gsomix	however, I wish you good night :)
 gsomix	bb
 harshit_	no worries .. hav a nice sleep
 blackburn_	harshit_:
-!- romi_ [~mizobe@187.57.1.50] has quit [Ping timeout: 246 seconds]
 harshit_	hey blackburn_ : do you hav time ?
 blackburn_	yes
 harshit_	i am porting newton svm to shogun for a while and now its almost done
 harshit_	Do i need to port the non linear version of newton svm too ?
 blackburn_	it is up to you
 harshit_	okay, and i am making use of  gmres function in lapack ,
 blackburn_	looks like this gsoc idea should be removed once you finish it
 harshit_	so can i make its wrapper in mathematics/lapack.h
 shogun-buildbot	build #186 of nightly_none is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/nightly_none/builds/186
 harshit_	i mean, am i allowed to push updates to mathematics/lapack.h
 harshit_	Also wanted to discuss my deep learning idea .
 harshit_	btw are you in the team of shogun ?
-!- blackburn_ [5bde8018@gateway/web/freenode/ip.91.222.128.24] has quit [Ping timeout: 245 seconds]
-!- PhilTillet [~Philippe@tillet-p42154.maisel.int-evry.fr] has joined #shogun
-!- romi_ [~mizobe@187.101.162.14] has joined #shogun
 shogun-buildbot	build #185 of nightly_all is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/nightly_all/builds/185
-!- blackburn [5bde8018@gateway/web/freenode/ip.91.222.128.24] has joined #shogun
-!- blackburn [5bde8018@gateway/web/freenode/ip.91.222.128.24] has quit [Ping timeout: 245 seconds]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
@sonney2k	n4nd0, I meant the octave_modular interface
@sonney2k	not the octave_static one
 n4nd0	sonney2k: I tried the example in that interface
 n4nd0	sonney2k: maybe I wrote static, sorry, but I tried in modular interface
@sonney2k	n4nd0, what did you try?
 n4nd0	sonney2k: octave_modular/classifier_lda_modular.m
@sonney2k	and what happened?
 n4nd0	error: member not found
 n4nd0	error: called from:
 n4nd0	error:   classifier_lda_modular.m at line 25, column 1
-!- l0nr4n [~l0nr4n@unaffiliated/l0nr4n] has joined #shogun
 n4nd0	sonney2k: any clue about that?
@sonney2k	I am compiling for octave_modular...
 n4nd0	ok
 n4nd0	what happens is that apply is not found in lda but I've no idea why
@sonney2k	IIRC it worked yesterday
 n4nd0	maybe there is something wrong with my environment
@sonney2k	n4nd0, it just works here
@sonney2k	which version of swig and octave?
 n4nd0	GNU Octave, version 3.2.4
@sonney2k	and are you sure that you did make install as root?
@sonney2k	lapack/atlas got also found?
 n4nd0	SWIG Version 2.0.4
@sonney2k	same here
@sonney2k	n4nd0, does classifier_libsvm_modular work?
 n4nd0	aham
 n4nd0	look here
 n4nd0	Checking for Atlas support ... no
@sonney2k	maybe that is the culprit
 n4nd0	facepalm for me ...
 n4nd0	I also note this
 n4nd0	Checking for Atlas support ... no
 n4nd0	ups sorry
 n4nd0	this one I meant
@sonney2k	install libatlas-dev  / libatlas-base-dev
 n4nd0	Checking for octave-config ... no
 n4nd0	is that an issue?
@sonney2k	n4nd0, octave-config is in octave3.2-headers pkg here
@sonney2k	I use this to determine link flags
 n4nd0	Atlas is still not detected by configure, I have installed the packages you told me
 n4nd0	maybe with libatlas-cpp-0.6-dev?
-!- harshit_ [~harshit@182.68.142.173] has quit [Quit: Leaving]
@sonney2k	n4nd0, hmmhh check configure.log
@sonney2k	I have libatlas3gf-base installed too
 n4nd0	sonney2k: oh, didn't know about this configure.log, thanks
 n4nd0	sonney2k: yeah I had that package too, must be another thing, I have to check it
-!- romi_ [~mizobe@187.101.162.14] has quit [Ping timeout: 246 seconds]
@sonney2k	though that shouldn't be the issue - if you have lapack/blas it should work nevertheless
 n4nd0	from the log I am reading clapack.h: No such file or directory
 n4nd0	didn't expect that since I have been using blas from C++
@sonney2k	n4nd0, ohh looks like clapack.h moved from /usr/include to /usr/include/atlas
@sonney2k	so try ./configure --includes=/usr/includes/atlas
-!- romi_ [~mizobe@187.57.11.40] has joined #shogun
 n4nd0	sonney2k: Atlat support ... yes :)
 n4nd0	let's see if this fixes the problem in octave
@sonney2k	n4nd0, don't forget to do make install as root (necessary for octave...)
@sonney2k	anyways I am off to bed. cu
 n4nd0	sonney2k: it is working now :)
@sonney2k	great
 n4nd0	sonney2k: thank you I'll check tom valgrind with octave then to check qda
 n4nd0	sonney2k: it is time to sleep for me too
 n4nd0	good night!
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
 CIA-64	shogun: Soeren Sonnenburg master * r1336edf / src/configure : add /usr/include/atlas detection upon configure - http://git.io/CVEklA
 shogun-buildbot	build #552 of r_static is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/r_static/builds/552  blamelist: sonne@debian.org
 shogun-buildbot	build #574 of cmdline_static is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/cmdline_static/builds/574  blamelist: sonne@debian.org
 shogun-buildbot	build #553 of octave_static is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/octave_static/builds/553  blamelist: sonne@debian.org
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Ping timeout: 276 seconds]
 shogun-buildbot	build #541 of python_static is complete: Failure [failed test_1]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/python_static/builds/541  blamelist: sonne@debian.org
 PhilTillet	So many bots !!!
 PhilTillet	:o
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
-!- romi_ [~mizobe@187.57.11.40] has quit [Ping timeout: 246 seconds]
--- Log closed Fri Mar 23 00:00:19 2012
