--- Log opened Sat Feb 23 00:00:49 2013
 shogun-notifier-	shogun: Sergey Lisitsyn :master * 7421ea5 / src/shogun/lib/tapkee/ (3 files): https://github.com/shogun-toolbox/shogun/commit/7421ea58a264f33fd8b271477f3548b19147e498
 shogun-notifier-	shogun: Updates for tapkee
 shogun-notifier-	shogun: Sergey Lisitsyn :master * d91f97e / src/shogun/lib/tapkee/routines/locally_linear.hpp: https://github.com/shogun-toolbox/shogun/commit/d91f97eafc85281a638bdd8a67f9fbd79588f018
 shogun-notifier-	shogun: Changed eigen old define to tapkee internal define
 shogun-buildbot_	build #867 of deb1 - libshogun is complete: Failure [failed compile]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/deb1%20-%20libshogun/builds/867  blamelist: Sergey Lisitsyn <lisitsyn.s.o@gmail.com>
-!- wiking [~wiking@info2k1.hu] has quit [Quit: leaving]
 shogun-buildbot_	build #868 of deb1 - libshogun is complete: Failure [failed compile]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/deb1%20-%20libshogun/builds/868  blamelist: Sergey Lisitsyn <lisitsyn.s.o@gmail.com>
 shogun-notifier-	shogun: Sergey Lisitsyn :master * 28c5f41 / src/shogun/lib/tapkee/routines/methods_traits.hpp: https://github.com/shogun-toolbox/shogun/commit/28c5f412fbae754d2a827264af96cf3170e3b263
 shogun-notifier-	shogun: Added missed method traits
 shogun-buildbot_	build #869 of deb1 - libshogun is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/deb1%20-%20libshogun/builds/869
-!- travis-ci [~travis-ci@ec2-54-242-202-157.compute-1.amazonaws.com] has joined #shogun
 travis-ci	[travis-ci] it's Sergey Lisitsyn's turn to pay the next round of drinks for the massacre he caused in shogun-toolbox/shogun: http://travis-ci.org/shogun-toolbox/shogun/builds/4993934
-!- travis-ci [~travis-ci@ec2-54-242-202-157.compute-1.amazonaws.com] has left #shogun []
 shogun-notifier-	shogun: Sergey Lisitsyn :master * 2ba8bb6 / src/shogun/lib/tapkee/ (7 files): https://github.com/shogun-toolbox/shogun/commit/2ba8bb6338b172145ccacb501c57be2dbc70aa39
 shogun-notifier-	shogun: Added projecting functions capabilities in tapkee
 blackburn	oh gosh 5 hours of that stuff
 shogun-buildbot_	build #227 of ubu1 - libshogun is complete: Failure [failed compile]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ubu1%20-%20libshogun/builds/227  blamelist: Sergey Lisitsyn <lisitsyn.s.o@gmail.com>
-!- travis-ci [~travis-ci@ec2-54-242-202-157.compute-1.amazonaws.com] has joined #shogun
 travis-ci	[travis-ci] it's Sergey Lisitsyn's turn to pay the next round of drinks for the massacre he caused in shogun-toolbox/shogun: http://travis-ci.org/shogun-toolbox/shogun/builds/4994111
-!- travis-ci [~travis-ci@ec2-54-242-202-157.compute-1.amazonaws.com] has left #shogun []
 shogun-buildbot_	build #228 of ubu1 - libshogun is complete: Failure [failed compile]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ubu1%20-%20libshogun/builds/228  blamelist: Sergey Lisitsyn <lisitsyn.s.o@gmail.com>
 shogun-buildbot_	build #556 of cyg1 - libshogun is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/cyg1%20-%20libshogun/builds/556
-!- n4nd0 [53b32c87@gateway/web/freenode/ip.83.179.44.135] has quit [Quit: Page closed]
 shogun-buildbot_	build #826 of deb3 - modular_interfaces is complete: Failure [failed test ruby_modular]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/deb3%20-%20modular_interfaces/builds/826  blamelist: Sergey Lisitsyn <lisitsyn.s.o@gmail.com>
-!- FSCV [~FSCV@187.210.54.166] has quit [Quit: Leaving]
 shogun-buildbot_	build #291 of nightly_default is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/nightly_default/builds/291
-!- shogun-notifier- [~irker@7nn.de] has quit [Quit: transmission timeout]
-!- hoijui [~hoijui@dslb-092-078-043-220.pools.arcor-ip.net] has joined #shogun
-!- hoijui [~hoijui@dslb-092-078-043-220.pools.arcor-ip.net] has quit [Ping timeout: 260 seconds]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
 n4nd0	blackburn: good morning
 n4nd0	I have just profiled isomap
 blackburn	n4nd0: hey
 n4nd0	checking the output now with kcachegrind
 n4nd0	do you want to take a look to the file?
 blackburn	oh cool, tell me what is the bottleneck
 blackburn	:)
 blackburn	callgrind you mean?
 blackburn	not really I can make it too - just let me know what is slow
 n4nd0	I cehck it with kcachegrind
 n4nd0	let me some time to analyze then :)
 n4nd0	blackburn: compute_shortest_distances_matrix is where the program spends the most time
 n4nd0	but that is sort of obvious I think
 blackburn	n4nd0: better surprise me
 blackburn	:D
 blackburn	n4nd0: actually sklearn implements that via cython
 blackburn	so no matter what we do it would be sort of similar
 n4nd0	blackburn: do you think we can do something smart there to make it faster?
 blackburn	n4nd0: some quantum computing
 n4nd0	??
 blackburn	n4nd0: but to be serious no, it seems we can't
 blackburn	may be some microoptimizations
 n4nd0	Eigen::redux_impl is the other part where the time is spent
 blackburn	n4nd0: not sure what it is
 n4nd0	blackburn: something that is called most of the times from compute_shortest_distances
 blackburn	n4nd0: may be that's a distance callback
 n4nd0	almost 10 million times for 1000 data point swissroll
 n4nd0	it is sth from Eigen::internal so I am not sure what it is either
 n4nd0	brb
-!- trtr3434 [~trtr3434@sta-104-34.tm.net.my] has joined #shogun
-!- trtr3434 [~trtr3434@sta-104-34.tm.net.my] has left #shogun []
 blackburn	almost 10 million times is surely distance
 n4nd0	blackburn: so it should be probably something called from Eigen to compute the distance
 blackburn	n4nd0: yes as distances are compute using eigen
 blackburn	n4nd0: ah btw
 blackburn	will you have time next friday?
 blackburn	friday's night to be more precise
 n4nd0	i think so
 n4nd0	why?
 n4nd0	blackburn: ^
 blackburn	n4nd0: chris will have some time and we planned to hack paper
 n4nd0	blackburn: cool
 n4nd0	I will be available then
 blackburn	n4nd0: nice
 blackburn	n4nd0: I think a few hours should be enough once everything software related is ready
 n4nd0	ok
 blackburn	n4nd0: we should release tapkee 0.1 I think
 n4nd0	blackburn: it sounds good
 blackburn	n4nd0: may be friday too
 n4nd0	blackburn: what do we need to have ready before release?
 blackburn	n4nd0: I don't know - it is pretty ok alread
 n4nd0	cool
 blackburn	n4nd0: I wanted to attempt to fix gpu
 blackburn	n4nd0: we aalso should get shogun released too :)
 n4nd0	blackburn: it is GPUDenseMatrixOperation and GPUDenseImplicitSquareMatrixOperation the parts that use GPU right?
 n4nd0	blackburn: hehe yeah
 blackburn	n4nd0: exactly
 n4nd0	blackburn: the results were normally the same, weren't they?
 n4nd0	it was only a matter of speedup?
 blackburn	n4nd0: I thought they weren't the same
 n4nd0	I remember I tested it
 blackburn	and it was just slower?
 n4nd0	I don't remember if the results were always the same
 blackburn	hmm okay
-!- shogun-notifier- [~irker@7nn.de] has joined #shogun
 shogun-notifier-	shogun: Sergey Lisitsyn :master * 064b53c / examples/undocumented/libshogun/library_hdf5.cpp: https://github.com/shogun-toolbox/shogun/commit/064b53cd4ac01a8438efb7abb4268d87b359c1bf
 shogun-notifier-	shogun: Added missed free in library hdf5 example
-!- travis-ci [~travis-ci@ec2-107-22-88-191.compute-1.amazonaws.com] has joined #shogun
 travis-ci	[travis-ci] it's Sergey Lisitsyn's turn to pay the next round of drinks for the massacre he caused in shogun-toolbox/shogun: http://travis-ci.org/shogun-toolbox/shogun/builds/5000219
-!- travis-ci [~travis-ci@ec2-107-22-88-191.compute-1.amazonaws.com] has left #shogun []
 shogun-buildbot_	build #229 of ubu1 - libshogun is complete: Failure [failed compile]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ubu1%20-%20libshogun/builds/229  blamelist: Sergey Lisitsyn <lisitsyn.s.o@gmail.com>
 shogun-buildbot_	build #827 of deb3 - modular_interfaces is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/deb3%20-%20modular_interfaces/builds/827
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
 shogun-notifier-	shogun: Sergey Lisitsyn :master * de82da5 / examples/undocumented/libshogun/library_serialization.cpp: https://github.com/shogun-toolbox/shogun/commit/de82da565a84e6a9fac01b7ba1ee2924fde772ed
 shogun-notifier-	shogun: Fixed leaks in library serialization
 shogun-notifier-	shogun: Sergey Lisitsyn :master * 5fcbf7b / src/shogun/lib/tapkee/ (3 files): https://github.com/shogun-toolbox/shogun/commit/5fcbf7b7f0df8492e99e21847dee86a876eb2d01
 shogun-notifier-	shogun: Old eigen support in tapkee and laplacian eigenmaps fix
-!- travis-ci [~travis-ci@ec2-107-22-88-191.compute-1.amazonaws.com] has joined #shogun
 travis-ci	[travis-ci] it's Sergey Lisitsyn's turn to pay the next round of drinks for the massacre he caused in shogun-toolbox/shogun: http://travis-ci.org/shogun-toolbox/shogun/builds/5001158
-!- travis-ci [~travis-ci@ec2-107-22-88-191.compute-1.amazonaws.com] has left #shogun []
 shogun-buildbot_	build #230 of ubu1 - libshogun is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ubu1%20-%20libshogun/builds/230
 shogun-buildbot_	build #231 of ubu1 - libshogun is complete: Failure [failed compile]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ubu1%20-%20libshogun/builds/231  blamelist: Sergey Lisitsyn <lisitsyn.s.o@gmail.com>
 shogun-notifier-	shogun: Sergey Lisitsyn :master * 77b9c8e / applications/ (32 files): https://github.com/shogun-toolbox/shogun/commit/77b9c8e936ab5258165f22b44e8800e7b501a5fe
 shogun-notifier-	shogun: Updated old edrt folder in applications
 shogun-buildbot_	build #232 of ubu1 - libshogun is complete: Failure [failed compile]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ubu1%20-%20libshogun/builds/232  blamelist: Sergey Lisitsyn <lisitsyn.s.o@gmail.com>
-!- travis-ci [~travis-ci@ec2-107-22-88-191.compute-1.amazonaws.com] has joined #shogun
 travis-ci	[travis-ci] it's Sergey Lisitsyn's turn to pay the next round of drinks for the massacre he caused in shogun-toolbox/shogun: http://travis-ci.org/shogun-toolbox/shogun/builds/5001926
-!- travis-ci [~travis-ci@ec2-107-22-88-191.compute-1.amazonaws.com] has left #shogun []
 blackburn	ubu1 is not being updated
 blackburn	argh
 shogun-buildbot_	build #233 of ubu1 - libshogun is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/ubu1%20-%20libshogun/builds/233
 blackburn	finally
-!- hoijui [~hoijui@dslb-092-078-043-220.pools.arcor-ip.net] has joined #shogun
 shogun-notifier-	shogun: Sergey Lisitsyn :master * 9554dab / src/shogun/structure/StructuredModel.h,src/shogun/structure/libbmrm.h: https://github.com/shogun-toolbox/shogun/commit/9554dab08344a46be07757dfb2ab0a9f8d8f50a3
 shogun-notifier-	shogun: Added some doc
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
 shogun-buildbot_	build #831 of deb3 - modular_interfaces is complete: Failure [failed test python_modular]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/deb3%20-%20modular_interfaces/builds/831  blamelist: Sergey Lisitsyn <lisitsyn.s.o@gmail.com>
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
-!- hoijui [~hoijui@dslb-092-078-043-220.pools.arcor-ip.net] has quit [Ping timeout: 252 seconds]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
 wiking	hu
 blackburn	hu!
-!- zxtx [~zv@c-24-18-130-24.hsd1.wa.comcast.net] has quit [Ping timeout: 255 seconds]
-!- zxtx [~zv@c-24-18-130-24.hsd1.wa.comcast.net] has joined #shogun
-!- shogun-notifier- [~irker@7nn.de] has quit [Quit: transmission timeout]
-!- hoijui [~hoijui@141.23.95.39] has joined #shogun
-!- hoijui [~hoijui@141.23.95.39] has quit [Ping timeout: 264 seconds]
@sonney2k	wiking, please bring bsd1 buildbot back to live
 wiking	sonney2k: shit it's again down
 wiking	up and runnnin
-!- hoijui [~hoijui@dslb-092-078-043-220.pools.arcor-ip.net] has joined #shogun
@sonney2k	wiking, thx
@sonney2k	wiking, can we get rid of this warning:
@sonney2k	http://shogun-toolbox.org/buildbot/builders/bsd1%20-%20libshogun/builds/691/steps/test/logs/warnings%20%281%29
-!- alexlovesdata [~binder@e178001222.adsl.alicedsl.de] has joined #shogun
 alexlovesdata	anybody still out there?
 alexlovesdata	I want to make CRandomFourierGaussPreproc applicable to CDotfeatures
 alexlovesdata	it seems that I have to derive a base class from CPreproc to define an interface for that
 alexlovesdata	my question is: what apply() interface that base class (I call it CDotPreproc) derived from Cpreproc should have?
 blackburn	alexlovesdata: hey there
 alexlovesdata	hey blackburn :)
 blackburn	alexlovesdata: let me check
 alexlovesdata	I will derive it from CPreprocessor ...
 blackburn	alexlovesdata: do you need out of sample for that preprocessor?
 blackburn	I guess so..
 alexlovesdata	what do you mean by out of sample?
 alexlovesdata	until now it is derived only from CDensePreprocessor<float64_t>
 blackburn	alexlovesdata: you need to 'learn' it on training data and then apply for test, right?
 alexlovesdata	no ...
 alexlovesdata	you initialize it once
 alexlovesdata	for testing you need to save the init parameters
 alexlovesdata	but the init parameters do not depend on the data
 alexlovesdata	however one needs to obtain a kernel width  estimate prior to using that ..
 blackburn	alexlovesdata: so you need to apply it to features only?
 alexlovesdata	yep
 blackburn	alexlovesdata: I am afraid no generic interface is here..
 alexlovesdata	but for application to test settings I need to save the settings via get_randomcoefficients ;)
 alexlovesdata	I think the same ...
 blackburn	whoops
 alexlovesdata	no problem ...
 blackburn	these functions are pretty wrong
 alexlovesdata	for me it is not clear how to apply this to sparse features other than mistreating them as dense ones
 blackburn	alexlovesdata: what is the output of applying it to sparse features?
 alexlovesdata	same ... for string features I would need a gaussian distribution in string space
 alexlovesdata	the output is a dense feature with a changed dimensionality
 blackburn	alexlovesdata: preprocessor part is heavily broken in some means :D
 blackburn	okay lets see
 blackburn	I do not mind to change that I just need to realize how
 alexlovesdata	ye ... to me it seems from the interface part also somewhat strange
 alexlovesdata	typically it would make sense to use it with streamingfeatures or any features over a numeric type
 alexlovesdata	a preprocessor gets one feature type as input but returns another feature type as output
 blackburn	alexlovesdata: it is actually 'converter'
 alexlovesdata	it should work on a feature matrix and on a single feature
 blackburn	alexlovesdata: all dimension reduction is in 'converter' folder
 alexlovesdata	for preprocessor we need a routine for checking the input and the output type
 alexlovesdata	of the feature
 blackburn	alexlovesdata: okay what about inheriting it from embeddingconverter
 alexlovesdata	eg RF preproc has as input type a set of allowed features ...
 blackburn	shogun/converter/EmbeddingConverter.h
 alexlovesdata	i look it up
 blackburn	alexlovesdata: it fits your requirement
 blackburn	input is any features
 blackburn	object
 blackburn	output is dense
 alexlovesdata	ye ... except that it lacks a check for allowed input feature type
 alexlovesdata	however that can be done during runtime
 blackburn	alexlovesdata: yeah just check it in embed method
 blackburn	alexlovesdata: I can help you with first step
 alexlovesdata	I need to check about conflicts with double inheritance w.r.t. to apply
 blackburn	I can move it to converter and then you will fix things you'd like to fix
 blackburn	alexlovesdata: double inheritance?
 alexlovesdata	ye, from CDensePreprocessor<float64_t>
 blackburn	alexlovesdata: no, it won't be inherited from dense preprocessor then
 alexlovesdata	and from Embeddingconverter
 blackburn	no, no double inheritance :)
 alexlovesdata	does it make sense to move it from the preprocessors to converters?
 alexlovesdata	any gain in usability?
 blackburn	alexlovesdata: well more generic interface (that embed method)
 blackburn	and apply
-!- hoijui [~hoijui@dslb-092-078-043-220.pools.arcor-ip.net] has quit [Ping timeout: 252 seconds]
 blackburn	alexlovesdata: so just cleaner interface
 blackburn	I do not know what to do with preprocessor yet
 blackburn	alexlovesdata: you don't use it as on-the-fly thing, right?
 alexlovesdata	with Cstreamingfeatures it would make pretty sende
 alexlovesdata	sense
 alexlovesdata	but for that i need an interface which converts one feature vector into another
 blackburn	hmm then I'd keep it in preprocessor
@sonney2k	alexlovesdata, err err
 alexlovesdata	ie x -> R(x)
 blackburn	you already have it here
 alexlovesdata	err err = ? thinking error?
 blackburn	master here
@sonney2k	alexlovesdata, you should implement your gaussianfourierfeatures form scratch
 blackburn	haha I'd say something about shogun from scratch
@sonney2k	don't even think about wasting brain & cpu cycles!
 alexlovesdata	with what goal/ direction Sonne?
@sonney2k	alexlovesdata, speed!
 alexlovesdata	huh
@sonney2k	there is almost no use for the stuff you did in the preprocessor!
 blackburn	I see nothing terribly wrong here
 blackburn	sonney2k: what is wrong?
 alexlovesdata	i have no experience w.r.t. to speed optimizations
@sonney2k	the difference is that dotfeatures only iterate over non-zero features
@sonney2k	for speed
 alexlovesdata	but if you tell me what you have in mind I can understand hopefully
 blackburn	but don't say anything about std::copy :D
@sonney2k	so doing a transformation x-> Phi(x) is not helpful
@sonney2k	(which is what preprocessors do)
 blackburn	alexlovesdata: he probably means you need to emulate dot and add
 blackburn	not to compute it explicitly
 alexlovesdata	or he means that I use the dot from it
 blackburn	sonney2k: I wish it was possible with HKM but it would be wrong
 alexlovesdata	in principle it can be done IF I can embed the vector as a dot feature itself ...
 alexlovesdata	that depends on the type of the dot feature
 blackburn	alexlovesdata: are these random features still relevenat?
 blackburn	relevant*
 alexlovesdata	if you like to approximate a gaussian kernel by transforming features
 alexlovesdata	so that the scalarproduct of the feature transform approx a gaussian, ye
@sonney2k	alexlovesdata, did you ask andrea about the post workshop stuff?
 blackburn	alexlovesdata: I mean HKM seems to be pretty cool enough
 alexlovesdata	not yet, Sonne
 alexlovesdata	HKM = hierarchical k-means?
@sonney2k	alexlovesdata, please do next week...
 alexlovesdata	ye, Sonne
 blackburn	alexlovesdata: homo gay map
@sonney2k	thx
 blackburn	alexlovesdata: err
 blackburn	homogeneous kernel map
 alexlovesdata	in principle it is the same
 alexlovesdata	for gaussian kernel
 blackburn	alexlovesdata: yeah but HKM can't approximate gaussian
 alexlovesdata	some of the HKM kernels are not useful in practice
 alexlovesdata	i would say gaussian is a special case of HKM approximations
 blackburn	alexlovesdata: which ones? I had good experience with any kernel with HKM..
 blackburn	alexlovesdata: ah I wanted to ask you some things about my stupid kind of research
@sonney2k	alexlovesdata, regarding dotfeatures - just implement sparse_dot and add_to_dense vec as fast as possible
@sonney2k	so no copying around etc
 alexlovesdata	RF is just another case of homogeneous kernel map
@sonney2k	and e.g. for sparse features it helps a lot to not first create a dense feature vector :)
@sonney2k	but just operate on the non-zero components (if possible)
@sonney2k	only then the DotFeatures framework is fast
@sonney2k	gtg
 alexlovesdata	Sonne ... I would say: it should suffice to embed the stuff in a dotfeature itself
 alexlovesdata	then I could use its dot
 alexlovesdata	if you say: implement sparse_dot ... you mean for the preprocessor?
 alexlovesdata	as far as I see it Sonne ... I would need to define for each dot feature type a way to define the gaussian in the space of the dot feature
 alexlovesdata	thats not generic
 alexlovesdata	like gaussian in string space
 alexlovesdata	i would need to do that for each derived class (!)
 alexlovesdata	I have to think about that ...
 alexlovesdata	I see no fast ad hoc solution right now
 alexlovesdata	ok I think I have an idea ... for Dotfeatures and for creating of streamingfeatures from existing ones ...
-!- alexlovesdata [~binder@e178001222.adsl.alicedsl.de] has left #shogun []
--- Log closed Sun Feb 24 00:00:49 2013
