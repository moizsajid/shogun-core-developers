--- Log opened Fri Feb 15 00:00:46 2013
-!- heiko [~heiko@027d8b72.bb.sky.com] has quit [Quit: Leaving.]
 n4nd0	good night guys
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: leaving]
-!- FSCV [~FSCV@204.45.110.163] has quit [Quit: Leaving]
-!- blackburn [~blackburn@188.168.128.140] has quit [Quit: Leaving.]
-!- pari [6eeaec2a@gateway/web/freenode/ip.110.234.236.42] has joined #shogun
 pari	Hi all, I am new to this community and am willing to start contributing to the toolbox. It would be very helpful if you could supply me with possible ideas/ areas to look into. Thanks in advance.
-!- blackburn [~lisitsin@mxs.kg.ru] has joined #shogun
 blackburn	pari: try to run compile and then try some examples, subscribe to the mailing list and check out ideas at github
 blackburn	*remove 'run' word
-!- sumit [73f91219@gateway/web/freenode/ip.115.249.18.25] has joined #shogun
@sonney2k	blackburn, what is wrong with the API? YOu could easily create SGMatrix etc from opencv matrices
@sonney2k	thanks to us using MALLOC & friends
@sonney2k	with zero overhead...
-!- pari [6eeaec2a@gateway/web/freenode/ip.110.234.236.42] has quit [Ping timeout: 245 seconds]
 blackburn	sonney2k: no, nothing wrong at all - I just have a feeling it could be better somehow
 blackburn	sonney2k: although I have no idea how
@sonney2k	SGMatrix<float64_t>(opencvmat, m,n, false)
@sonney2k	then do whatever?
@sonney2k	how can it be more simple?
@sonney2k	only way I can think of is directly using their features
-!- hoijui [~hoijui@dslb-092-078-043-220.pools.arcor-ip.net] has joined #shogun
 blackburn	sonney2k: have you ever played to sid meier's alpha centauri?
 sonne|work	no
-!- sumit [73f91219@gateway/web/freenode/ip.115.249.18.25] has quit [Ping timeout: 245 seconds]
-!- n4nd0 [~nando@n145-p173.kthopen.kth.se] has joined #shogun
 sonne|work	n4nd0: do we have any news on the website? http://shogun-toolbox.org/page/Events/gsoc2013 looks awful now intermixed with the WS
 n4nd0	sonne|work: I started taking a look last week to the website code in github but nothing else
 n4nd0	I will focus on it from now on during my time shogun-ing
 blackburn	sonne|work: what is ws?
 n4nd0	blackburn: workshop
 blackburn	ah
-!- flx_ [~flx@fb.ml.tu-berlin.de] has joined #shogun
-!- flx_ [~flx@fb.ml.tu-berlin.de] has left #shogun []
-!- flxb [~flx@fb.ml.tu-berlin.de] has joined #shogun
-!- flxb [~flx@fb.ml.tu-berlin.de] has quit [Quit: leaving]
-!- flxb [~flx@fb.ml.tu-berlin.de] has joined #shogun
-!- flxb [~flx@fb.ml.tu-berlin.de] has quit [Ping timeout: 244 seconds]
-!- flxb [~flx@fb.ml.tu-berlin.de] has joined #shogun
-!- flxb [~flx@fb.ml.tu-berlin.de] has quit [Ping timeout: 244 seconds]
-!- heiko [~heiko@nat-164-235.internal.eduroam.ucl.ac.uk] has joined #shogun
-!- n4nd0 [~nando@n145-p173.kthopen.kth.se] has quit [Ping timeout: 252 seconds]
-!- flxb [~flx@fb.ml.tu-berlin.de] has joined #shogun
-!- n4nd0 [~nando@n145-p173.kthopen.kth.se] has joined #shogun
-!- n4nd0 [~nando@n145-p173.kthopen.kth.se] has quit [Client Quit]
-!- n4nd0_ [~nando@n145-p173.kthopen.kth.se] has joined #shogun
-!- n4nd0_ is now known as n4nd0
 n4nd0	blackburn: Georg has done a very nice job!
-!- hoijui [~hoijui@dslb-092-078-043-220.pools.arcor-ip.net] has quit [Quit: Leaving]
 blackburn	n4nd0: yeah
-!- tom___ [2eda6d52@gateway/web/freenode/ip.46.218.109.82] has joined #shogun
 tom___	hi
 n4nd0	blackburn: so what do you think of his main idea? the first one listed in the gdocs
 n4nd0	hey tom___
 tom___	I would like some precision about output format in shogun (hdf5, json, ascii .. )
 tom___	which one is more mature ? which one would you recommand ,
 n4nd0	tom___: what do you want to do?
 tom___	saving/loading multiclass machine, features, labels ..
 n4nd0	I guess it depends a bit on your preferences, what you feel most comfortable with
 tom___	I am running with c++ api and would like to plot some results with python then save in c++ load in python
 n4nd0	if you are going to use large volumes of data, then you should go for hdf5 maybe
 n4nd0	AFAIK it should be the most efficient of those
 tom___	size of ascii files seems smaller than with hdf5 ? possible ?
 n4nd0	if you are not storing lot of data, it might be possible
 tom___	mmmh
 tom___	both format are compatible with the python api ?
 n4nd0	tom___: using shogun methods you mean?
 tom___	yes!
 n4nd0	yeah, they should be
 n4nd0	have you taken a look to python examples?
 n4nd0	let me see
 tom___	what format do you use yourself ? :)
 n4nd0	I have not really used them for large applications
 n4nd0	just small tests and IIRC I used ascii
 n4nd0	tom___: I see that features_io_modular.py
 n4nd0	under examples/undocumented/python/
 n4nd0	uses the three formats
 n4nd0	ascii, binary and hdf5
 n4nd0	maybe it can help you decide which one you want to select
 tom___	allright thanks for advices
 tom___	have a nice day
 n4nd0	tom___: thanks, you too
-!- tom___ [2eda6d52@gateway/web/freenode/ip.46.218.109.82] has quit [Quit: Page closed]
-!- FSCV [~FSCV@187.210.54.166] has joined #shogun
-!- FSCV_ [~FSCV@204.45.110.163] has joined #shogun
-!- FSCV [~FSCV@187.210.54.166] has quit [Ping timeout: 252 seconds]
-!- blackburn [~lisitsin@mxs.kg.ru] has quit [Quit: Leaving.]
-!- flxb [~flx@fb.ml.tu-berlin.de] has quit [Ping timeout: 264 seconds]
-!- lambday [b6131049@gateway/web/freenode/ip.182.19.16.73] has joined #shogun
-!- n4nd0 [~nando@n145-p173.kthopen.kth.se] has quit [Quit: leaving]
-!- flxb [~flx@fb.ml.tu-berlin.de] has joined #shogun
 sonne|work	http://www.youtube.com/watch?feature=player_embedded&v=VFGxWVZ7tgo
 sonne|work	^ blackburn - such stuff can only happen in rossia :)
 heiko	man, I hope blackburn is still alive :)
 sonne|work	heiko: do you use eclipse and c++?
 heiko	sonne|work, yes, why?
 wiking	http://www.youtube.com/watch?feature=player_embedded&v=OaREmEdXZe4
 wiking	:D
 heiko	wiking thats fake
 wiking	nice photoshop :D
-!- flxb [~flx@fb.ml.tu-berlin.de] has quit [Ping timeout: 248 seconds]
-!- sonne|work [~sonnenbu@sams-office-nat.tomtomgroup.com] has quit [Quit: Leaving.]
-!- heiko [~heiko@nat-164-235.internal.eduroam.ucl.ac.uk] has quit [Quit: Leaving.]
-!- heiko [~heiko@nat-164-235.internal.eduroam.ucl.ac.uk] has joined #shogun
-!- KMcQuisten [d8338942@gateway/web/freenode/ip.216.51.137.66] has joined #shogun
 KMcQuisten	Is there a set way to make the shogun wrapper of LibSVR perform nu-SVR, or is it hardwired to do epsilon-SVR?
-!- alexlovesdata [~binder@2001:638:806:e001:eda1:1d04:97b:c9f] has joined #shogun
-!- FSCV_ [~FSCV@204.45.110.163] has quit [Ping timeout: 245 seconds]
-!- heiko [~heiko@nat-164-235.internal.eduroam.ucl.ac.uk] has quit [Quit: Leaving.]
-!- FSCV [~FSCV@187.210.54.166] has joined #shogun
 KMcQuisten	Anyone alive, or are you all sleeping on the other side of the world?
-!- FSCV_ [~FSCV@173.254.212.46] has joined #shogun
 alexlovesdata	here
-!- FSCV [~FSCV@187.210.54.166] has quit [Ping timeout: 248 seconds]
-!- KMcQuisten [d8338942@gateway/web/freenode/ip.216.51.137.66] has quit [Quit: Page closed]
-!- heiko [~heiko@nat-164-235.internal.eduroam.ucl.ac.uk] has joined #shogun
-!- blackburn [~blackburn@85.114.170.181] has joined #shogun
 heiko	blackburn, does it make sense to allow the tube epsilon for model selection?
 heiko	and epsilon?
 blackburn	heiko: I remember that question!
 heiko	see email
 blackburn	heiko: yeah
 heiko	so?
 heiko	just add this?
 blackburn	heiko: okay it won't hurt right?
 heiko	no, its just: does it make sense?
 blackburn	heiko: I think it can be considered
 blackburn	just some more flexibility
 heiko	ok then, here we go
 blackburn	wiking: about video - it is not fake but it was in tajikistan :D
 blackburn	not that meteorite thing
 blackburn	heiko: ah you said it is fake - it is not :)
 heiko	blackburn, really?
 heiko	this was said on a german news webiste
 heiko	glad you still live :)
 blackburn	heiko: it is some gas fire
 heiko	we would be screwed without you
 heiko	o
 blackburn	heiko: fake is that it was caused by meteorite
 heiko	yeah thats what I meant, not the meteor
 blackburn	it happened before in other country
 blackburn	but actually it happened :)
 alexlovesdata	good the blackburn did not loose too much of his brain due to meteorite strike :D
-!- shogun-notifier- [~irker@7nn.de] has joined #shogun
 shogun-notifier-	shogun: Heiko Strathmann :master * 9f1daba / src/shogun/classifier/svm/SVM.cpp: https://github.com/shogun-toolbox/shogun/commit/9f1daba1d32cc786614f64f5fd7088bd2b88aa3b
 shogun-notifier-	shogun: added epsilon and tube_epsilon for model selection
 shogun-notifier-	shogun: Heiko Strathmann :master * 83d3fbe / src/shogun/classifier/svm/SVM.cpp: https://github.com/shogun-toolbox/shogun/commit/83d3fbed74dc4f9fd77f1a968b5f4cef4280e548
 shogun-notifier-	shogun: Merge pull request #877 from karlnapf/master
 shogun-notifier-	shogun:
 shogun-notifier-	shogun: added epsilon and tube_epsilon for model selection
 blackburn	alexlovesdata: pretty far away from me
 blackburn	you know, close is 1000 km for me
 blackburn	it is somewhat 1500 km far away I think :D
 heiko	haha
 blackburn	alexlovesdata: I have lost my brain due to vodka though!
 blackburn	alexlovesdata: http://cs14112.userapi.com/c7005/v7005319/3d3/xD8UN_by11E.jpg see mr. poutine riding
 blackburn	http://s.pikabu.ru/post_img/2013/02/15/8/1360930135_841226929.jpg that's how russian tv looks like
 alexlovesdata	uhh
 alexlovesdata	WW3 welcome :|
 alexlovesdata	do we have some hidden long range cannon under the north polar ice cap?
 alexlovesdata	do the russians operate devices like this??
 blackburn	alexlovesdata: russians exchanged everything to vodka
 blackburn	:D
 blackburn	alexlovesdata: ahh I was searching for this pic to show to you
 blackburn	http://s.pikabu.ru/post_img/2013/02/15/5/1360911381_1738019492.jpg
 blackburn	alexlovesdata: translating: chelyabinsk (the place hit by that stone) before stone shower
 blackburn	and chelyabinsk after stone shower
 blackburn	heiko: ha! have you seen that mail? local alignment kernel as gsoc project
 heiko	what?
 heiko	blackburn, good idea
 heiko	although most of them should be there
 heiko	its just a mess to use
 blackburn	heiko: most of what?
 heiko	would be good to cleanup and have examples and proper documentation
 heiko	string kernels
 blackburn	ah yes
 blackburn	but not only one kernel
 blackburn	heiko: who can mentor that?
 heiko	s?ren :D
 blackburn	heiko: anyone else? :D
 heiko	maybe oli stegle?
 heiko	but he is busy in Cambridge now :=)
 heiko	dont know
 heiko	but would be good to have
 heiko	since many biologists out there
 heiko	and its an easy project
 blackburn	the more ideas we have the more difficult it would be to choose
 heiko	so far most of the projects are more advanced
 blackburn	but the final choice should get better too
 blackburn	yes I want to improve biological part of shogun
 blackburn	as I don't solve any biological problems I do not understand anything
 heiko	I know a little bit about these kernels so I could help out a bit if e.g. the main mentor is too busy
 heiko	but would be better to have some expert
 blackburn	yes
 blackburn	may be I should ask chris
 blackburn	he should know something :D
 heiko	yes, I mean they are close to this
 alexlovesdata	I wonder a bit ...
 blackburn	heiko: have you seen they moved gsoc thingy a month forward?
 heiko	not seen
 blackburn	it ends sept. 27
 heiko	what means forward?
 heiko	to later
 alexlovesdata	can we optimize large scale primal svms when the features do not fit into memory?
 heiko	uh
 alexlovesdata	I know Cstreamingfeatures anf vowpal wabbit
 blackburn	heiko: and it starts a bit later
 blackburn	heiko: and I won't receive t-shirt :D
 alexlovesdata	I was thinking: what strategies do we have for that mega large scale case?
 blackburn	due to rules
 blackburn	alexlovesdata: ultra mega scale
 blackburn	alexlovesdata: good q
 blackburn	alexlovesdata: we have outdated vowpal wabbit though
-!- sumit [73f91219@gateway/web/freenode/ip.115.249.18.25] has joined #shogun
-!- lambday [b6131049@gateway/web/freenode/ip.182.19.16.73] has quit [Ping timeout: 245 seconds]
-!- sumit [73f91219@gateway/web/freenode/ip.115.249.18.25] has quit [Ping timeout: 245 seconds]
 shogun-notifier-	shogun: Heiko Strathmann :master * 2e37cd5 / / (11 files): https://github.com/shogun-toolbox/shogun/commit/2e37cd5beea2fc7f827611e4155b8025fc11bba2
 shogun-notifier-	shogun: Made new kernel selection methods for linear time MMD available under modular interfaces.
 shogun-notifier-	shogun: Includes some other minor changes
 shogun-notifier-	shogun: Heiko Strathmann :master * 17d6ba9 / / (11 files): https://github.com/shogun-toolbox/shogun/commit/17d6ba9eb5fea2d38673b03ef28c72f81ffe425f
 shogun-notifier-	shogun: Merge pull request #878 from karlnapf/master
 shogun-notifier-	shogun:
 shogun-notifier-	shogun: kernel selection for linear time mmd for modular interfaces
-!- heiko [~heiko@nat-164-235.internal.eduroam.ucl.ac.uk] has left #shogun []
@sonney2k	alexlovesdata, hey there
 alexlovesdata	hey sonney2k
 alexlovesdata	I am thinking of an MKL extension on cross-validation data
 alexlovesdata	so that it works beter in practice
 alexlovesdata	on Sunday I consider to write some KDA for shogun ... once I got behing ther git monster
@sonney2k	alexlovesdata, about the after workshop happening
 alexlovesdata	yep ... what will be the input to Andrea?
@sonney2k	could you or someone from the TU people take care of the crowd?
 alexlovesdata	yes I could do
@sonney2k	like AZ
 alexlovesdata	andreas Z ?
@sonney2k	or if chris is around (he is officially TU right?)
@sonney2k	yes
@sonney2k	I am away sadly :/
 alexlovesdata	I can sk AZ whether he likes to join in helping me ... but what is the motivation of AZ to help me?
 alexlovesdata	Chris will help because he is involved in it clearly
@sonney2k	alexlovesdata, he will mentor ICA for shogun anyways
 alexlovesdata	ahhh , ok
@sonney2k	so it might get him connected to the crowd?
@sonney2k	he might like it
 alexlovesdata	ye ... I can ask him with the pretext that he will anyway mentor it
 alexlovesdata	any special expectations about taking care of the crowd?
@sonney2k	I guess you only need some official who is around from beginning to end on the weekend
@sonney2k	you could probably split this up
 alexlovesdata	should be doable
@sonney2k	I would have organized that thing more early but we wanted it to be as close as possible to ISMB
@sonney2k	(and me around) might not be close  enough but nevertheless
@sonney2k	alexlovesdata, for ultra mega large scale we use mean(x) > threshold
@sonney2k	btw ;)
 alexlovesdata	how does mean(X)
 alexlovesdata	> threshold help in that?
@sonney2k	alexlovesdata, ultra mega largescale boils down to computing *simple* statistics
@sonney2k	and simple rules
@sonney2k	no more
@sonney2k	everything else is beyond ...
@sonney2k	but yes we don't have anything distributed
@sonney2k	as in map-reduce & friends
 alexlovesdata	hmmm ... that could be something for GSOC ;)
@sonney2k	so we can only realisticly handle a billion of examples
 alexlovesdata	where does the limit come from?
@sonney2k	actually there is no limit
@sonney2k	it is just that you need a fast harddisk to stream data
 alexlovesdata	svm optimization could be parallelized in principle
@sonney2k	with streaming features you can just ask: 'give me the next example'
@sonney2k	alexlovesdata, yeah but that is not the bottleneck
@sonney2k	bottleneck is reading from disk
 alexlovesdata	well ... fast hard disks are no problem since the arrival of ... ;)
@sonney2k	no
@sonney2k	they are dog slow
@sonney2k	you can do thousands of svm iterations while reading the next example from disk
 alexlovesdata	SSDs??
@sonney2k	so mini-batch algorithms are fast
@sonney2k	yes even ssds are dog slow
 alexlovesdata	but one could work on distrobuted batches
@sonney2k	it is like <300MB/s vs. 10GB/s main memory speed vs. 1000GB/s cache speed
 alexlovesdata	the problem is an interface that is flexible to a lot of ways of parallelization
@sonney2k	that would just give you cache misses
-!- sumit [75e10b98@gateway/web/freenode/ip.117.225.11.152] has joined #shogun
 alexlovesdata	I would not dare to comentor GPU svms
@sonney2k	but I agree there is lots of stuff one could do
@sonney2k	GPU svms are overhyped
@sonney2k	they can be *only fast* if all data fits in GPU memory
 alexlovesdata	yep ...
@sonney2k	so lets say you have 2 G of GPU mem
 alexlovesdata	that expeerience I had with clustering on GPUs already
@sonney2k	that woudl be a tiny problem
@sonney2k	so it is useless
 alexlovesdata	but distributed SVMs is a thing we can try
@sonney2k	considering that I was solving 60G problems with SVMs 5 years ago
@sonney2k	I would say linear SVMs with piece wise linear functions is the thing you should use
 alexlovesdata	piece wise linear on what?
 alexlovesdata	you mean locally linear SVMs ?
@sonney2k	with shogun these piece wise linear functions can be implicilty used so you can have a svm-normal vector of a few GB but only say 100 dimensional input data
@sonney2k	no linear SVMs but you use binary features:
@sonney2k	look at http://www.shogun-toolbox.org/doc/en/2.0.1/classshogun_1_1CBinnedDotFeatures.html
@sonney2k	got to leave the train
 alexlovesdata	why losing information with binarization?
@sonney2k	you hardly do
@sonney2k	l8r
 alexlovesdata	is there any paper on that to udnerstand it?
 alexlovesdata	ok I understand it
 alexlovesdata	roughly ... not fully
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
@sonney2k	alexlovesdata, I got some pretty good results with that and extremely fast... it is more expressive than linear - just depending on the number of bins
@sonney2k	alexlovesdata, what I would hope is that fastfood (smolas paper) would give us sth even better w/ kernels
 alexlovesdata	I have to read the fast food paper
 alexlovesdata	well ... for the most common kernel ... linear
 alexlovesdata	RF features always allow to use primal solveras
 alexlovesdata	similar developments exist for other kernels ... see the paper by vedaldi
@sonney2k	RF?
 alexlovesdata	random fourier features
 alexlovesdata	one needs to be careful about kernel weight
 alexlovesdata	but one can get a transform such that the transformed features approximate a gaissuan kernel
 n4nd0	sonney2k: you won't be around during the workshop? :(
@sonney2k	n4nd0, I will be around during workshop but not on saturday/sunday in the hands-on session :/
@sonney2k	alexlovesdata, that you can do such transformation is not sufficient
 n4nd0	oh that's a pity :(
@sonney2k	alexlovesdata, you cannot precompute these features
 n4nd0	sonney2k: but we will see you during the workshop :)
@sonney2k	alexlovesdata, you have to do that on-the-fly and very very fast
@sonney2k	otherwise you gain nothing
 alexlovesdata	you just need to save the generating coefficients
 alexlovesdata	then RF acts as a preprocessors
 alexlovesdata	which transforms on the fly
 alexlovesdata	or do you see any problems about that?
@sonney2k	alexlovesdata, no - I am just thinking that this would be some easy student task to prepare for gsoc
@sonney2k	http://berkeley.intel-research.net/arahimi/papers/rahimi-recht-random-features.pdf
@sonney2k	implement algorithm 1 here
@sonney2k	just a a shogun preprocessor
 alexlovesdata	it is implemented alreade :D
@sonney2k	for the gaussian kernel
@sonney2k	alexlovesdata, what?
@sonney2k	name?
 alexlovesdata	wait ... I find the name of it in shogun
@sonney2k	ohh randomfouriergausspreproc :D
 alexlovesdata	http://www.shogun-toolbox.org/doc/en/2.0.1/classshogun_1_1CRandomFourierGaussPreproc.html
@sonney2k	obviously
 alexlovesdata	hahaha, yes
@sonney2k	haha
 alexlovesdata	:)
@sonney2k	stso then randombinning too :D
 n4nd0	nobody really knows everything in SHOGUN :D
 alexlovesdata	stso = ?
 alexlovesdata	shogun ... the dark dungeons
 n4nd0	hehe
* sonney2k is impressed
* n4nd0 too
@sonney2k	I guess I just use 10% of shogun
 alexlovesdata	most of us use 0.5% I would say
 alexlovesdata	anyway it might be useful to read about fastfood
 alexlovesdata	I just want to get this tourine here going and then drive home
 alexlovesdata	tourine =routine
@sonney2k	alexlovesdata, I think this preprocessor should better be defined as DotFeatures... then any linear SVM could directly work on this
 alexlovesdata	you are  right ... I could do that on Sunday
@sonney2k	would be faster than preprocessing all the time
 alexlovesdata	or try ;)
@sonney2k	alexlovesdata, btw where did you do the FFT?
 alexlovesdata	+ write an example which compares against a real gaussian on small scale data
@sonney2k	and where is the sin() ?
 alexlovesdata	you need only the cos ... if I remember correctly
@sonney2k	int the paper above they have sin(w'x) and cos(w'x)
 alexlovesdata	if I remember correctly there was a way to get around the sin ...
 alexlovesdata	I will check that on sunday
 alexlovesdata	below equation (2) in the paper
 alexlovesdata	other mappings such as ...
 alexlovesdata	also satisfy the condition ...
 alexlovesdata	there is a mapping cos(wx +b)
 alexlovesdata	that I had implemented
@sonney2k	sqrt(2) cos(wx+b) ok
@sonney2k	alexlovesdata, I think in fast food they have RF and also random hadamart (sp?) features
@sonney2k	but this stuff really only kicks ass if we have it as dot features
 alexlovesdata	hadamard ... could be
 alexlovesdata	I will take care of it on sunday for dot features
 alexlovesdata	and of an example
 alexlovesdata	... will do the example first
@sonney2k	but still consider we need 1000 w's for the approximation - it might actually be very expensive compared to learning piece-wise linear functions
@sonney2k	but I never did care enough to compare this
 alexlovesdata	it blows up dimensions, though 100 was enough when i tested it
 alexlovesdata	thats why I asked abt strategies when the features do not fit into mem
@sonney2k	alexlovesdata, with dot features you don't need factor 100 more memory
@sonney2k	but just the SVM-w will be 100 times bigger
@sonney2k	that can be very fast - since also very cache-friendly
@sonney2k	maybe we can broaden the fastfood project in this respect
-!- sumit [75e10b98@gateway/web/freenode/ip.117.225.11.152] has quit [Ping timeout: 245 seconds]
 alexlovesdata	I go home
 alexlovesdata	will continue from home :|
@sonney2k	alexlovesdata, see you!
-!- alexlovesdata [~binder@2001:638:806:e001:eda1:1d04:97b:c9f] has left #shogun []
@sonney2k	traceroute 216.81.59.173
@sonney2k	*lol*
-!- shogun-notifier- [~irker@7nn.de] has quit [Quit: transmission timeout]
 n4nd0	it got lost after the fifth hop here
--- Log closed Sat Feb 16 00:00:14 2013
