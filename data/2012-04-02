--- Log opened Mon Apr 02 00:00:13 2012
--- Day changed Mon Apr 02 2012
 harshit_	okay.doing that ..
 n4nd0	sonney2k, blackburn new pull request :)
 blackburn	it seems I stare to github whole day long hah
 blackburn	n4nd0: I'll review it in a min
 n4nd0	blackburn: thank you man, but no hurries, it is kind of late already
@sonney2k	harshit_, I am starting to fall asleep - but I want to see the updated output before I do so please do it now if you can
 n4nd0	blackburn: just tell me a general opinion if so
 blackburn	n4nd0: do you prefer commenting code here or at github? ;)
@sonney2k	n4nd0, cool figures
 n4nd0	blackburn: let's do it at github better
 blackburn	ok
 n4nd0	sonney2k: thank you :D
 n4nd0	sonney2k: did you see the one I prepared for multiclass svm?
@sonney2k	no
 n4nd0	sonney2k: http://dl.dropbox.com/u/11020840/shogun/multiclass_svm.png
 n4nd0	sonney2k: I didn't expect that flower shape haha
@sonney2k	cool
@sonney2k	I should check whether my son recognizes this as flower :D
@sonney2k	saying bluuu bluu (flower == blume in german)
 n4nd0	haha
 n4nd0	blomma in Swedish
 n4nd0	there are similarities
 blackburn	sonney2k: your son is kind of talking already?!
 blackburn	n4nd0: are you sure it works only for euclidean?
@sonney2k	might be an illusion but I think he starts to recognizing flowers - at least every time I got close to one he is making this weird bluuu  bluee sound
 n4nd0	blackburn: I didn't check it :S
 blackburn	sonney2k: cool
 harshit_	sonney2k: hey figured that out .. it was not the problem in the values , it was the problem with the way i was printing them
 harshit_	the actual problem was something else
 harshit_	:)
 harshit_	:)
-!- PhilTillet [~Philippe@tillet-p42154.maisel.int-evry.fr] has joined #shogun
@sonney2k	harshit_, so enlighten us!
 harshit_	actually problem was that i was resetting value of t to 0 in function line_search_linear
 harshit_	where as it needed to be calculated by using its previous value
 harshit_	Just need some more testing then i'll send you the final test results on both c++ and matlab
 shogun-buildbot	build #652 of libshogun is complete: Failure [failed compile]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/libshogun/builds/652  blamelist: sonne@debian.org, shelhamer@imaginarynumber.net
 blackburn	ah yes btw it fails
 blackburn	:D
 blackburn	I'll take care
 CIA-64	shogun: Soeren Sonnenburg master * ra2a559c / testsuite/python_modular/tester.py : add -m option to tester to show only missing tests - http://git.io/4kFzJA
@sonney2k	nite folks
 blackburn	sonney2k: nite
 n4nd0	good night
@sonney2k	harshit_, good to hear - I think we will need to compare newton svm from C++ to some bigger data set once you are confident again that it works
@sonney2k	cu
 harshit_	sonney2k : wait
 harshit_	for 2 min
 harshit_	see here : http://snipt.org/ugiic5
 blackburn	no way :D
 harshit_	is he gone ?
 blackburn	yes
 harshit_	shit
 harshit_	then please you have a look
 n4nd0	I had enough for today too guys
 n4nd0	good night
 blackburn	hah
-!- Vuvu [~Vivan_Ric@115.248.130.148] has quit [Remote host closed the connection]
-!- romi_ [~mizobe@187.74.1.223] has quit [Quit: Leaving]
 blackburn	n4nd0: nite
 harshit_	good bye n3nd0
 n4nd0	harshit_: idk if I can help you with that, what is the problem?
 harshit_	problem is with precision of float64_t
 n4nd0	mmm no idea what's going on there
 blackburn	yeah hard to digest
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has left #shogun []
-!- Vuvu [~Vivan_Ric@115.248.130.148] has joined #shogun
 blackburn	harshit_: hey but h's are different!
 harshit_	I think i have messed up a lil with the label values
 harshit_	in sleep :(
 blackburn	hah no worries
 harshit_	dont knw what i am doing, I think i should continue tmrw
 harshit_	maybe everything requires a clean test again
 CIA-64	shogun: Sergey Lisitsyn master * ra17ad85 / (3 files): Fixes for SG_ADD conversion - http://git.io/-T635w
 harshit_	blackburn: hey do you think liblinear + lbp features + wiking preprocessor will make a good proposal
 harshit_	vs
 harshit_	c5.0 + liblinear
 blackburn	c5.0 is much more time demanding and important for me
 harshit_	may be i should submit both , what say ?
 blackburn	feel free if you want to do that :)
-!- av3ngr [av3ngr@nat/redhat/x-mtbcichayakoymjc] has joined #shogun
 harshit_	btw would you also apply for gsoc ?
 harshit_	if so then what project would you be working on ?
 blackburn	yes, for multitask learning
-!- PhilTillet [~Philippe@tillet-p42154.maisel.int-evry.fr] has quit [Ping timeout: 252 seconds]
 harshit_	transfer learning is really nice field :) would be nice to see it in shogun
 harshit_	good bye, going to sleep.
-!- harshit_ [~harshit@182.68.67.61] has quit [Remote host closed the connection]
 blackburn	good night
-!- PhilTillet [~Philippe@npasserelle10.minet.net] has joined #shogun
-!- PhilTillet [~Philippe@npasserelle10.minet.net] has quit [Ping timeout: 245 seconds]
-!- PhilTillet [~Philippe@npasserelle10.minet.net] has joined #shogun
-!- blackburn [~qdrgsm@31.28.44.229] has quit [Quit: Leaving.]
 shogun-buildbot	build #654 of libshogun is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/libshogun/builds/654
-!- PhilTillet [~Philippe@npasserelle10.minet.net] has quit [Ping timeout: 265 seconds]
-!- flxb [~cronor@e178169137.adsl.alicedsl.de] has left #shogun []
-!- Vuvu [~Vivan_Ric@115.248.130.148] has quit [Quit: Leaving]
-!- harshit_ [~harshit@182.68.67.61] has joined #shogun
-!- harshit_ [~harshit@182.68.67.61] has quit [Ping timeout: 246 seconds]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- harshit_ [~harshit@182.68.67.61] has joined #shogun
-!- menonnik [b4953181@gateway/web/freenode/ip.180.149.49.129] has joined #shogun
@sonney2k	harshit_, for liblinear/ocas not a lot of work (maybe close to nothing) might be necessary - so implementing other dotfeatures might be sth to focus on and of course if you intend to work on trees in general - also fine
 harshit_	sonney2k: So would you prefer liblinear + c5.0
 harshit_	or liblinear + lbp + some other features
@sonney2k	dotfeatures + c5.x
@sonney2k	or other trees
 harshit_	ohk got it, so trees are in demand.
 harshit_	sonney2k : for Newton SVM , it was definitely  not precision issue
@sonney2k	well we don't have any trees in there - so it would be nice to have any
 harshit_	there is some other small problem, which i am searching for last 3hrs
 harshit_	will get you on it,As soon i'll find it
@sonney2k	but other stuff is also fine - we will have to see how many slots we get and how we can divide work then so a little flexibility is necessary
@sonney2k	harshit_, thanks!
 harshit_	so in trees would c5.0 will be the best to implement, the c5.0 released under gnu license
 harshit_	or you have something else in your mind ?
 harshit_	Also i dont want to waste the current time, So want to start working on LBP features
 harshit_	Saw opencv code: it looks good
 CIA-64	shogun: Evan Shelhamer master * r4f1e9e5 / src/README.developer : Cleanup doc whitespace and word wrap - http://git.io/7Afz_Q
 CIA-64	shogun: Evan Shelhamer master * r787d681 / src/README.developer : (log message trimmed)
 CIA-64	shogun: Revise whitespace and versioning scheme sections of the developer readme
 CIA-64	shogun: - include notice of newline convention (LF) and how to enforce it automatically
 CIA-64	shogun:  through git settings
 CIA-64	shogun: - rephrase trailing whitespace caution and suggest means to automatically
 CIA-64	shogun:  strip trailing whitespace for emacs and vim
 CIA-64	shogun: - update versioning section with info on github and suggested workflow
 CIA-64	shogun: Soeren Sonnenburg master * r142a356 / src/README.developer :
 CIA-64	shogun: Merge pull request #411 from shelhamer/readme-whitespace-and-versioning
 CIA-64	shogun: Developer Readme whitespace and versioning - http://git.io/ss8t6w
-!- menonnik [b4953181@gateway/web/freenode/ip.180.149.49.129] has quit [Quit: Page closed]
 harshit_	sonney2k: ^
-!- gsomix [~gsomix@188.168.4.80] has quit [Read error: Operation timed out]
-!- sonne|work [~sonnenbu@194.78.35.195] has joined #shogun
-!- mridul [~Adium@61.12.27.114] has joined #shogun
-!- gsomix [~gsomix@188.168.4.80] has joined #shogun
-!- harshit_ [~harshit@182.68.67.61] has quit [Ping timeout: 248 seconds]
-!- harshit_ [~harshit@182.68.67.61] has joined #shogun
 sonne|work	moin gsomix
 harshit_	sonney2k: https://gist.github.com/2281396, have a look at line 17,18,19 in C++ output and 18,19,20 in Matlab output
 harshit_	n4nd0 : if you are around, please have a look at https://gist.github.com/2281396
 n4nd0	harshit_: so what's the problem?
 harshit_	actually precision is the problem ,
 harshit_	as you can see in line 19 of C++
 harshit_	and in line 21 of matlab
 harshit_	g = gpart1- gpart2
 n4nd0	aham
 harshit_	g after subtraction comes out to be of order e-17
 n4nd0	there is a little error around here
-!- mridul [~Adium@61.12.27.114] has left #shogun []
 n4nd0	but what's g? is it the difference between the result you get with matlab and C++?
 harshit_	yeah and thats bocz of high precision in matlab
 harshit_	no g is just a variable used for getting the results
 n4nd0	ok
 n4nd0	but the difference between C++ and matlab is ~e-17??
-!- stephenlee [da18b3c4@gateway/web/freenode/ip.218.24.179.196] has joined #shogun
 harshit_	yeah its a very small difference but the problem is that in next line of code i compute g/h
 harshit_	as h is also of order e-17 , g/h turn out to be some thing large
 harshit_	and here the difference becomes prominent
 n4nd0	aham
 n4nd0	I see
 harshit_	do you think i should move on with it ..
 harshit_	coz it really doesnt make any big impact on final result
 n4nd0	so the final result is ok?
 harshit_	yeah in most cases, the difference is of order of 1e-5 at most
 harshit_	in final result
 n4nd0	in my opinion, that is ok
 n4nd0	but you should ask sonney2k just in case
 harshit_	have a look here : http://snipt.org/ugjp4
 harshit_	thats one of the big differences i have encountered
 harshit_	do you think thats acceptable
 n4nd0	I see
 n4nd0	idk, I mean, there's probably no general answer to that
 n4nd0	I guess it depends on application
 harshit_	yeah, right may be i need to do some real tests
 harshit_	on it
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Quit: Changing server]
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
 n4nd0	harshit_: have you already thought of any particular example to test it?
 harshit_	not yet, why ? do you have any in your mind ?
 n4nd0	mmm I would try with classification of toy data first
 n4nd0	if you get good results / similar to MATLAB
 n4nd0	it will be ok I guess
 harshit_	ohk will do it tday, lets hope for best :)
-!- flxb [~cronor@141.23.80.206] has joined #shogun
-!- flxb [~cronor@141.23.80.206] has quit [Quit: flxb]
-!- flxb [~cronor@141.23.80.206] has joined #shogun
-!- flxb [~cronor@141.23.80.206] has left #shogun []
-!- flxb [~cronor@fb.ml.tu-berlin.de] has joined #shogun
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has joined #shogun
 blackburn	oh good old sonne|work haven't seen you there for a while ;)
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has quit [Ping timeout: 244 seconds]
 sonne|work	heh
 blackburn	sonne|work: do you think development and master line separating is a good idea? I do
-!- vikram360 [~vikram360@117.192.173.130] has quit [Ping timeout: 265 seconds]
 sonne|work	I don't understand why it is a good idea...
 sonne|work	in my brain (at least currently) master is always the most up-to-date thing
 blackburn	sonne|work: something like debian stable as master and debian unstable as development? :)
 sonne|work	but where is master in all this?
 sonne|work	I mean what is master needed for then?
 sonne|work	we currently have branches for shogun 1.X etc
 sonne|work	but never use them (unfortunately)
 sonne|work	so we don't really fix bugs and release 1.1.1 / 1.1.2 ...
 blackburn	sonne|work: what is master for you?
 sonne|work	but always work on master
 sonne|work	master is development branch for me - the thing that is most recent
 blackburn	in this approach current master should go to developmen
 sonne|work	of course it makes sense to have branches for new complicated features
 blackburn	other way is to create stable branch
 sonne|work	like the (rotten) c5.0 branch
 blackburn	one example
 blackburn	we wanted to release
 blackburn	so we would separate branch from some march revision
 blackburn	before this new features
 blackburn	and merge fixes
 sonne|work	yeah I agree to that
 blackburn	in fact I think we are way too fast to have releases
 blackburn	:D
 sonne|work	I don't think so :D
 blackburn	I can hardly imagine somebody would want to install old shogun
 sonne|work	but that is the reality!
 sonne|work	people only install release versions!
 blackburn	sonne|work: what I do not like is to create branches for each fix
 blackburn	sonne|work: yes that'd right if we had .deb
 sonne|work	we should create automagically created debs / releases every night
 sonne|work	only when the test suite passes
 blackburn	it would be costly for me to get into .deb packaging ;)
 blackburn	will you have time to manage this?
 blackburn	however we have mighty gsomix!
 blackburn	:D
 blackburn	gsomix: would you like to set it up later? ;)
 blackburn	hey that's kind of good idea to add to your proposal
 blackburn	sonne|work: do you like it?
 blackburn	gsomix: do not afraid to be overloaded with it, it would be more interesting than hunt for covertree memleaks
 blackburn	gsomix: ok even two extensions of your proposal: auto deb (with ppa probably) and auto tests improvement
-!- n4nd0 [~nando@n179-p53.kthopen.kth.se] has joined #shogun
 gsomix	blackburn, ou.
 gsomix	blackburn, I'll read it later. But, I agree to everything.
-!- PhilTillet [~Philippe@ASte-Genev-Bois-152-1-52-104.w82-121.abo.wanadoo.fr] has joined #shogun
 blackburn	gsomix: and again start writing proposal, proposal would never be wrote by itself ;)
 gsomix	blackburn, ok. Once I get back from the gym.
 blackburn	are you used to visit gym? you never told me that before :)
 gsomix	blackburn, in university.
 blackburn	ah that kind of
 gsomix	Classes in physical culture.
 gsomix	Bjjj.
 blackburn	lolz
 blackburn	you have 17 minutes more, get the python4 support done!
 gsomix	More defines!
 gsomix	#defines, i mean
 blackburn	ah yes one more funny thing you can deal with
 blackburn	is to add common lisp typemaps
 blackburn	:D
 blackburn	yeah why not
 gsomix	haskell
 blackburn	IIRC there is no haskell support for swig
 blackburn	who would ever need this shit
 gsomix	There is part in swig documentation "Extending SWIG to support new languages".
 blackburn	nevertheless I can hardly imagine this stuff in haskell
-!- stephenlee [da18b3c4@gateway/web/freenode/ip.218.24.179.196] has quit [Ping timeout: 245 seconds]
 harshit_	blackburn : good news :) every thing is working perfectly now in Newton SVM
 harshit_	hurray :D
 harshit_	now just gonna test it on toy dataset
 blackburn	harshit_: that's nice
 harshit_	thanks for your support blackburn and n4nd0
 blackburn	oscar award speech ;)
 harshit_	lol
 harshit_	cant wait for my first open source contribution to be accepted
 blackburn	is it your first PR?
 harshit_	PR ?
 blackburn	pull request
 harshit_	to an open source organization - yes.
 blackburn	I see
 harshit_	but had some PR on private git hub repos
 blackburn	I just thought you commited some things before
-!- harshit_ [~harshit@182.68.67.61] has quit [Ping timeout: 260 seconds]
-!- PhilTillet [~Philippe@ASte-Genev-Bois-152-1-52-104.w82-121.abo.wanadoo.fr] has quit [Quit: Leaving]
-!- PhilTillet [~Philippe@ASte-Genev-Bois-152-1-52-104.w82-121.abo.wanadoo.fr] has joined #shogun
-!- nickon [~noneedtok@dD5774105.access.telenet.be] has joined #shogun
-!- n4nd0 [~nando@n179-p53.kthopen.kth.se] has quit [Ping timeout: 246 seconds]
-!- nickon [~noneedtok@dD5774105.access.telenet.be] has quit [Client Quit]
-!- nickon [~noneedtok@dD5774105.access.telenet.be] has joined #shogun
-!- n4nd0 [~nando@n179-p53.kthopen.kth.se] has joined #shogun
-!- vikram360 [~vikram360@117.192.161.93] has joined #shogun
-!- PhilTillet [~Philippe@ASte-Genev-Bois-152-1-52-104.w82-121.abo.wanadoo.fr] has quit [Read error: Connection reset by peer]
 n4nd0	blackburn: regarding one of the comments in th PR
 blackburn	yes
 n4nd0	blackburn: you mean that it should work with sparse features too?
 blackburn	why not?
 blackburn	all you need is distance so you don't have to check it
 n4nd0	yes, it looks reasonable for me
 n4nd0	blackburn: but we are just talking about simple or sparse features right?
 n4nd0	blackburn: I am checking some of the other types of CDotFeatures though
 blackburn	n4nd0: let the distance check it :0
 blackburn	:)
 n4nd0	blackburn: do you mean that it shouldn't be checked here?
 blackburn	yes, distance should I think
 n4nd0	in case it cannot be done, the distance will lock it when doing get_distance_matrix
 blackburn	it should throw SG_ERROR on init
 n4nd0	in init yeah
 n4nd0	I got to that part right now :D
 n4nd0	blackburn: btw, I think I am not really familiarized with the idea of test suite and I probably should
 n4nd0	blackburn: I understand that it's something we use to check the behaviour of the build right?
 n4nd0	blackburn: that everything is working fine
 blackburn	n4nd0: it compares output with previous one
 n4nd0	blackburn: ok
 n4nd0	blackburn: we should always be sure that the previous one is ok then :P
 blackburn	if they are equal - life is good
 blackburn	yes
 n4nd0	ok
 n4nd0	this might make me look kind of stupid but ...
 n4nd0	I think I have never run this testsuite
 blackburn	you don't have to
 n4nd0	is it something we should ourselves? or done in the buildbot?
 blackburn	well we have to
 n4nd0	so?
 n4nd0	do I have to run it or not?
 blackburn	hah if you want to check something - yes
 blackburn	I mean in any case I run it sometimes and Soeren does
 n4nd0	ok
 blackburn	try to run it anyway
 blackburn	just cd to testsuite/python_modular
 blackburn	and run tester.py
 n4nd0	oh
 n4nd0	should all of them be ok??
 n4nd0	maybe I'm missing a library or sth, I got quite a few of ERROR, some exceptions and it ended with a seg fault :O
 blackburn	they should but they are not ok :D
 n4nd0	haha ok
 n4nd0	is the seg fault normal??
 n4nd0	last file was
 n4nd0	kernel_sparse_gaussian_modular.py setting 1/2                ERROR
 blackburn	it could be related to some serialization stuff we need to fix still
 n4nd0	ok
 n4nd0	I have also noted distance_mahalanobis_modular.py setting 1/1                  NO TEST
 n4nd0	I guess I should provide one
 n4nd0	same for QDA
 blackburn	yes we need to generate tests for new ones
 blackburn	it is pretty straightforward btw
 blackburn	generator.py examplename.py
 n4nd0	distance_mahalanobis_modular.py setting 1/1                  OK
 n4nd0	:D
 n4nd0	blackburn: about the other comment at github
 n4nd0	blackburn: the one related to the embed_distance idea
 blackburn	yes
 blackburn	just do as it was done in mds and isomap
 n4nd0	blackburn: do you have time for it a moment now?
 blackburn	yes a little
 n4nd0	blackburn: didn't notice that it's done like that in the others
 blackburn	I think apply should init distance with given features and delegate all the things to embed_distance
 blackburn	and embed_distance should do all the job
 n4nd0	looks nice like that
 n4nd0	I have to understand exactly what is the job of embed distance though
 n4nd0	in one case it should do exactly as it does now
 blackburn	yes, the only difference is distance initialization
 n4nd0	mmm I think I don't understand that clearly
 n4nd0	initialization is simple m_distance->init(features, features) right?
 blackburn	yes
 blackburn	embed_distance makes sense if you have distances but do not have features
 n4nd0	no ASSERT(features) then
 n4nd0	?
 blackburn	where?
 blackburn	def apply(features):
 blackburn	  m_distance.init(features,features)
 blackburn	  return embed_distance(m_distance)
 blackburn	def embed_distance(distance):
 blackburn	  all the SPE stuff assuming distance is inited
 n4nd0	aham, I see
 n4nd0	but should sth else be added to handle the custom distance case you talked about?
 blackburn	yes if you want to precompute it prematurely
 blackburn	all you need is
 blackburn	def apply(features):
 gsomix	hi all
 blackburn	  m_distance.init(features,features)
 blackburn	  dist = CustomDistance(m_distance)
 blackburn	  return embed_distance(dist)
 n4nd0	then is it just required another apply to handle this case?
 blackburn	yes
 blackburn	just pass custom distance to embed_distance
 n4nd0	blackburn: ok, I think I got it, thank you very much :)
 blackburn	welcome
 blackburn	;)
-!- vikram360 [~vikram360@117.192.161.93] has quit [Read error: Connection reset by peer]
-!- vikram360 [~vikram360@117.192.161.93] has joined #shogun
-!- av3ngr [av3ngr@nat/redhat/x-mtbcichayakoymjc] has quit [Quit: That's all folks!]
 n4nd0	blackburn: ups I got a problem with git when I tried to push the new stuff
 n4nd0	error: failed to push some refs to 'git@github.com:iglesias/shogun.git'
 n4nd0	To prevent you from losing history, non-fast-forward updates were rejected
 n4nd0	Merge the remote changes (e.g. 'git pull') before pushing again.  See the
 n4nd0	'Note about fast-forwards' section of 'git push --help' for details.
 n4nd0	I think it is the same as the other day
 n4nd0	I should just do git push --force??
 n4nd0	or should I pull as it suggests me
 blackburn	no better try to rebase your branch
 blackburn	or to merge
 n4nd0	I did rebase before the push
 n4nd0	I think that is why this is happening
 blackburn	yes
 blackburn	n4nd0: is it a branch?
 blackburn	n4nd0: your master is not up to date
 blackburn	try to push your master to github
 blackburn	and then push your branch once again
 blackburn	i.e. you rebased it locally but not on github
 blackburn	should work if I understand that correctly
-!- wiking [~wiking@78-23-191-201.access.telenet.be] has joined #shogun
-!- wiking [~wiking@78-23-191-201.access.telenet.be] has quit [Changing host]
-!- wiking [~wiking@huwico/staff/wiking] has joined #shogun
 n4nd0	I needed to pull
 n4nd0	it was in a branch yes
 n4nd0	but my master is up to date, I did it a few moments ago
 blackburn	your local master or github one?
 blackburn	I checked your github fork and last commit was 3 days ago
 n4nd0	ah fuck it was my local one
 wiking	blackburn: ey
 n4nd0	maybe it was because of that
 n4nd0	I did the pull and solve a couple of conflicts
 blackburn	wiking: hey
 blackburn	n4nd0: yes keep master up to date
 wiking	blackburn: ok so you haven't got time yet right?
 blackburn	both masters
 blackburn	wiking: hmm it seems I have actually
 wiking	since i haven't seen a reply by you
 blackburn	ahhh
 wiking	or maybe it slipped my eyes
 blackburn	I did not understand :D
 blackburn	wiking: did you get alex' idea
 blackburn	?
 sonne|work	guys you should really discus on the ML
 wiking	noup
 blackburn	hah right
 blackburn	sonne|work: but we are talking about old mail
 blackburn	wiking: I'd suggest you to answer to ml this time
 blackburn	but I still do not understand the idea
 blackburn	:D
 sonne|work	well then invite him to this irc chat and ask him online :D
 blackburn	sonne|work: yeah I think that's the thing wiking should do ;)
 wiking	blackburn: he is on Skype rather than irc imho
 sonne|work	wiking: so what - send him the irc web url and grab him - tell him that I said that :)
 wiking	:>>>>
 wiking	ok
 n4nd0	blackburn: I updated the PR
 n4nd0	blackburn: I think I might have screwed though :S because of the merge
 n4nd0	blackburn: can you take a quick look and tell if it is ok or if I should do sth?
 blackburn	yes
 n4nd0	blackburn: thank you man
 sonne|work	wiking: btw did you submit your proposal?
 blackburn	n4nd0: allright
 blackburn	n4nd0: one more thing to go is to convert it to rather distance than distance matrix
 blackburn	this means you would have to store pointer to distance in lle point
 blackburn	err spe point
 blackburn	i.e. all distance_matrix[i*N+j] -> distance->distance(i,j)
 n4nd0	aham I see
 wiking	sonne|work: not yet
 sonne|work	but you plan to right?
 wiking	sonne|work: deadline is on the 7th right
 wiking	yep
 sonne|work	6th iirc
 sonne|work	but you might want to iterate with your potential mentor...
 blackburn	hurry up!
 blackburn	gsomix: and you as well
 sonne|work	(one can update until apr. 6)
 wiking	:>>
 wiking	i'll do something till tomorrow i think
 n4nd0	blackburn: just in SPE_COVERTREE_POINT or also in embed_distance? the change to distance->distance(i, j)
 blackburn	n4nd0: everywhere probably
 blackburn	overhead of custom distance is rather slow
 blackburn	low
 blackburn	so it is almost the same
 n4nd0	blackburn: then covertree has to be changed, instead of SGMatrix -> CDistance
 n4nd0	CDistance* actually
 blackburn	yes exactly
 n4nd0	I am with that right now then
-!- gsomix [~gsomix@188.168.4.80] has quit [Ping timeout: 276 seconds]
-!- gsomix [~gsomix@83.234.169.79] has joined #shogun
-!- harshit_ [~harshit@182.68.67.61] has joined #shogun
 flxb	Hello
 n4nd0	flxb: hi there
 flxb	I have a weird error. I get Illegal instruction errors for some (!) shogun examples on some (!) nodes on our cluster. On other nodes everything works find. The nodes should have the same setup. The examples that fail have Illegal instruction in the next line in this listing: http://pastebin.com/mGWShRP1 Does anyone have any idea what this could be?
 n4nd0	where does that Illegal instruction come from?
 n4nd0	I mean, you redirect the output of the python scripts /dev/null right?
 flxb	yes
 flxb	but apparently illegal instruction errors are not redirected
 n4nd0	mmm
 n4nd0	I just executed the script and didn't get any of those Illegal instructions
 n4nd0	let me check again
 n4nd0	what do you get without /dev/null?
 n4nd0	in particular for those that give illefal instruction
 n4nd0	illegal*
 flxb	i get http://pastebin.com/mJFhEJam
 flxb	it must occur when shogun apply gets called
 n4nd0	mmm
 n4nd0	I think I need more hints because I cannot reproduce that illegal instruction in my machine
 n4nd0	I can execute classifier_domainadaptationsvm_modular.py without problems
 blackburn	wtf is illegal instruction
 n4nd0	I think it is something related to the processor
 flxb	n4nd0: it works on some nodes here too
 blackburn	flxb: could you please paste configure output somewhere?
 blackburn	it can be related to -march parameter of gcc
 harshit_	n4nd0,blackburn : how can i make use of toy dataset in C++ , it doesn't seems to be in plain text
 blackburn	why not to use it from python?
 n4nd0	harshit_: what kind of format does the file have?
 flxb	blackburn: configure output is here: http://pastebin.com/0wKEJjrW
 flxb	blackburn: maybe it's worth mentioning that i had to change swig to swig2.0 in configure file
 harshit_	blackburn : my python is not very good, Actually I can test it in octave.
 blackburn	flxb: shouldn't cause it
 flxb	ok
 harshit_	n4nd0: its *.dat and *.mat
 blackburn	flxb: actually you could try to compile with --disable-optimization
 n4nd0	harshit_: binary files then?
 harshit_	not really when i open DynProg in text editor it shows some weird symbols
 blackburn	flxb: it worths mentioning you have pretty old gcc btw
 n4nd0	harshit_: then they are binary files ( != text files )
 n4nd0	harshit_: I don't think there is something in shogun to read directly .dat and .mat in C++
 n4nd0	harshit_: it's what we discussed last week
 harshit_	yeah
 harshit_	have to make use of octave then
 n4nd0	harshit_: python works good for them too
 harshit_	I remember, Also in 2011 ideas list there were some project related to this issue
 flxb	blackburn: should i try with Checking for GCC & CPU optimization abilities ... k8?
 harshit_	project to enable shogun to support mat 7.0 files
 harshit_	that seems interesting too
 blackburn	flxb: k8? it seems you have xeon, why k8?
 blackburn	I don't think we really need it - it is oneliner in python
 flxb	blackburn: i did --disable-optimization, but i am now on a different node. can this be the problem?
 blackburn	flxb: what do you mean? did you compile with disable opt?
 flxb	blackburn: no, i did not, i will try that now
 blackburn	I see
 flxb	but previously i compiled on another node
 blackburn	flxb: are they identical?
 blackburn	in case of optimizations enabled that could cause some troubles
 flxb	blackburn: yes i guess that is the problem
 flxb	one is Quad-Core AMD Opteron(tm) Processor 2378, the other one is Intel(R) Xeon(R) CPU
 blackburn	ah
 blackburn	yes could be a problem for sure
 blackburn	then just compile on each machine separately with optimizations enabled
 blackburn	should work
 blackburn	it is some mtune or march or other hardware-related option issue
 flxb	how much performance drawbacks do i have if i just disable optimization?
 blackburn	depends what are you doing
 blackburn	however I haven't seen any drawback larger than 1.5x
-!- Marty28 [~Marty@158.181.76.57] has quit [Quit: ChatZilla 0.9.88.1 [Firefox 11.0/20120310010446]]
 flxb	blackburn: ok. everything works now!
 flxb	thanks!
 n4nd0	cool
 blackburn	whoa I don't like to work 8 hours straight :(
 n4nd0	blackburn: lot of things to do at the job?
 blackburn	n4nd0: no, but sitting for 8 hours..
 blackburn	I mean it bothers to not change activities/place :)
 n4nd0	aham
 sonne|work	harshit_: totally fine if you come up with an octave modular example
 harshit_	sonne|work : done with it !
 harshit_	test it on fm_train_real.dat
 sonne|work	how does it compare speed wise?
 harshit_	same result on matlab
 sonne|work	well you can load any (bigger) data set
 harshit_	which one ? dna ?
 sonne|work	or mnist ...
 sonne|work	IIRC someone has .mat files for that one around too
 harshit_	ohk,but please tell me how to compare speeds
 sonne|work	tic; toc; in matlab :)
 sonne|work	or octave
 harshit_	okay .. thanks
 sonne|work	so just load the data tic; call newton svm matlab script ; toc
 sonne|work	and then do the same under octave with your new shogun newton svm impl
 n4nd0	sonne|work: I just submitted the application for multiclass
 sonne|work	seen it
 n4nd0	sonne|work: could you take it a look when you get some time and tell your opinion / things to improve?
 sonne|work	ok
 n4nd0	sonne|work: thank you :)
 n4nd0	sonne|work: it is quite based on SO's one so you can save some reading ;)
 n4nd0	time for me to take a rest
 n4nd0	see you later guys
 blackburn	yeah you are too
 blackburn	ehm don't know right word
 blackburn	nervous? ;)
 n4nd0	mmm no
 n4nd0	why?
 n4nd0	should I :P??
 blackburn	no, I mean you spend too much time there
 n4nd0	ah yes
 n4nd0	see you later then
 blackburn	see you
 harshit_	sonne|work : time  =  8.2211e-04, for training on fm database
 n4nd0	blackburn: try to stand up and stretch your legs for a while :)
 harshit_	now testing it on 20 newsgroup
 harshit_	will that work
-!- n4nd0 [~nando@n179-p53.kthopen.kth.se] has quit [Quit: leaving]
 sonne|work	harshit_: how big is the data set?
 sonne|work	how many examples / dims?
 blackburn	n4ndo yeah I do
 sonne|work	and please try matlab  too :)
 sonne|work	so we can compare
 harshit_	not really big
 harshit_	2*92
 harshit_	now running on 20Newgroup which is very large
 sonne|work	harshit_: how large?
 harshit_	about 18000 examples and 6000 features in 20NEwsgroup
 sonne|work	ok - is this data set sparse?
 sonne|work	if so please don't forget to convert it to dense
 sonne|work	in matlab the cmd is
 sonne|work	double(X)
 sonne|work	so we can compare
 sonne|work	octave modular has no sparse feature matrix support yet (one of gsomix's gsoc tasks :)
 harshit_	yeah that is sparse :
 blackburn	sonne|work: one of 100
 sonne|work	100000 :D
 sonne|work	gtg
 sonne|work	cu
 harshit_	bye
 harshit_	blackburn : having problems with 20Newsgroup on my problem
 harshit_	its a multiclass problem
 harshit_	which big dataset do you normally use
 blackburn	harshit_: http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html
 harshit_	thanks, :)
-!- harshit_ [~harshit@182.68.67.61] has quit [Ping timeout: 245 seconds]
-!- genix [~gsomix@188.168.5.165] has joined #shogun
@sonney2k	blackburn, well he could have just mergerd some labels...
 blackburn	sonney2k: Im not sure what is you are talknig about?
@sonney2k	multiclass -> binary
 blackburn	ah yes sure
@sonney2k	anyway mldata.org is probably even better for harshit - data already is in matlab format
-!- gsomix [~gsomix@83.234.169.79] has quit [Read error: Operation timed out]
-!- blackburn [5bdfb203@gateway/web/freenode/ip.91.223.178.3] has quit [Quit: Page closed]
-!- PhilTillet [~Philippe@tillet-p42154.maisel.int-evry.fr] has joined #shogun
 PhilTillet	Hello
-!- n4nd0 [~nando@s83-179-44-135.cust.tele2.se] has joined #shogun
-!- blackburn [~qdrgsm@83.234.54.186] has joined #shogun
 CIA-64	shogun: Soeren Sonnenburg master * rce6628c / examples/undocumented/python_modular/classifier_multiclasslinearmachine_modular.py : rename function to match file name - http://git.io/6uWtmg
 CIA-64	shogun: Soeren Sonnenburg master * ra28591d / testsuite/python_modular/tester.py : remove pdb import from tester - http://git.io/Qamxaw
 n4nd0	sonney2k: aham! so it was that pdb what changed before in the tester
 n4nd0	I executed it once and was smooth and in the second I got this gdb type interface
 n4nd0	I was like ... what did I do?
 n4nd0	:D
@sonney2k	n4nd0, yeah I screwed up debugging the tests
@sonney2k	n4nd0, I went through most of the tests and checked where they differ
@sonney2k	and most were ok but hey I screwed up again and forgot to upload the updated test files
@sonney2k	which are now gone - bah!
-!- siddharth [~siddharth@14.139.82.6] has joined #shogun
@sonney2k	n4nd0, I am now trying to figure out what this QDA error is about
@sonney2k	QDA.cs(143,18): error CS0136: A local variable named `i' cannot be declared in this scope because it would give a different meaning to `i', which is already used in a `parent or current' scope to denote something else
 n4nd0	what? I have never seen that
 n4nd0	but let's check
@sonney2k	n4nd0, look at the buildbot
@sonney2k	I renamed i -> c and it will likely compile
-!- siddharth [~siddharth@14.139.82.6] has left #shogun ["Leaving"]
 PhilTillet	sonney2k, is the kernel matrix stored columnwise or rowwise?
 CIA-64	shogun: Soeren Sonnenburg master * r54e89fd / src/shogun/classifier/QDA.h : rename index i to c to fix clash with csharp typemap - http://git.io/urYyOQ
 n4nd0	sonney2k: were are those files like QDA.cs?
@sonney2k	n4nd0, yes all good - lets hope the buildbot is happy now
@sonney2k	shogun-buildbot, be happy!
 shogun-buildbot	What you say!
 n4nd0	sonney2k: let's hope so
@sonney2k	PhilTillet, everything in shogun is columnwise
 n4nd0	sonney2k: ah ok, one makes the changes in the C++ source
@sonney2k	PhilTillet, but kernel matrix is usually not computed as one big thing (won't fit in mem...)
 PhilTillet	well yes but for GPUs ...
 PhilTillet	:p
 PhilTillet	for a first prototype I mean
@sonney2k	n4nd0, yes and swig generates the csharp python etc bindings
-!- genix [~gsomix@188.168.5.165] has quit [Read error: Operation timed out]
@sonney2k	PhilTillet, well it is really useless to do it for kernel matrices that fit in memory
 PhilTillet	hmmm
 PhilTillet	probably
@sonney2k	maybe you would rather want to speed up the compute() function? not sure what you are doing right now
 PhilTillet	I am trying to make some opencl implementation of my dirty code
 n4nd0	sonney2k: are the bindings normal source files? I got surprised looking at the buildbot and seeing that it identifies a QDA.cs, for example
 PhilTillet	like in the shogun CGaussianKerel and CKernelMachine class
 PhilTillet	so that just have to replace svm->apply() with svm->ocl_apply()
 PhilTillet	it internally copies everything to GPU mem (for now with the assumption that it will fit :D)
 n4nd0	sonney2k: I thought that we could use the code we do in C++ as libraries from the other languages, but that there was no generation with SWIG
@sonney2k	PhilTillet, what does it copy ? the kernel matrix?
@sonney2k	n4nd0, exactly
 PhilTillet	that was my incoming question
 PhilTillet	should I make another temporary matrix?
 PhilTillet	or should I make a gpu_kernel_matrix ?
 PhilTillet	like an attribute
@sonney2k	if you precompute the kernel matrix - all the rest will take basically 0 time
 n4nd0	sonney2k: I am reading a bit about SWIG right now to understand a bit more, thank you!
 PhilTillet	I know
 PhilTillet	the rest is just roughly a matrix vector product
@sonney2k	yes
 PhilTillet	but the kernel matrix is computed at the "apply()" point right?
 PhilTillet	hmm I see
 PhilTillet	the kernel matrix is not necessarily features*support_vectors
 PhilTillet	sonney2k, did not read carefully enough your question, it copies features to gpu, and caches support vectors
 PhilTillet	then compute labels on gpu
 PhilTillet	and copies them back to cpu
@sonney2k	PhilTillet, ahh so you copy just the support vectors?
 PhilTillet	the features too
@sonney2k	which features?
 PhilTillet	the examples
@sonney2k	which examples :)
 PhilTillet	wait I'm getting confused
 PhilTillet	XD
@sonney2k	the one to compute the output for?
 PhilTillet	yes
@sonney2k	s/one/ones
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
@sonney2k	(support vectors are also examples - a subset of the training examples)
 PhilTillet	oh yes right
@sonney2k	so test examples you mean probably
 PhilTillet	yes, I copy the support vectors and test examples to gpu
 PhilTillet	compute test labels on gpu
 PhilTillet	copies back to cpu
 PhilTillet	(test labels)
@sonney2k	what would be more reasonable is to copy only SVs to gpu
-!- harshit_ [~harshit@182.68.67.61] has joined #shogun
@sonney2k	and then test example by test example to GPU mem and compute output
 PhilTillet	I really do not think so
 PhilTillet	:p
 PhilTillet	would get way less gigaflops
@sonney2k	why?
@sonney2k	I would bet that it does not make any difference
 PhilTillet	hmmm
 PhilTillet	It does from a cahcing point of view
@sonney2k	why?
 PhilTillet	I mean, it's the difference between a matrix matrix product and a matrix vector product
 PhilTillet	when running on GPU
 PhilTillet	each work group caches chunk of the matrix
 PhilTillet	i don't really know how to explain
 PhilTillet	well there are multiple problems, but this is the first one
 PhilTillet	the work groups on gpu will cache chunks of the feature matrix
 n4nd0	sonney2k: it looks like it failed again
-!- blackburn [~qdrgsm@83.234.54.186] has quit [Ping timeout: 246 seconds]
 n4nd0	sonney2k: same error, same place
@sonney2k	PhilTillet, ok yes matrix1 * matrix2 is faster but neither matrix1 nor matrix2 fit in GPU memory
 PhilTillet	yes, this is why there has to be some complicated tricks to do
 PhilTillet	to do submatrix1*submatrix2
@sonney2k	you could even imagine test features to be streamed from disk
 PhilTillet	shouldn't it be possible to stream it into a buffer, and when the buffer has a certain size, transfer on gpu, compute, etc
@sonney2k	yes exactly
 PhilTillet	I think if we compute example by example, performance would be even worse on GPU than on CPU
 PhilTillet	plus, for each GPU operation (memory transfer, opencl kernel initialization, etc...)
 PhilTillet	there is about a 50microsec time
@sonney2k	but I would really focus on only doing submatrix1 stuff and use vectors on the right hand side
 PhilTillet	so if you get a 50microsec overhead for each example
 PhilTillet	but the main issues is the gigaflop one :p
 PhilTillet	hmmm
 PhilTillet	right hand side is the test examples?
@sonney2k	if the overhead is really that huge then it is becoming tough
@sonney2k	yes
 PhilTillet	I mean, why not accumulating the test examples into a sufficiently small buffer?
@sonney2k	brb
 PhilTillet	ok :)
 n4nd0	sonney2k: QDA.cpp:87, I used int instead of int32_t there, do you think it can be related?
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Ping timeout: 276 seconds]
-!- blackburn [~qdrgsm@83.234.54.186] has joined #shogun
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
-!- gsomix [~gsomix@188.168.5.227] has joined #shogun
@sonney2k	n4nd0, be patient ... the buildbot is still working
 blackburn	gsomix: here, wanted to catch me? ;)
 blackburn	sonney2k: what's up?
 blackburn	strange issue with 'i'
@sonney2k	no
@sonney2k	not strange and problem resolved
 blackburn	sonney2k: that mail from jacob - I can hardly come with any answer, can you?
@sonney2k	blackburn, no - I am not a GP expert
@sonney2k	olivier has to answer to this
 blackburn	yes but he listed oliver's ideas mostly :)
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Remote host closed the connection]
@sonney2k	no idea
@sonney2k	blackburn, did the buildbot get any break recently?
@sonney2k	seems to me it is hardly diling
@sonney2k	idling
 blackburn	sonney2k: what kind of break?
 blackburn	ah
 blackburn	yeah strange
 blackburn	a few small commits probably
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
 CIA-64	shogun: Sergey Lisitsyn master * rf1564b9 / (3 files in 3 dirs): Warnings removal - http://git.io/w639Ng
 blackburn	sonney2k: have you seen git network?
 blackburn	of shogun
 blackburn	https://github.com/shogun-toolbox/shogun/network kind of subway
 blackburn	just like last year :)
 blackburn	sonney2k: btw have you got stats of shogun-toolbox.org? should be interesting
@sonney2k	blackburn, would be more impressive if we both did pull requests too
 blackburn	sonney2k: I do for big things like edrt
 blackburn	but hey new branch to remove warnings..
 blackburn	whoaa http://www.youtube.com/watch?feature=player_detailpage&v=K9EICyaEJq0
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Remote host closed the connection]
 harshit_	blackburn :having a little error when i use lard dataset in octave : No matching function for overload
 blackburn	which function?
 harshit_	and error points to Label()
 blackburn	Label?
 harshit_	on line : labels=Labels(label_train_twoclass);
 harshit_	where label_train_twoclass is a vector
 harshit_	having labels
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
@sonney2k	harshit_, what type is that?
@sonney2k	harshit_, does Labels([1.0, 2.0, 3.0]) work?
 harshit_	I dont declare any type as such ,labels is returned from libsvmread() function
 harshit_	wait i'll check
 harshit_	No Labels([1.0,2.0,3.0]) doesn't give any error
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Ping timeout: 276 seconds]
 blackburn	http://cs5422.userapi.com/u464017/-14/x_ac4cb519.jpg skyscraper is on fire in moscow
 harshit_	Done ! figured out the problem
 n4nd0	blackburn: too warm around there?
 blackburn	n4nd0: I am fortunately 1000 km far away haha
 n4nd0	blackburn: good
 n4nd0	blackburn: I hope it is not a big disaster
 blackburn	today was a plane crash in other city
 blackburn	that was a disaster actualyl
 blackburn	38 died
 blackburn	IIRC
@sonney2k	harshit_, so what was the problem?
 harshit_	sonney2k: In octave , newton SVM is taking 0.091
 harshit_	i just transposed labels and matrix and it worked !
 harshit_	0.091 sec to train 60*1000 dataset
 harshit_	dataset I used is called splice dataset
@sonney2k	harshit_, can't you use a bigger data set?
 harshit_	couldn't find any one which doesn't requires preprocessing
@sonney2k	harshit_, http://mldata.org/repository/data/viewslug/covtypebinary_scale/
@sonney2k	you can even just download a .mat file
@sonney2k	no work needed...
 harshit_	great .. wait i'll run on it
 harshit_	dam thats a really big one !
 n4nd0	sonney2k: do you have any other task in mind / something you would like to see done in shogun?
@sonney2k	n4nd0, want to learn a bit more about swig?
 harshit_	sonney2k : I saw S3VM somewhere in liblinear, so why in homepage of shogun semisupervised algos is crossed
 harshit_	at place where all toolboxes are compared
@sonney2k	n4nd0, or lets better ask which topic is of interest to you?
@sonney2k	harshit_, liblinear has s3svm?
 n4nd0	sonney2k: I am a bit open minded in that sense, I even prefer to learn some new stuff
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
 harshit_	I dont remember exactly which svm library it was but somewhere i saw an enum where S3VM was an option for classifier type
 n4nd0	sonney2k: I wondered before if you had something on shell scripting to be done
 harshit_	sonney2k : Just wondering if you want to see co-clustering by blum in shogun !
 n4nd0	sonney2k: among the things I have done this far, I like the most QDA
 n4nd0	sonney2k: other classifier (if there's something not around here yet!) could be good then
@sonney2k	n4nd0, some 'easy' decision tree then?
 blackburn	I have my own id3 python prototype actually
 n4nd0	sonney2k: sure, I don't know about decision trees that much
 n4nd0	it will be good to learn about them
 blackburn	parzen window classifier
@sonney2k	maybe even start with decision stumps
@sonney2k	blackburn, true
 n4nd0	haha you guys definetely have lot of ideas
@sonney2k	e.g. https://en.wikipedia.org/wiki/ID3_algorithm
 blackburn	not a lot, only a few (about one thousand)
@sonney2k	or rbf networks https://en.wikipedia.org/wiki/Radial_basis_function_network
 blackburn	ARMA model haha
 blackburn	ransac
@sonney2k	blackburn, btw does KNN use covertree now?
 blackburn	no
 blackburn	I suggested to do that a few times :)
 n4nd0	blackburn: oh yes, that's true, you told me about that
 blackburn	n4nd0: now you can do that I think
 n4nd0	blackburn: ok, I will take a look to covertree in KNN then
 blackburn	(after struggles with spe)
 n4nd0	sonney2k: is that ok?
 n4nd0	blackburn: sure ;)
@sonney2k	yup
 n4nd0	ok
 blackburn	n4nd0: but will you finish spe?
 blackburn	:)
 n4nd0	blackburn: yeah!
 blackburn	ok
 n4nd0	blackburn: I said sure :P
 blackburn	I believe we need to add more cats to shogun
@sonney2k	harshit_, so what are the timings?
 blackburn	we have no graphical examples with cats
@sonney2k	blackburn, well we have one cat - your gf :)
 blackburn	sonney2k: http://www.persian-catsclub.com/images/persian-cat.jpg looks like shogun mascot
@sonney2k	yeah
 blackburn	sonney2k: I pasted you msg to gf :D
@sonney2k	kind of a yakuza mafia shogun cat
 blackburn	yeah
 blackburn	very dangerous
 harshit_	sonney2k: strange error ! nothing comes after first iteration of newtonSVM
 harshit_	But everything was working fine for other datasets
@sonney2k	harshit_, even w/ matlab?
 harshit_	I am working in octave for now
 blackburn	sonney2k: is scatter mc svm a good idea still?
@sonney2k	not so much
 blackburn	ah, n4nd0 - nearest centroid classifier!
 n4nd0	blackburn: haha another idea!?
 blackburn	and one with median
 blackburn	yes
 blackburn	two even
 blackburn	I forgot how do they call it
 harshit_	Could that be bcoz of less memory available to octave?
@sonney2k	harshit_, well you could use 1/2 of the data if the data set is too big
 harshit_	sonney2k : its running now with full dataset, Problem was that I had a lot of things opened earlier
 PhilTillet	hi hi
 CIA-64	shogun: Soeren Sonnenburg master * refd2da9 / testsuite/python_modular/tester.py : add try catch around len() - http://git.io/8yuhSA
 n4nd0	sonney2k: what about the QDA.cs issue? I have checked and think that the error is still there
 n4nd0	sonney2k: but maybe I didn't check it correctly
@sonney2k	n4nd0, it compiled locally here...
@sonney2k	PhilTillet, that's a linear method - hard to imagine how GPUs can speed up anything for this
 n4nd0	I have no idea to check the buildbot then :S
@sonney2k	n4nd0, it is overly busy...
 PhilTillet	sonney2k, what are you talking about? :p
@sonney2k	heh
 blackburn	sonney2k: was it an answer for 'hi hi'?
 blackburn	I can hardly imagine what you would answer for ho ho
 PhilTillet	lol
@sonney2k	n4nd0, lets see if everything is OK tomorrow
 blackburn	kernel laplace transformation can not map into non-euclidean space?
 blackburn	:D
@sonney2k	blackburn, did I say that I love the shogun killer cat(tm)?
@sonney2k	anyway bed time for me
@sonney2k	cu all
 PhilTillet	cu
 n4nd0	good night
 blackburn	sonney2k: yeah cats are cool :) nite
-!- harshit_ [~harshit@182.68.67.61] has quit [Read error: Connection reset by peer]
-!- PSmitAalto [82e9b263@gateway/web/freenode/ip.130.233.178.99] has quit [Ping timeout: 245 seconds]
-!- harshit_ [~harshit@182.68.67.61] has joined #shogun
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Ping timeout: 276 seconds]
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
-!- harshit_ [~harshit@182.68.67.61] has quit [Read error: Connection reset by peer]
 shogun-buildbot	build #196 of nightly_all is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/nightly_all/builds/196
 blackburn	n4nd0: gsomix vodka! ^
 n4nd0	awesome!!
 n4nd0	C# should work soon then
 n4nd0	btw
 n4nd0	what does nightly stands for / mean?
 n4nd0	I guess it must be a name used to refer to a special release or sth like that
 blackburn	n4nd0: it build on nights ;)
 blackburn	is builded*
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Remote host closed the connection]
 blackburn	firefox also has nightly builds and a lot of other projects too
 n4nd0	aham, I see
 n4nd0	so it was the obvious answer :D
-!- wiking_ [~wiking@huwico/staff/wiking] has joined #shogun
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
-!- naywhaya1e [~ryan@spoon.lugatgt.org] has joined #shogun
-!- wiking [~wiking@huwico/staff/wiking] has quit [Ping timeout: 260 seconds]
-!- naywhayare [~ryan@spoon.lugatgt.org] has quit [Ping timeout: 260 seconds]
-!- wiking_ is now known as wiking
 shogun-buildbot	build #435 of csharp_modular is complete: Success [build successful]  Build details are at http://www.shogun-toolbox.org/buildbot/builders/csharp_modular/builds/435
-!- harshit_ [~harshit@182.68.67.61] has joined #shogun
 harshit_	sonney2k: done !
 harshit_	it was not running because of the value of C I set was too low
 harshit_	now it has took 7.892sec for whole dataset
-!- muddo [~muddo@gateway/tor-sasl/muddo] has quit [Ping timeout: 276 seconds]
 blackburn	see you guys
-!- muddo [~muddo@gateway/tor-sasl/muddo] has joined #shogun
-!- blackburn [~qdrgsm@83.234.54.186] has quit [Ping timeout: 252 seconds]
-!- vikram360 [~vikram360@117.192.161.93] has quit [Read error: Connection reset by peer]
 n4nd0	good night
 gsomix	ta-dam
 gsomix	i finished repair of room.
-!- flxb [~cronor@fb.ml.tu-berlin.de] has quit [Quit: flxb]
-!- PhilTillet [~Philippe@tillet-p42154.maisel.int-evry.fr] has quit [Remote host closed the connection]
-!- wiking [~wiking@huwico/staff/wiking] has quit [Quit: wiking]
-!- tibi_popa [tibi_popa@95.76.45.235] has joined #shogun
--- Log closed Tue Apr 03 00:00:19 2012
